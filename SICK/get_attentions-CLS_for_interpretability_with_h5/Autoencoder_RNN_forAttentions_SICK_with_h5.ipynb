{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Uq8sbfogrQJy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import re\n",
        "import shutil\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.utils.data.sampler import SequentialSampler\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import silhouette_score, jaccard_score, f1_score, homogeneity_completeness_v_measure, adjusted_rand_score\n",
        "from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score, pairwise_distances\n",
        "import numpy as np\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "import torch.nn.functional as F\n",
        "import h5py\n",
        "import ast\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08HLAANDw06m",
        "outputId": "18adab86-eafe-4777-a48b-287e94e726b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "W4BiyNxQhY4T"
      },
      "outputs": [],
      "source": [
        "path_base = '/content/drive/MyDrive/Tesis/SICK/transformer_tunned_BERT/uncase_base/study_optuna/'\n",
        "file_root = '/content/drive/MyDrive/Tesis/SICK/uncase_based/SICK.txt'\n",
        "with open(file_root, 'r') as temp_f:\n",
        "    # get No of columns in each line\n",
        "    col_count = [ len(l.split(\"\\t\")) for l in temp_f.readlines() ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jJCuyxk3hmEH"
      },
      "outputs": [],
      "source": [
        "def getSICKSents(filename='sts-train.csv', set_type='TRAIN', encoding='utf-8'):\n",
        "  f = open(filename, 'r', encoding=encoding)\n",
        "  s1, s2, target = [], [], []\n",
        "  for i, line in enumerate(f):\n",
        "    example = re.split(r'\\t+', line)\n",
        "    if i >= 1:\n",
        "      if example[-1].strip() == set_type:\n",
        "        s2.append(example[1])\n",
        "        s1.append(example[2])\n",
        "        target.append(float(example[4]))\n",
        "  print(\"samples: {}\".format(len(target)))\n",
        "  return s1, s2, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EcrzLWThrkg",
        "outputId": "311255d7-1d19-486d-b4c1-fb6a4bb2ce61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "samples: 4906\n"
          ]
        }
      ],
      "source": [
        "s1_test,s2_test,target_test= getSICKSents(file_root, 'TEST')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CfBedtrSv9bN"
      },
      "outputs": [],
      "source": [
        "BERT_PATH = \"bert-base-uncased\"\n",
        "root_drive = '/content/drive/MyDrive/Tesis/SICK/transformer_tunned_BERT/uncase_base/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKElhIi44LJD",
        "outputId": "b31b0bb5-bfb5-47e4-8933-6215faee2fcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Device: {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vwILPcnLp7H0"
      },
      "outputs": [],
      "source": [
        "def save_with_hdf5(file_path, data_dict):\n",
        "    # Save data in HDF5 format\n",
        "    with h5py.File(file_path, 'w') as hf:\n",
        "        # Iterate through the dictionary and save the data to the HDF5 file\n",
        "        def save_dict(group, data):\n",
        "            for key, value in data.items():\n",
        "                key_str = str(key)  # Convert the key to a string\n",
        "                if isinstance(value, dict):\n",
        "                    # If the value is a dictionary, create a new group and save the data inside it\n",
        "                    subgroup = group.create_group(key_str)\n",
        "                    save_dict(subgroup, value)\n",
        "                elif isinstance(value, np.ndarray):\n",
        "                    # If the value is a NumPy array, save it as a dataset\n",
        "                    group.create_dataset(key_str, data=value)\n",
        "                else:\n",
        "                    # For other data types, save them as attributes\n",
        "                    group.attrs[key_str] = value\n",
        "\n",
        "        save_dict(hf, data_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-HNxqbJcYs7_"
      },
      "outputs": [],
      "source": [
        "def is_tuple(string):\n",
        "    try:\n",
        "        result = ast.literal_eval(string)\n",
        "        return isinstance(result, tuple)\n",
        "    except (SyntaxError, ValueError):\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1dWJRmZJYrfF"
      },
      "outputs": [],
      "source": [
        "def load_with_hdf5(file_path):\n",
        "    loaded_data = {}\n",
        "\n",
        "    # Load data from the HDF5 file\n",
        "    with h5py.File(file_path, 'r') as hf:\n",
        "        # Recursive function to load data from the HDF5 file\n",
        "        def load_dict(group):\n",
        "            result = {}\n",
        "            for key, item in group.items():\n",
        "                # Use the key directly if it is a string, otherwise, convert back to tuple\n",
        "                key_obj = ast.literal_eval(key) if is_tuple(key) else key\n",
        "                if isinstance(item, h5py.Group):\n",
        "                    # If it's a group, load its data recursively\n",
        "                    result[key_obj] = load_dict(item)\n",
        "                    # Retrieve attributes from the group\n",
        "                    for attr_key, attr_value in item.attrs.items():\n",
        "                        result[key_obj][attr_key] = attr_value\n",
        "                else:\n",
        "                    # If it's a dataset, load its values\n",
        "                    result[key_obj] = torch.tensor(np.array(item))\n",
        "            return result\n",
        "\n",
        "        loaded_data = load_dict(hf)\n",
        "\n",
        "    return loaded_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uX58jKR0Y6hF"
      },
      "outputs": [],
      "source": [
        "file_name = 'embeddings_att_sick.h5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Wt0bSVTKZ0Kt"
      },
      "outputs": [],
      "source": [
        "!cp {root_drive + file_name} /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tknswpDAwi-j"
      },
      "outputs": [],
      "source": [
        "#all_attentions_matrix = load_with_hdf5(root_drive + file_name)\n",
        "all_attentions_matrix = load_with_hdf5(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dm9exZEsB7sh",
        "outputId": "62096729-3672-44f3-ec82-9d6061d42514"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "706464"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(all_attentions_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAexbnf3I632",
        "outputId": "3b634af2-b4ff-4023-930a-db47cb5c2ffc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-16-56402357c72e>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tensor_list.append(torch.tensor(all_attentions_matrix[(i,j,k)]['vectors']).flatten())\n"
          ]
        }
      ],
      "source": [
        "layers = 12\n",
        "heads = 12\n",
        "#num_sentences = list(all_attentions_matrix.keys())[-1][0]+1\n",
        "num_sentences = int(len(all_attentions_matrix.keys())/(layers*heads))\n",
        "attentions_concat_heads = {}\n",
        "attentions_matrix_list = []\n",
        "attentions_list = []\n",
        "\n",
        "for i in range(num_sentences):\n",
        "  for j in range(layers):\n",
        "    tensor_list = []\n",
        "    for k in range(heads):\n",
        "      tensor_list.append(torch.tensor(all_attentions_matrix[(i,j,k)]['vectors']).flatten())\n",
        "    #attentions_concat_heads[(i,j)] = torch.stack(tensor_list).unsqueeze(0).permute(0, 2, 1)\n",
        "    stack = torch.stack(tensor_list)\n",
        "    attentions_concat_heads[(i,j)] = stack\n",
        "    attentions_matrix_list.append(stack)\n",
        "    #attentions_list.append(((i,j),all_attentions_matrix[(i,j,k)]['label'], stack))\n",
        "    attentions_list.append(((i,j),all_attentions_matrix[(i,j,k)]['sequence'],all_attentions_matrix[(i,j,k)]['label'],all_attentions_matrix[(i,j,k)]['dimension'],stack))\n",
        "attentions_list = [(id,s,label,dim,tensor.permute(1,0)) for id, s, label, dim, tensor in attentions_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGj5N56IdE5R",
        "outputId": "a747b79d-b0c3-4a8e-8262-995e14233f8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "58872"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(attentions_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GKJ74Gwpd-R",
        "outputId": "9d37d878-fa91-4e15-a538-768d6adc513c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((2, 0),\n",
              " 's1: The young boys are playing outdoors and the man is smiling nearby s2: A group of children is playing in the house and there is no man standing in the background',\n",
              " '3.0',\n",
              " '33',\n",
              " tensor([[0.0262, 0.1389, 0.4780,  ..., 0.0255, 0.5980, 0.4030],\n",
              "         [0.0459, 0.0046, 0.0307,  ..., 0.0165, 0.0251, 0.2017],\n",
              "         [0.0216, 0.0008, 0.0092,  ..., 0.0344, 0.0096, 0.0032],\n",
              "         ...,\n",
              "         [0.0471, 0.0352, 0.1198,  ..., 0.0264, 0.0337, 0.1335],\n",
              "         [0.0302, 0.0087, 0.2945,  ..., 0.0223, 0.0434, 0.0442],\n",
              "         [0.0664, 0.0175, 0.1813,  ..., 0.0263, 0.6866, 0.1654]]))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attentions_list[24]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXBO0gqRwGuf",
        "outputId": "1a8c00ce-10dc-4ed4-cf50-7ce8842a0495"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1089, 12])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attentions_list[0][4].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-t7cRSS-NRO"
      },
      "source": [
        "Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "dSzUvRBd7oaW"
      },
      "outputs": [],
      "source": [
        "# Crear un sampler secuencial\n",
        "# attentions_list = dataset\n",
        "# SequentialSampler does not perform any shuffling or random selection of items.\n",
        "sampler = SequentialSampler(attentions_list)\n",
        "\n",
        "# Definir el tamaño del lote\n",
        "batch_size = 12 # always 12, because it is the number of attention layers, 12 layers for the same sentence\n",
        "\n",
        "# Crear el DataLoader sin un BatchSampler\n",
        "dataloader = DataLoader(attentions_list, batch_size=batch_size, sampler=sampler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQmpqNtb9cNp",
        "outputId": "4db20de0-f352-4979-e225-5ad854ef8a78"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4906"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataloader) #1379 OK because there are 1379 sentences, 1 batch = 1 same sentence , 12 elements in the batch because there are 12 layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RUVAl03NZqO",
        "outputId": "ce086190-201c-40ab-e671-010ab239a62b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([12, 1089, 12])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sr = next(iter(dataloader))\n",
        "sr[0] # ids (num_sent, num_layer)\n",
        "sr[1] # sequence\n",
        "sr[2] # similarity label\n",
        "sr[3] # dimension\n",
        "sr[4].shape #[batch_size, len_sentence, input_size] with attentions ([12,289,12])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "lh2_LvEAFOuX"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "cJcjfZz_-uD3"
      },
      "outputs": [],
      "source": [
        "def train_loop(model, iterator, optimizer, criterion, device=device, clip = 1.0):\n",
        "    #Training loop\n",
        "    model.train()\n",
        "    loss_sum = 0\n",
        "    seed = 42\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    #torch.cuda.set_device(0)\n",
        "\n",
        "    for i, (_,_,_,_,input) in enumerate(iterator):\n",
        "        optimizer.zero_grad()\n",
        "        output, _ = model(input)\n",
        "        loss = criterion(output, input)\n",
        "        loss.backward()\n",
        "        #prevent gradients from exploding\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        #Update params\n",
        "        optimizer.step()\n",
        "        loss_sum += loss.item()\n",
        "\n",
        "    epoch_train_loss = loss_sum * batch_size / len(iterator)\n",
        "\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "hZ3fWPpSI-pq"
      },
      "outputs": [],
      "source": [
        "# Extraer el vector latente fijo de cada elemento del batch\n",
        "def extract_latent_vectors(model, dataloader, device, model_type='RNN'):\n",
        "    model.eval()\n",
        "    vector_representations = {}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (id,s,label,dim,input) in dataloader:\n",
        "            latent_vectors = []\n",
        "            if model_type == 'RNN':\n",
        "              _, (latent_representation, _) = model.encoder(input)\n",
        "              latent = latent_representation.squeeze(0)\n",
        "            else:\n",
        "              latent_representation = model.encoder(input)\n",
        "              latent = latent_representation.squeeze(0).squeeze(1)\n",
        "            tuples = list(zip(id[0].tolist(), id[1].tolist()))\n",
        "            #latent = latent_representation.squeeze(0)\n",
        "            for i in range(latent.size(0)):\n",
        "              latent_vectors.append(latent[i].numpy())\n",
        "              vector_representations[tuples[i]] = { 'vector' : latent[i].numpy(), 'sequence': s, 'label': label, 'dimension':dim}\n",
        "\n",
        "    return vector_representations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "CspMdXG6P9dc"
      },
      "outputs": [],
      "source": [
        "# Definir la arquitectura del autoencoder con LSTM\n",
        "class AutoencoderLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, latent_size = 128):\n",
        "        super(AutoencoderLSTM, self).__init__()\n",
        "        self.encoder = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.decoder = nn.LSTM(hidden_size, input_size, batch_first=True)\n",
        "    def forward(self, x):\n",
        "        # Codificación\n",
        "        #o = [1, 12, 128] = [batch_size, len_sents, hidden_size]\n",
        "        #x = [1, 12, 289] = [batch_size, len_sents, input_size]\n",
        "        #print(x.shape)\n",
        "        o, (h_n, _) = self.encoder(x)\n",
        "        #h = [1, 1, 128] = [batch_size, num_layers * num_directions, hidden_size]\n",
        "        # Reducción a tamaño latente\n",
        "        #latent = [1, 128] = [num_layers * num_directions, hidden_size]\n",
        "        latent = h_n.squeeze(0)\n",
        "        # Decodificación\n",
        "        #output, _ = self.decoder(latent.unsqueeze(0).repeat(1, x.size(1), 1))\n",
        "        output, _ = self.decoder(o)\n",
        "        return output, latent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VTc_w-0EI_7",
        "outputId": "04337af4-665d-4fd3-883a-bf5bda33021e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Epoch: 001/4 | Epoch Time: 2m 52s | Train loss: 0.0706\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 002/4 | Epoch Time: 2m 47s | Train loss: 0.0551\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 003/4 | Epoch Time: 2m 48s | Train loss: 0.0522\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 004/4 | Epoch Time: 2m 48s | Train loss: 0.0510\n"
          ]
        }
      ],
      "source": [
        "NUM_EPOCHS = 4\n",
        "best_valid_loss = float('inf')\n",
        "model_name = 'Autoencoder_LSTM'\n",
        "train_loss_values = []\n",
        "history = {\"train\": {\"loss\": []}}\n",
        "\n",
        "input_size = 12  #due to 768 dimensión of BERT\n",
        "hidden_size = 2  # size of fixed vector #laten dim\n",
        "learning_rate = 0.001 #0.00025 #0.0007\n",
        "\n",
        "seed = 42\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "\n",
        "model = AutoencoderLSTM(input_size, hidden_size)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    epoch_train_loss = train_loop(model,dataloader,optimizer,criterion,device)\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    train_loss_values.append(epoch_train_loss)\n",
        "\n",
        "    history[\"train\"][\"loss\"].append(epoch_train_loss)\n",
        "\n",
        "    print('-' * 80)\n",
        "    #print(f'Epoch: {epoch+1:03}/{NUM_EPOCHS} | Epoch Time: {epoch_mins}m {epoch_secs}s | Train loss: {epoch_train_loss:.4f} | Train acc: {epoch_train_acc:.4f} | Dev loss: {epoch_dev_loss:.4f} | Dev acc: {epoch_dev_acc:.4f}')\n",
        "    print(f'Epoch: {epoch+1:03}/{NUM_EPOCHS} | Epoch Time: {epoch_mins}m {epoch_secs}s | Train loss: {epoch_train_loss:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "rmqDO8T-doKJ"
      },
      "outputs": [],
      "source": [
        "vector_representations = extract_latent_vectors(model, dataloader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "387PV-bDzyzd",
        "outputId": "727b554a-e00c-445d-82dc-a10bcab53616"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.21865737, -0.2827385 ], dtype=float32)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector_representations[(0,0)]['vector']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "tYaMFe_AqDKZ"
      },
      "outputs": [],
      "source": [
        "save_with_hdf5('reduced_vectors_sick_att_2D_prueba.h5', vector_representations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BdlJHLZVrvOQ",
        "outputId": "a38e37d5-844a-4dae-9d91-27d300715010"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Tesis/SICK/transformer_tunned_BERT/uncase_base/'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "root_drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "kHNIz9gCrN2L"
      },
      "outputs": [],
      "source": [
        "!cp 'reduced_vectors_sick_att_2D_prueba.h5' {root_drive}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32RlZGvQo8XE",
        "outputId": "c241fdbe-3386-4c22-9ece-1ac4ff33d43d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "58872"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vector_representations) #(num_sentence,layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "MmjHPaj5w5_m"
      },
      "outputs": [],
      "source": [
        "def convert_to_num(text):\n",
        "    try:\n",
        "        # Try to convert the text to a number (int or float)\n",
        "        number = float(text)\n",
        "        # Check if the number is an integer, and if so, convert it to int\n",
        "        if number.is_integer():\n",
        "            return int(number)\n",
        "        return number\n",
        "    except ValueError:\n",
        "        # If there is a ValueError, return the original text\n",
        "        return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "EfSgYSnaoq_v"
      },
      "outputs": [],
      "source": [
        "def get_representations_per_layer(num_sentences, vector_representations, layers = 12, main_key = 'vector', add_keys = ['sequence','label','dimension']):\n",
        "  vectors_per_layer = {}\n",
        "  labels = {}\n",
        "  data = []\n",
        "  for l in range(layers):\n",
        "    vectors_per_layer[l] = np.array([vector_representations[(i,l)][main_key] for i in range(num_sentences)])\n",
        "  data.append(vectors_per_layer)\n",
        "  for j in add_keys:\n",
        "    data.append({i: vector_representations[(i, 0)][j][0].item() if isinstance(vector_representations[(i, 0)][j][0], torch.Tensor) else convert_to_num(vector_representations[(i, 0)][j][0]) for i in range(num_sentences)})\n",
        "  return tuple(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jBjE7TBjskDP",
        "outputId": "3231f04d-6c50-4ee8-cdfe-e7457b2c3877"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.0'"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector_representations[(i,0)]['label'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "mBvM7amZVhFB"
      },
      "outputs": [],
      "source": [
        "vectors_per_layer, sequences, labels, dimensions = get_representations_per_layer(num_sentences, vector_representations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "4GnzEYA7yURV"
      },
      "outputs": [],
      "source": [
        "save_with_hdf5('vectors_per_layer_ATT_LSTM_prueba_sick_h5.h5', vectors_per_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "PQo3Bd7dy8Ka"
      },
      "outputs": [],
      "source": [
        "!cp 'vectors_per_layer_ATT_LSTM_prueba_sick_h5.h5' {root_drive}"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
