{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Uq8sbfogrQJy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import re\n",
        "import shutil\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.utils.data.sampler import SequentialSampler\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import silhouette_score, jaccard_score, f1_score, homogeneity_completeness_v_measure, adjusted_rand_score\n",
        "from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score, pairwise_distances\n",
        "import numpy as np\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08HLAANDw06m",
        "outputId": "311670b3-4e04-41ec-9b16-e99789f26268"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O Stsbenchmark.tar.gz http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz\n",
        "shutil.unpack_archive('./Stsbenchmark.tar.gz', extract_dir='./', format='gztar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4BiyNxQhY4T",
        "outputId": "bf36ccc6-22f3-436e-8c52-4d089386f619"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-29 23:53:12--  http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz\n",
            "Resolving ixa2.si.ehu.es (ixa2.si.ehu.es)... 158.227.106.100\n",
            "Connecting to ixa2.si.ehu.es (ixa2.si.ehu.es)|158.227.106.100|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: http://ixa2.si.ehu.eus/stswiki/images/4/48/Stsbenchmark.tar.gz [following]\n",
            "--2024-01-29 23:53:13--  http://ixa2.si.ehu.eus/stswiki/images/4/48/Stsbenchmark.tar.gz\n",
            "Resolving ixa2.si.ehu.eus (ixa2.si.ehu.eus)... 158.227.106.100\n",
            "Connecting to ixa2.si.ehu.eus (ixa2.si.ehu.eus)|158.227.106.100|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 409630 (400K) [application/x-gzip]\n",
            "Saving to: ‘Stsbenchmark.tar.gz’\n",
            "\n",
            "Stsbenchmark.tar.gz 100%[===================>] 400.03K   302KB/s    in 1.3s    \n",
            "\n",
            "2024-01-29 23:53:16 (302 KB/s) - ‘Stsbenchmark.tar.gz’ saved [409630/409630]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getSTSBenchmarkSents(filename='sts-train.csv', root='stsbenchmark/', encoding='utf-8'):\n",
        "  f = open(root+filename, 'r', encoding=encoding)\n",
        "  s1, s2, target = [], [], []\n",
        "  for line in f:\n",
        "    example = re.split(r'\\t+', line)\n",
        "    if len(example) > 7:\n",
        "      example = example[:-2]\n",
        "    s2.append(example[-1])\n",
        "    s1.append(example[-2])\n",
        "    target.append(float(example[-3]))\n",
        "  print(\"{} samples: {}\".format(filename, len(target)))\n",
        "  return s1, s2, target"
      ],
      "metadata": {
        "id": "jJCuyxk3hmEH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s1_test,s2_test,target_test= getSTSBenchmarkSents(filename='sts-test.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EcrzLWThrkg",
        "outputId": "4441b91a-7835-483a-b4bf-da240d184deb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sts-test.csv samples: 1379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BERT_PATH = \"bert-base-uncased\"\n",
        "root_drive = '/content/drive/MyDrive/Tesis/STS_Benchmark/transformer_tunned_BERT/uncase_base/'"
      ],
      "metadata": {
        "id": "CfBedtrSv9bN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Device: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKElhIi44LJD",
        "outputId": "2a1291b8-2ac9-4fe6-a2bc-cced2d29271c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#(num_senquence, num_capa)\n",
        "CLS_vectors = torch.load(root_drive + 'bert-base-uncased_CLS_outputs_test_STS-B.pth', map_location=torch.device(device))"
      ],
      "metadata": {
        "id": "tknswpDAwi-j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLS_vectors[(0,0)]['vectors'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAexbnf3I632",
        "outputId": "b98bd03d-9129-4149-ea46-a81a0ac594aa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layers = 12\n",
        "heads = 12\n",
        "num_sentences = list(CLS_vectors.keys())[-1][0]+1\n",
        "CLS_vectors_list = []\n",
        "\n",
        "for i in range(num_sentences):\n",
        "  for j in range(layers):\n",
        "    CLS_vectors_list.append(((i,j),CLS_vectors[(i,j)]['sequence'],CLS_vectors[(i,j)]['label'],CLS_vectors[(i,j)]['dimension'],CLS_vectors[(i,j)]['vectors']))"
      ],
      "metadata": {
        "id": "L23MV8rfAAxm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLS_vectors_list[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GKJ74Gwpd-R",
        "outputId": "62c7eaf3-f2d5-4fb3-942c-383fb4ba8a2e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((0, 0),\n",
              " 's1: A girl is styling her hair. s2: A girl is brushing her hair.',\n",
              " 2.5,\n",
              " 17,\n",
              " tensor([[ 2.1241e-03,  8.7672e-02, -2.0873e-01, -3.1814e-01,  2.7714e-01,\n",
              "           6.1523e-02, -1.8077e-01, -3.2233e-02, -1.0158e-01, -4.0595e-01,\n",
              "           3.4837e-02, -3.4986e-02,  1.5076e-01, -1.4688e-01, -1.2356e-01,\n",
              "           4.7144e-01,  4.5217e-01,  2.8083e-01, -1.1098e-01, -5.7833e-01,\n",
              "          -5.3669e-01, -3.2599e-01,  3.8374e-02, -2.1438e-01, -1.6631e-01,\n",
              "          -2.5951e-01, -3.9027e-01,  3.3140e-02,  5.1995e-02, -1.2945e-01,\n",
              "          -1.0947e-01, -1.7551e-01,  2.0924e-01,  1.3261e-01, -3.7521e-01,\n",
              "           7.5862e-02, -3.9207e-01,  1.6900e-01, -2.4508e-01,  2.2689e-01,\n",
              "           3.1682e-01, -1.9301e-01, -1.1316e-01,  1.7409e-01,  9.5839e-02,\n",
              "           1.2638e-01, -1.5249e+00, -1.8080e-02,  5.6530e-01, -2.1335e-01,\n",
              "           1.8438e-01,  4.1332e-02, -2.7097e-01,  8.9426e-01,  3.6618e-02,\n",
              "          -1.1993e-01, -2.5171e-01,  9.9663e-02,  2.7470e-01, -2.6993e-01,\n",
              "          -7.9190e-04, -4.5424e-02,  2.8888e-01,  6.1482e-02, -2.3661e-01,\n",
              "           4.3340e-01,  8.1512e-02, -1.7688e-01, -4.1176e-02,  6.1572e-02,\n",
              "          -4.8899e-03,  1.6114e-02, -3.7970e-01, -4.9134e-01,  2.6244e-01,\n",
              "          -4.4434e-02, -3.2246e-01,  2.8203e-01,  2.5260e-01,  3.5206e-01,\n",
              "          -3.0487e-01, -6.9409e-02,  6.6748e-02,  2.2410e-01,  3.2443e-01,\n",
              "           2.4921e-01,  2.8177e-01,  3.0974e-01, -8.4236e-02,  2.3495e-01,\n",
              "          -3.8089e-01, -2.4197e-02, -2.1665e-01,  1.9089e-03,  8.7039e-02,\n",
              "           1.4091e-01,  5.4470e-01, -3.2310e-01, -1.7874e-01, -2.8963e-01,\n",
              "           7.6051e-03, -1.3237e-01,  1.5568e-01, -9.8097e-02, -4.5425e-01,\n",
              "           4.0867e-01,  3.7830e-02, -1.0288e-01,  1.0689e-01,  1.5883e-01,\n",
              "           2.4719e-01, -1.7160e-01,  6.4810e-02, -1.7144e-01,  9.8137e-02,\n",
              "           4.0186e-01, -3.3446e-01, -2.0762e-01, -4.9168e-02, -9.3384e-02,\n",
              "          -4.9693e-02,  9.3713e-01, -6.3294e-02, -2.4665e-01,  7.7011e-02,\n",
              "           3.3627e-02,  8.5370e-02, -6.5803e-03, -2.8821e-01,  1.4815e-01,\n",
              "           3.7914e-01, -4.8487e-03,  5.6452e-01,  1.6520e-01,  1.9665e-02,\n",
              "           3.3245e-01,  4.7466e-01,  7.1260e-02,  3.1405e-01,  2.0111e+00,\n",
              "          -1.0623e-01,  1.0655e-01, -4.8103e-01,  1.5683e-01, -7.6471e-02,\n",
              "          -3.7718e-01,  9.6113e-02,  6.7271e-02,  1.2339e-02,  2.0651e-01,\n",
              "          -7.2450e-02, -1.0131e-01, -9.7565e-02, -7.9134e-02, -5.6600e-02,\n",
              "           1.6903e-01,  1.3422e-01,  5.2529e-02, -1.7230e-01, -1.0352e-01,\n",
              "           1.2343e-01,  8.5121e-03, -3.8394e-03, -2.7453e-01, -1.7124e-01,\n",
              "           2.2663e-01,  5.1563e-01,  1.4862e-01,  7.8980e-01, -1.0316e-01,\n",
              "          -6.4849e-02, -1.1567e-03,  9.1958e-02, -2.2270e-01, -6.1618e-03,\n",
              "          -4.5074e-02,  1.3819e-01, -2.1766e-01, -1.9249e-01,  1.5599e-01,\n",
              "           1.1054e-01,  7.2886e-02, -3.3339e-01, -4.5752e-02,  1.5805e-01,\n",
              "          -2.3977e-01,  3.0853e-01, -4.2159e-01, -1.8534e-01,  2.1538e-01,\n",
              "           2.2209e-01,  1.7802e-02, -4.5395e-01,  3.2455e-01, -9.8551e-02,\n",
              "          -1.0819e-01,  2.9297e-01,  1.5230e-01, -1.3803e-01, -2.3642e-01,\n",
              "          -3.6484e-01, -1.6297e-01, -5.7460e-02, -2.1219e-01,  1.7075e-01,\n",
              "          -2.4845e-01, -8.3459e-03,  4.5688e-01,  1.5428e-01, -2.1558e-02,\n",
              "           7.7812e-02,  5.8015e-03, -2.5498e-02,  4.5243e-02, -1.3895e-02,\n",
              "          -6.4855e-02, -7.5102e-02,  1.4741e-01,  4.4681e-03, -1.1164e-01,\n",
              "           7.0072e-02, -1.5407e-01, -1.2925e-01,  2.3428e-01, -3.5349e-02,\n",
              "           1.5790e-01,  1.2900e-01,  2.7447e-01, -7.3573e-02, -6.0172e-01,\n",
              "           8.5415e-02, -1.9698e-01,  1.6680e-02,  5.0192e-02, -3.8818e-02,\n",
              "           1.6162e-01, -3.9552e-03, -1.7488e-01, -3.3627e-01, -1.3020e-01,\n",
              "           3.9547e-03, -2.3022e-01,  9.7639e-02, -1.2283e-01, -7.3320e-02,\n",
              "          -5.6556e-01,  1.1258e-01,  1.5488e-01,  3.3684e-01,  3.0059e-01,\n",
              "          -1.6824e-01, -1.8131e-01,  2.4640e-01,  1.2341e-01, -5.0860e-02,\n",
              "           2.3878e-01,  2.6818e-01,  3.0219e-01, -7.8430e-02, -1.7515e-01,\n",
              "          -4.5851e-01,  2.1582e-01,  1.3144e-01, -2.8105e-01, -2.2085e-01,\n",
              "          -4.5232e-01, -2.1737e-01, -1.8654e-01,  1.9184e-01, -1.5920e-01,\n",
              "          -2.2145e-01,  1.7288e-01,  1.5782e-01,  1.8259e-01, -2.9243e-01,\n",
              "          -2.0978e-01,  1.4698e-01,  8.9676e-02, -2.4383e-02,  2.8531e-02,\n",
              "           1.3828e-01, -2.8093e-02,  1.6484e-01, -1.0339e-01,  1.3031e-01,\n",
              "           1.7394e-01, -7.8875e-04, -3.5895e-02,  3.5101e-02, -1.3389e-01,\n",
              "          -1.0964e-01, -1.9908e-01,  2.5516e-02,  5.1787e-02,  9.3587e-02,\n",
              "           7.3206e-02,  3.6243e-01, -1.3149e-01, -2.9984e-01, -1.0458e-01,\n",
              "          -1.5037e-01,  4.9874e-01,  2.4451e-01, -3.0587e-01, -1.0121e+00,\n",
              "          -1.2534e-01, -5.0260e-01,  3.3156e-02, -9.8725e+00, -1.4765e-01,\n",
              "          -4.5646e-01,  2.3530e-01,  3.3180e-01, -3.5983e-02, -1.3039e-01,\n",
              "          -1.8253e-01, -4.5071e-01, -5.4503e-04,  2.4911e-01,  4.9132e-01,\n",
              "          -4.6162e-02,  1.5817e-01,  2.9052e-01, -9.0415e-02, -1.2816e-01,\n",
              "          -3.1896e-01,  3.0699e-02, -2.9331e-01,  2.1541e-01,  1.3631e-01,\n",
              "           3.4031e-01, -2.2842e-01,  1.9141e-01,  1.9782e-02, -3.5247e-01,\n",
              "           6.6401e-02,  8.4198e-02, -3.8714e-01,  6.2129e-02, -1.1215e-01,\n",
              "          -1.7133e-01,  4.0676e-02,  2.8888e-01, -4.3132e-02,  3.4606e-01,\n",
              "           4.8388e-01,  1.0213e-01,  9.9923e-02,  1.5812e-01,  7.7775e-02,\n",
              "          -3.9398e-01,  3.5331e-02,  1.4108e-01, -5.0305e-02,  6.8406e-03,\n",
              "           9.2810e-02, -3.2515e-01,  1.3171e-01,  1.1585e-01,  9.3684e-02,\n",
              "          -6.8370e-02,  2.6736e-01,  9.6829e-02, -1.2933e-01,  1.1291e-01,\n",
              "          -1.3767e-01,  2.5227e-02,  1.0654e-01, -3.0252e-01, -2.5377e-01,\n",
              "           1.4633e-01, -3.2594e-01,  4.2952e-01, -2.5261e-01,  7.7717e-03,\n",
              "          -1.7034e-01, -4.8605e-01, -8.4991e-02, -9.9368e-02, -1.2995e-01,\n",
              "          -4.9041e-02, -7.7356e-01, -3.8584e-02, -1.1264e-01,  3.2188e-01,\n",
              "           6.1606e-02, -1.9826e-01,  2.0261e-01, -2.6993e-02,  1.5200e-01,\n",
              "          -1.4749e-01, -7.5026e-02, -2.8378e-01, -3.2707e-01, -3.2447e-01,\n",
              "          -4.3258e-01, -3.0898e-01, -4.4465e-01,  2.6726e-01, -9.4265e-03,\n",
              "          -1.2914e-01,  1.7132e-01, -2.2622e-01,  7.2100e-03, -2.2591e-01,\n",
              "          -2.6903e-01, -9.3020e-03,  1.6091e-01,  1.4475e-01, -9.5306e-02,\n",
              "          -2.0140e-02, -1.3865e-01, -3.0443e-02, -2.9879e-01,  3.4183e-01,\n",
              "           2.5470e-01, -2.1896e-01, -3.9613e-02, -4.0494e-02,  2.3707e-01,\n",
              "           5.5678e-01,  4.0869e-02,  1.3786e-01,  8.0530e-02, -2.3892e-01,\n",
              "           7.5601e-02,  3.1929e-01, -2.8498e-01, -3.4305e-01,  5.7910e-03,\n",
              "           1.4315e-01, -1.8989e-01, -1.8358e-01, -8.9879e-02, -1.0880e-01,\n",
              "          -8.2003e-02, -2.0570e-02, -1.3449e-01,  3.8939e-01,  1.4088e-01,\n",
              "           8.3985e-02,  1.1752e-01,  2.6090e-03,  8.5475e-01,  1.2420e-01,\n",
              "          -1.3138e-01, -5.2526e-01,  4.8989e-01,  1.9725e-01, -8.6564e-02,\n",
              "           8.0499e-02,  1.1611e-02, -1.5507e-01,  2.3971e-01, -6.0459e-02,\n",
              "           3.9858e-02, -1.7479e-01,  8.9458e-02,  9.8171e-02,  1.6493e-01,\n",
              "          -8.7731e-02,  1.1096e-01, -1.4591e-01, -1.7570e-01, -4.2716e-01,\n",
              "           1.2262e-01,  2.8811e-01, -2.7558e-01,  2.6209e-01,  1.4900e-01,\n",
              "          -5.8411e-01, -1.4156e-01,  2.2473e-01,  1.5102e-02, -2.0862e-01,\n",
              "          -3.0184e-02,  4.1301e-01,  7.8002e-02,  2.0597e-01, -2.4332e-01,\n",
              "           3.6197e-01,  3.4705e-01, -6.0835e-01,  1.4302e-01, -2.3687e-01,\n",
              "           2.2425e-01,  4.6946e-01, -1.5421e-01, -5.3277e-02,  2.8841e-01,\n",
              "          -3.2493e-02,  2.2498e-01,  4.1835e-02,  2.8270e-01,  4.8546e-01,\n",
              "           1.3009e-01,  2.1509e-01,  2.7664e-01, -3.8473e-02, -2.9213e-01,\n",
              "           1.8622e-02, -6.2021e-02,  2.6150e-02, -3.7782e-01, -2.4250e-01,\n",
              "          -1.0378e-01, -5.7818e-02, -1.1856e-01,  2.6245e-02, -2.9676e-01,\n",
              "           1.2054e-02, -8.5744e-02, -3.1815e-01, -1.8576e-01,  1.7116e-01,\n",
              "          -1.9121e-01,  4.0884e-02,  1.6745e-01,  1.8404e-02,  4.0639e-01,\n",
              "          -1.0328e-01,  1.5313e-01,  3.6880e-01,  3.1587e-01,  1.1102e-01,\n",
              "           2.2318e-01, -1.6020e-01, -3.7438e-01, -3.7908e-01,  2.9474e-01,\n",
              "           1.7695e-01, -4.6959e-01, -2.9682e-01,  2.0369e-01,  1.9354e-01,\n",
              "          -8.3632e-02, -9.8848e-04, -1.9443e-01, -5.8399e-03, -5.1627e-01,\n",
              "          -2.3038e-01,  2.6794e-01,  2.8452e-02,  7.5576e-02, -6.6650e-02,\n",
              "           7.0233e-01, -1.0030e-02,  9.1951e-02, -4.3881e-01, -1.5380e-01,\n",
              "          -2.5235e-01, -2.0908e-01,  1.0592e-01, -4.5228e-02, -6.2955e-02,\n",
              "          -1.8957e-01, -2.3013e-01, -7.1754e-03,  4.0132e-02,  1.8004e-01,\n",
              "          -5.0780e-01,  4.7297e-01,  4.1509e-01,  1.0431e-01,  6.5537e-02,\n",
              "          -3.5222e-01, -8.2245e-02, -8.4997e-02,  3.0171e-01,  1.3283e-01,\n",
              "          -2.6492e-02,  2.1067e-01, -4.8952e-02,  3.8718e-01,  1.8871e-01,\n",
              "           1.6913e-01,  6.7295e-02,  4.5841e-02,  2.2245e-01, -3.0390e-01,\n",
              "           1.4245e-01,  7.2655e-02, -1.6397e-01,  1.3979e-01,  9.7345e-03,\n",
              "          -1.9964e-01, -2.5981e-01, -1.1955e-01,  2.4887e-01,  2.4902e-01,\n",
              "          -1.8113e-01,  1.2033e-01, -1.6329e-01,  2.9328e-02,  1.0791e-01,\n",
              "          -1.5764e-01,  1.0569e-01,  3.0933e-02, -9.5662e-02,  3.1021e-02,\n",
              "          -2.3543e-01,  1.5888e-01,  2.4887e-01,  3.4879e-01,  6.8724e-02,\n",
              "           8.6997e-02, -4.0612e-01,  2.8129e-01, -2.0029e-01,  2.9708e-01,\n",
              "          -3.9570e-01, -4.2647e-01,  1.1754e-02,  1.0792e-01, -1.3142e-01,\n",
              "          -3.1385e-01,  1.2849e-02,  1.7590e-01, -1.1450e-01,  6.4763e-02,\n",
              "          -3.6994e-02,  2.4056e-01, -3.0003e-02,  1.2700e-01, -1.1027e-02,\n",
              "           3.4422e-01,  2.4624e-01,  5.1014e-02,  2.5517e-01, -1.6424e-01,\n",
              "          -4.2899e-03, -2.3092e-01, -8.8466e-02,  3.3373e-01,  2.4547e-01,\n",
              "          -8.3689e-02,  1.1144e-01,  7.7730e-02,  1.6312e-01, -8.1666e-02,\n",
              "           1.2480e-01,  2.7076e-01,  6.1247e-02, -1.3898e-02,  2.3451e-01,\n",
              "           2.0124e-01, -5.9847e-01, -1.1953e-01, -9.7514e-03,  2.3583e-01,\n",
              "           2.3237e-01, -1.3167e-01,  4.5819e-01,  1.1195e-01,  4.2866e-02,\n",
              "           3.9910e-02,  1.4337e-02, -2.9913e-01,  2.5855e-01, -3.3853e-01,\n",
              "          -8.3409e-03,  1.5570e-01, -5.8240e-01, -4.0177e-01, -4.8221e-02,\n",
              "           8.7457e-02, -1.3467e-01, -2.8793e-02, -2.0562e-01,  3.2005e-01,\n",
              "          -2.2560e-02, -1.1776e-01, -3.8917e-01, -2.8999e-02, -1.0558e-01,\n",
              "           8.0744e-02,  2.0614e-02, -3.9955e-02,  1.9171e-01,  5.4962e-01,\n",
              "          -2.4687e-01,  3.0917e-01, -4.7476e-01,  1.0438e-02, -7.9749e-02,\n",
              "           2.5434e-02, -2.3281e-01,  1.5984e-02, -1.7223e-01,  3.0593e-02,\n",
              "          -1.4247e-01, -3.1527e-01,  6.4103e-02,  3.6070e-01, -3.4008e-01,\n",
              "           1.6096e-01,  1.4664e-01, -3.8048e-02, -9.2143e-02, -4.5189e-01,\n",
              "          -2.4973e-01, -8.3323e-04,  6.1688e-02, -2.3418e-01,  3.2327e-01,\n",
              "          -1.4682e-01,  3.7277e-01,  4.1984e-02,  6.3710e-02, -5.6634e-02,\n",
              "           1.9673e-01, -6.1467e-02,  4.6020e-01,  3.0188e-01, -1.6486e-01,\n",
              "          -1.7953e-01, -7.2427e-02,  1.2509e-01, -2.9136e-01, -1.0370e-01,\n",
              "           1.0291e-02,  2.1952e-01, -2.1826e-01, -3.5593e-01, -1.5267e-01,\n",
              "          -7.3245e-02, -9.0738e-02, -1.1353e-01,  3.5898e-01,  2.5535e-01,\n",
              "          -4.0211e-01,  4.5177e-01,  3.2391e-02, -5.5832e-01, -2.6706e-01,\n",
              "          -1.8720e-01,  2.3091e-01,  1.8718e-01, -2.2046e-01,  9.5463e-02,\n",
              "          -3.7606e-01,  2.1935e-01, -3.5342e-01, -1.9544e-01, -2.3915e-01,\n",
              "           1.1715e-01,  2.5987e-01,  7.8824e-03,  4.8455e-01, -4.7839e-02,\n",
              "          -2.5575e-01, -1.9533e-01, -1.6827e-01, -9.6855e-02, -1.7981e-01,\n",
              "           8.1178e-02, -8.7572e-02,  1.3709e-01,  3.3769e-01, -4.0503e-01,\n",
              "          -3.0069e-02, -1.4869e-01,  1.4334e-01, -2.2520e-01, -7.9778e-03,\n",
              "           1.9458e-01, -2.1721e-02,  2.7907e-02]], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CLS_vectors_list[0][4].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqNERjHcQWkn",
        "outputId": "9c55f03b-a701-4621-ef1a-9636f7302390"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataloader"
      ],
      "metadata": {
        "id": "8-t7cRSS-NRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un sampler secuencial\n",
        "# attentions_list = dataset\n",
        "# SequentialSampler does not perform any shuffling or random selection of items.\n",
        "sampler = SequentialSampler(CLS_vectors_list)\n",
        "\n",
        "# Definir el tamaño del lote\n",
        "batch_size = 12 # always 12, because it is the number of attention layers, 12 layers for the same sentence\n",
        "\n",
        "# Crear el DataLoader sin un BatchSampler\n",
        "dataloader = DataLoader(CLS_vectors_list, batch_size=batch_size, sampler=sampler)"
      ],
      "metadata": {
        "id": "dSzUvRBd7oaW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataloader) #1379 OK because there are 1379 sentences, 1 batch = 1 same sentence , 12 elements in the batch because there are 12 layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQmpqNtb9cNp",
        "outputId": "8d7ad0da-b115-4c14-e6a3-721aa702a93e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1379"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sr = next(iter(dataloader))\n",
        "sr[0] # ids (num_sent, num_layer)\n",
        "sr[1] # similarity label\n",
        "sr[2].shape\n",
        "sr[3].shape\n",
        "sr[4].shape #[batch_size, len_sentence, input_size] with attentions ([12,289,12])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RUVAl03NZqO",
        "outputId": "a5d34a9c-50da-4fe3-8b1f-2639eac67ea4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12, 1, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "lh2_LvEAFOuX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(model, iterator, optimizer, criterion, device=device, clip = 1.0):\n",
        "    #Training loop\n",
        "    model.train()\n",
        "    loss_sum = 0\n",
        "    seed = 42\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    #torch.cuda.set_device(0)\n",
        "\n",
        "    for i, (_,_,_,_,input) in enumerate(iterator):\n",
        "        optimizer.zero_grad()\n",
        "        output, _ = model(input.to(device))\n",
        "        loss = criterion(output, input)\n",
        "        loss.backward()\n",
        "        #prevent gradients from exploding\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        #Update params\n",
        "        optimizer.step()\n",
        "        loss_sum += loss.item()\n",
        "\n",
        "    epoch_train_loss = loss_sum * batch_size / len(iterator)\n",
        "\n",
        "    return epoch_train_loss"
      ],
      "metadata": {
        "id": "cJcjfZz_-uD3"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraer el vector latente fijo de cada elemento del batch\n",
        "def extract_latent_vectors(model, dataloader, device, model_type='RNN'):\n",
        "    model.eval()\n",
        "    vector_representations = {}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (id,s,label,dim,input) in dataloader:\n",
        "            latent_vectors = []\n",
        "            if model_type == 'RNN':\n",
        "              _, (latent_representation, _) = model.encoder(input)\n",
        "              latent = latent_representation.squeeze(0)\n",
        "            else:\n",
        "              latent_representation = model.encoder(input)\n",
        "              latent = latent_representation.squeeze(0).squeeze(1)\n",
        "            tuples = list(zip(id[0].tolist(), id[1].tolist()))\n",
        "            #latent = latent_representation.squeeze(0)\n",
        "            for i in range(latent.size(0)):\n",
        "              latent_vectors.append(latent[i].cpu().numpy())\n",
        "              vector_representations[tuples[i]] = { 'vector' : latent[i].cpu().numpy(), 'sequence': s, 'label': label, 'dimension':dim}\n",
        "\n",
        "    return vector_representations"
      ],
      "metadata": {
        "id": "hZ3fWPpSI-pq"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearAutoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim):\n",
        "        super(LinearAutoencoder, self).__init__()\n",
        "        dims = [768, 512, 256, 128, 32, 8, 2]\n",
        "\n",
        "        layer_dims= [i for i in dims if i > latent_dim ]\n",
        "        layer_dims.append(latent_dim)\n",
        "\n",
        "        encoder_layers = []\n",
        "        decoder_layers = []\n",
        "\n",
        "        for i in range(len(layer_dims) - 1):\n",
        "            encoder_layers.append(nn.Linear(layer_dims[i], layer_dims[i+1]))\n",
        "            encoder_layers.append(nn.GELU())\n",
        "            decoder_layers.insert(0, nn.Linear(layer_dims[i+1], layer_dims[i]))\n",
        "            decoder_layers.insert(0, nn.GELU())\n",
        "\n",
        "        self.encoder = nn.Sequential(*encoder_layers)\n",
        "        self.decoder = nn.Sequential(*decoder_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Codificación\n",
        "        encoded = self.encoder(x)\n",
        "        # Decodificación\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded, encoded\n"
      ],
      "metadata": {
        "id": "CspMdXG6P9dc"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 10 #500\n",
        "best_valid_loss = float('inf')\n",
        "model_name = 'Autoencoder_Lineal_CLS'\n",
        "train_loss_values = []\n",
        "history = {\"train\": {\"loss\": []}}\n",
        "\n",
        "input_size = 768  #due to 768 dimensión of BERT\n",
        "hidden_size = 64  # size of fixed vector #laten dim\n",
        "learning_rate = 0.00025 #0.00025 #0.0007\n",
        "\n",
        "seed = 42\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "\n",
        "#model = AttentionLinearAutoencoder(input_size, hidden_size)\n",
        "model = LinearAutoencoder(input_size, hidden_size)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    epoch_train_loss = train_loop(model.to(device),dataloader,optimizer,criterion,device)\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    train_loss_values.append(epoch_train_loss)\n",
        "\n",
        "    history[\"train\"][\"loss\"].append(epoch_train_loss)\n",
        "\n",
        "    print('-' * 80)\n",
        "    #print(f'Epoch: {epoch+1:03}/{NUM_EPOCHS} | Epoch Time: {epoch_mins}m {epoch_secs}s | Train loss: {epoch_train_loss:.4f} | Train acc: {epoch_train_acc:.4f} | Dev loss: {epoch_dev_loss:.4f} | Dev acc: {epoch_dev_acc:.4f}')\n",
        "    print(f'Epoch: {epoch+1:03}/{NUM_EPOCHS} | Epoch Time: {epoch_mins}m {epoch_secs}s | Train loss: {epoch_train_loss:.4f}')\n"
      ],
      "metadata": {
        "id": "1VTc_w-0EI_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18372750-2faf-416b-8d4b-441b183caffd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Epoch: 001/10 | Epoch Time: 0m 6s | Train loss: 1.0422\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 002/10 | Epoch Time: 0m 4s | Train loss: 0.5931\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 003/10 | Epoch Time: 0m 4s | Train loss: 0.5575\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 004/10 | Epoch Time: 0m 5s | Train loss: 0.5390\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 005/10 | Epoch Time: 0m 4s | Train loss: 0.5206\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 006/10 | Epoch Time: 0m 4s | Train loss: 0.5046\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 007/10 | Epoch Time: 0m 5s | Train loss: 0.4968\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 008/10 | Epoch Time: 0m 4s | Train loss: 0.4868\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 009/10 | Epoch Time: 0m 4s | Train loss: 0.4796\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 010/10 | Epoch Time: 0m 5s | Train loss: 0.4742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_representations = extract_latent_vectors(model, dataloader, device, model_type='Linear')"
      ],
      "metadata": {
        "id": "rmqDO8T-doKJ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_representations[(0,0)]['vector'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "387PV-bDzyzd",
        "outputId": "eaab65d1-b60f-417e-ec06-5eb7b910d167"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64,)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el diccionario en un archivo\n",
        "torch.save(vector_representations, root_drive + BERT_PATH + '_vector_representations_CLS_Linear64.pth')"
      ],
      "metadata": {
        "id": "hAkzCvQ8p4OQ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_representations = torch.load(root_drive + BERT_PATH + '_vector_representations_CLS_Linear.pth')"
      ],
      "metadata": {
        "id": "AmOB1Djot8z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vector_representations) #(num_sentence,layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32RlZGvQo8XE",
        "outputId": "03c02986-ce9f-48ae-adbc-61470b388005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16548"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_representations_per_layer(num_sentences, vector_representations, layers = 12):\n",
        "  vectors_per_layer = {}\n",
        "  labels = {}\n",
        "  for l in range(layers):\n",
        "    #vectors_per_layer[l] = np.array([vector_representations[(i,l)]['vector'].detach().numpy() for i in range(num_sentences)])\n",
        "    vectors_per_layer[l] = np.array([vector_representations[(i,l)]['vector'] for i in range(num_sentences)])\n",
        "  labels = { i: vector_representations[(i,0)]['label'][0].item() for i in range(num_sentences)}\n",
        "  return vectors_per_layer, labels"
      ],
      "metadata": {
        "id": "XQ-dXKeYTHok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectors_per_layer, labels = get_representations_per_layer(num_sentences, vector_representations)"
      ],
      "metadata": {
        "id": "mBvM7amZVhFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el diccionario en un archivo\n",
        "torch.save(vectors_per_layer, root_drive + BERT_PATH + str(hidden_size) + '_vectors_per_layer_CLS_LSTM.pth')"
      ],
      "metadata": {
        "id": "iZJHKzT9CB5x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}