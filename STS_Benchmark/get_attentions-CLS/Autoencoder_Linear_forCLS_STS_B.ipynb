{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uq8sbfogrQJy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import re\n",
        "import shutil\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.utils.data.sampler import SequentialSampler\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import silhouette_score, jaccard_score, f1_score, homogeneity_completeness_v_measure, adjusted_rand_score\n",
        "from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score, pairwise_distances\n",
        "import numpy as np\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08HLAANDw06m",
        "outputId": "2fd3cde7-3594-4fe0-ccf9-903131a01512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O Stsbenchmark.tar.gz http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz\n",
        "shutil.unpack_archive('./Stsbenchmark.tar.gz', extract_dir='./', format='gztar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4BiyNxQhY4T",
        "outputId": "3b6176b9-7628-4d20-db12-74aa6abe3402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-09 17:23:22--  http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz\n",
            "Resolving ixa2.si.ehu.es (ixa2.si.ehu.es)... 158.227.106.100\n",
            "Connecting to ixa2.si.ehu.es (ixa2.si.ehu.es)|158.227.106.100|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: http://ixa2.si.ehu.eus/stswiki/images/4/48/Stsbenchmark.tar.gz [following]\n",
            "--2023-11-09 17:23:22--  http://ixa2.si.ehu.eus/stswiki/images/4/48/Stsbenchmark.tar.gz\n",
            "Resolving ixa2.si.ehu.eus (ixa2.si.ehu.eus)... 158.227.106.100\n",
            "Connecting to ixa2.si.ehu.eus (ixa2.si.ehu.eus)|158.227.106.100|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 409630 (400K) [application/x-gzip]\n",
            "Saving to: ‘Stsbenchmark.tar.gz’\n",
            "\n",
            "Stsbenchmark.tar.gz 100%[===================>] 400.03K   411KB/s    in 1.0s    \n",
            "\n",
            "2023-11-09 17:23:23 (411 KB/s) - ‘Stsbenchmark.tar.gz’ saved [409630/409630]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getSTSBenchmarkSents(filename='sts-train.csv', root='stsbenchmark/', encoding='utf-8'):\n",
        "  f = open(root+filename, 'r', encoding=encoding)\n",
        "  s1, s2, target = [], [], []\n",
        "  for line in f:\n",
        "    example = re.split(r'\\t+', line)\n",
        "    if len(example) > 7:\n",
        "      example = example[:-2]\n",
        "    s2.append(example[-1])\n",
        "    s1.append(example[-2])\n",
        "    target.append(float(example[-3]))\n",
        "  print(\"{} samples: {}\".format(filename, len(target)))\n",
        "  return s1, s2, target"
      ],
      "metadata": {
        "id": "jJCuyxk3hmEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s1_test,s2_test,target_test= getSTSBenchmarkSents(filename='sts-test.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EcrzLWThrkg",
        "outputId": "751b6b01-e1e5-45d9-a87d-46adfe1a9f20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sts-test.csv samples: 1379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BERT_PATH = \"bert-base-uncased\"\n",
        "root_drive = '/content/drive/MyDrive/Tesis/STS_Benchmark/transformer_tunned_BERT/uncase_base/'"
      ],
      "metadata": {
        "id": "CfBedtrSv9bN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Device: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKElhIi44LJD",
        "outputId": "938fdcb8-8d1b-4ad0-d3d3-80c07bdca9d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#(num_sent, num_capa, num_cabezal)\n",
        "CLS_vectors = torch.load(root_drive + BERT_PATH + '_all_CLS_outputs_vectors.pth', map_location=torch.device(device))"
      ],
      "metadata": {
        "id": "tknswpDAwi-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLS_vectors[(0,0)]['vectors'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAexbnf3I632",
        "outputId": "7902bf63-45b5-4a99-f0af-f326ce8304a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layers = 12\n",
        "heads = 12\n",
        "num_sentences = list(CLS_vectors.keys())[-1][0]+1\n",
        "CLS_vectors_list = []\n",
        "\n",
        "for i in range(num_sentences):\n",
        "  for j in range(layers):\n",
        "    CLS_vectors_list.append(((i,j),CLS_vectors[(i,j)]['sequence'],CLS_vectors[(i,j)]['label'],CLS_vectors[(i,j)]['dimension'],CLS_vectors[(i,j)]['vectors']))"
      ],
      "metadata": {
        "id": "L23MV8rfAAxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLS_vectors_list[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GKJ74Gwpd-R",
        "outputId": "f5a26384-8468-4b86-fe06-2afce7a83594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((0, 0),\n",
              " 's1: A girl is styling her hair. s2: A girl is brushing her hair.',\n",
              " 2.5,\n",
              " 17,\n",
              " tensor([[ 1.3366e-02,  4.4970e-02, -2.1637e-01, -3.2843e-01,  2.6883e-01,\n",
              "           3.4715e-02, -1.9444e-01, -1.1049e-02, -1.1818e-01, -3.9399e-01,\n",
              "           3.0634e-02, -5.8748e-02,  1.3790e-01, -1.0854e-01, -1.1573e-01,\n",
              "           4.3709e-01,  4.1830e-01,  2.6936e-01, -8.8575e-02, -5.6118e-01,\n",
              "          -5.0836e-01, -3.3846e-01,  2.8790e-02, -1.9942e-01, -1.1913e-01,\n",
              "          -2.5059e-01, -3.8456e-01,  4.5932e-02,  4.7195e-02, -1.2446e-01,\n",
              "          -1.1421e-01, -1.6876e-01,  1.7933e-01,  1.6506e-01, -3.5994e-01,\n",
              "           6.3980e-02, -3.9983e-01,  1.9067e-01, -2.0721e-01,  2.4676e-01,\n",
              "           3.1398e-01, -1.7534e-01, -1.0620e-01,  1.6748e-01,  1.0974e-01,\n",
              "           9.0651e-02, -1.5393e+00, -1.7551e-02,  5.5214e-01, -2.3338e-01,\n",
              "           1.6909e-01,  5.9467e-02, -2.3357e-01,  8.8209e-01,  6.5783e-02,\n",
              "          -1.4159e-01, -2.2780e-01,  1.0475e-01,  2.7281e-01, -2.2613e-01,\n",
              "           1.9078e-02, -1.3809e-02,  2.7687e-01,  3.7127e-02, -2.5137e-01,\n",
              "           4.0342e-01,  1.0888e-01, -2.1168e-01, -2.4087e-02,  4.2044e-02,\n",
              "           7.7703e-03, -1.0821e-03, -3.6651e-01, -4.7638e-01,  2.4341e-01,\n",
              "          -5.7833e-02, -2.6765e-01,  2.3241e-01,  2.5562e-01,  3.3041e-01,\n",
              "          -3.0377e-01, -7.5887e-02,  7.3283e-02,  2.4753e-01,  2.8733e-01,\n",
              "           2.4159e-01,  2.5090e-01,  2.8659e-01, -5.0211e-02,  2.4035e-01,\n",
              "          -3.6193e-01, -4.6894e-02, -2.0913e-01,  2.8753e-02,  7.0249e-02,\n",
              "           1.4872e-01,  5.3545e-01, -3.1319e-01, -1.6712e-01, -2.6523e-01,\n",
              "           2.0126e-02, -1.0949e-01,  1.5555e-01, -7.5298e-02, -4.4586e-01,\n",
              "           3.9126e-01,  2.4918e-02, -1.0390e-01,  8.6138e-02,  1.7019e-01,\n",
              "           2.8112e-01, -1.6113e-01,  2.0060e-02, -1.7760e-01,  9.1851e-02,\n",
              "           4.1034e-01, -3.2049e-01, -2.0413e-01, -5.4218e-02, -5.9541e-02,\n",
              "          -7.9522e-02,  9.2266e-01, -6.3348e-02, -2.3412e-01,  5.0652e-02,\n",
              "           2.2754e-02,  9.2640e-02, -5.9283e-02, -2.8026e-01,  1.5969e-01,\n",
              "           3.7505e-01,  1.4483e-02,  5.2963e-01,  1.5437e-01, -2.4282e-03,\n",
              "           3.5534e-01,  4.5313e-01,  5.6341e-02,  2.8499e-01,  1.9948e+00,\n",
              "          -9.7163e-02,  1.2551e-01, -4.6749e-01,  1.8835e-01, -1.2568e-01,\n",
              "          -3.7155e-01,  9.4080e-02,  5.3741e-02,  1.6287e-02,  2.0011e-01,\n",
              "          -9.3409e-02, -6.4552e-02, -5.9014e-02, -7.7613e-02, -3.7977e-02,\n",
              "           1.5250e-01,  1.5335e-01,  5.3374e-02, -1.4183e-01, -8.5384e-02,\n",
              "           1.3371e-01, -2.6035e-02, -6.1871e-04, -2.7482e-01, -1.4005e-01,\n",
              "           2.2240e-01,  4.8478e-01,  1.6444e-01,  7.8498e-01, -7.4962e-02,\n",
              "          -5.4402e-02,  1.9818e-03,  7.2542e-02, -2.2120e-01, -8.1714e-03,\n",
              "          -3.2649e-02,  1.2988e-01, -2.3693e-01, -1.6599e-01,  1.6207e-01,\n",
              "           1.2483e-01,  7.9260e-02, -3.2821e-01, -6.9188e-03,  1.6208e-01,\n",
              "          -2.1776e-01,  3.1775e-01, -3.9095e-01, -1.8376e-01,  2.1218e-01,\n",
              "           2.0695e-01,  3.5219e-02, -4.3276e-01,  2.9418e-01, -1.0515e-01,\n",
              "          -1.1886e-01,  2.6476e-01,  1.4377e-01, -1.0968e-01, -2.3026e-01,\n",
              "          -3.7732e-01, -1.6594e-01, -8.1956e-02, -1.9302e-01,  1.8249e-01,\n",
              "          -2.0892e-01, -4.1856e-02,  4.1895e-01,  1.6175e-01, -1.2888e-02,\n",
              "           1.0795e-01,  2.3546e-02, -1.7487e-02,  5.0752e-02, -7.6361e-03,\n",
              "          -7.5811e-02, -8.6322e-02,  1.4715e-01,  4.1496e-03, -1.2043e-01,\n",
              "           5.7725e-02, -1.2988e-01, -1.2794e-01,  2.3264e-01,  1.1353e-02,\n",
              "           1.4942e-01,  1.4291e-01,  3.0399e-01, -1.0101e-01, -5.7384e-01,\n",
              "           7.0094e-02, -1.7526e-01,  1.5261e-02,  5.2028e-02, -4.3566e-02,\n",
              "           1.8879e-01,  6.9454e-03, -1.5622e-01, -3.1834e-01, -1.5671e-01,\n",
              "           1.9726e-02, -2.3722e-01,  9.1811e-02, -1.2671e-01, -4.1349e-02,\n",
              "          -5.6327e-01,  1.1370e-01,  1.6299e-01,  3.0379e-01,  3.0600e-01,\n",
              "          -1.5217e-01, -1.5598e-01,  2.2519e-01,  1.3250e-01, -3.7618e-02,\n",
              "           2.2382e-01,  2.6000e-01,  2.8009e-01, -6.2816e-02, -1.6530e-01,\n",
              "          -4.2948e-01,  2.1899e-01,  1.6876e-01, -2.5217e-01, -2.3122e-01,\n",
              "          -4.3579e-01, -2.0297e-01, -1.9977e-01,  1.9908e-01, -1.7648e-01,\n",
              "          -2.4345e-01,  1.8237e-01,  1.5257e-01,  2.0201e-01, -2.7993e-01,\n",
              "          -1.9273e-01,  1.4150e-01,  1.2100e-01, -1.8515e-02,  3.2114e-02,\n",
              "           1.7936e-01, -6.3275e-02,  1.4373e-01, -1.6503e-01,  1.3539e-01,\n",
              "           1.8369e-01,  1.0891e-02, -3.3772e-02,  2.4969e-02, -1.0422e-01,\n",
              "          -1.2204e-01, -1.7160e-01,  2.8673e-02,  6.7599e-02,  1.1149e-01,\n",
              "           9.6529e-02,  3.9039e-01, -1.4949e-01, -2.9466e-01, -1.0825e-01,\n",
              "          -1.4585e-01,  4.4016e-01,  2.3982e-01, -3.0082e-01, -1.0227e+00,\n",
              "          -1.2143e-01, -4.7138e-01,  3.1425e-02, -9.9198e+00, -1.6917e-01,\n",
              "          -4.2679e-01,  2.1791e-01,  3.2133e-01, -1.4489e-02, -1.3293e-01,\n",
              "          -1.5845e-01, -4.4861e-01,  2.5328e-03,  2.5766e-01,  4.9418e-01,\n",
              "          -4.0746e-02,  1.8603e-01,  2.5537e-01, -7.1739e-02, -1.2795e-01,\n",
              "          -3.0123e-01,  1.2319e-02, -2.6447e-01,  2.0923e-01,  1.0613e-01,\n",
              "           3.1948e-01, -2.7839e-01,  1.6128e-01,  1.5274e-02, -3.3914e-01,\n",
              "           7.5671e-02,  9.5483e-02, -3.7359e-01,  5.3302e-02, -1.2824e-01,\n",
              "          -1.4178e-01,  1.3444e-02,  2.7793e-01, -5.1618e-02,  3.1854e-01,\n",
              "           5.2055e-01,  9.5752e-02,  6.5816e-02,  1.3445e-01,  5.7546e-02,\n",
              "          -3.9258e-01,  3.3548e-02,  1.5075e-01, -5.3708e-02, -1.8564e-02,\n",
              "           8.3197e-02, -3.3961e-01,  1.3031e-01,  1.2398e-01,  6.6174e-02,\n",
              "          -8.0499e-02,  2.5352e-01,  8.7653e-02, -1.3290e-01,  1.2581e-01,\n",
              "          -1.5871e-01,  4.8443e-02,  1.3994e-01, -2.9965e-01, -2.4118e-01,\n",
              "           1.1506e-01, -3.2766e-01,  4.2550e-01, -2.6833e-01, -7.4173e-04,\n",
              "          -1.7250e-01, -5.1620e-01, -1.0800e-01, -9.4531e-02, -1.1641e-01,\n",
              "          -3.0526e-02, -7.7764e-01, -2.8800e-02, -1.2682e-01,  2.6371e-01,\n",
              "           3.7315e-02, -1.7796e-01,  2.1037e-01, -3.4599e-02,  1.6556e-01,\n",
              "          -1.6903e-01, -8.9705e-02, -2.8919e-01, -2.9640e-01, -3.3588e-01,\n",
              "          -4.3278e-01, -2.9292e-01, -4.5689e-01,  2.4514e-01, -2.9458e-02,\n",
              "          -1.3141e-01,  1.1420e-01, -2.2643e-01, -2.6110e-02, -2.2702e-01,\n",
              "          -2.5992e-01, -1.6477e-02,  1.7832e-01,  1.3747e-01, -7.3906e-02,\n",
              "          -2.1465e-02, -1.3404e-01, -1.6317e-02, -2.8059e-01,  3.6307e-01,\n",
              "           2.4038e-01, -2.1263e-01, -7.0644e-02, -4.6655e-02,  2.2321e-01,\n",
              "           5.5327e-01,  6.3641e-02,  1.5127e-01,  7.7412e-02, -2.4578e-01,\n",
              "           4.3676e-02,  2.8371e-01, -2.9232e-01, -3.3830e-01, -1.1610e-02,\n",
              "           1.4269e-01, -1.8133e-01, -1.4795e-01, -9.0535e-02, -9.4270e-02,\n",
              "          -6.2744e-02,  3.3707e-03, -1.3148e-01,  3.6776e-01,  1.5839e-01,\n",
              "           7.1392e-02,  1.0878e-01,  4.7547e-04,  8.3035e-01,  1.2055e-01,\n",
              "          -1.6567e-01, -4.7521e-01,  4.7057e-01,  1.8248e-01, -8.7973e-02,\n",
              "           7.9666e-02,  6.6440e-03, -1.5677e-01,  2.4851e-01, -6.4860e-02,\n",
              "           1.0915e-02, -1.4472e-01,  9.6002e-02,  6.9390e-02,  1.6768e-01,\n",
              "          -7.3616e-02,  1.1754e-01, -1.4078e-01, -1.6271e-01, -4.1298e-01,\n",
              "           1.0997e-01,  2.8417e-01, -2.6103e-01,  2.6156e-01,  1.8107e-01,\n",
              "          -5.9557e-01, -1.2684e-01,  2.1451e-01,  2.6874e-02, -1.7074e-01,\n",
              "          -3.9880e-02,  4.1413e-01,  1.1587e-01,  2.2307e-01, -2.4686e-01,\n",
              "           3.6435e-01,  3.2441e-01, -5.7108e-01,  1.3389e-01, -2.5574e-01,\n",
              "           1.9323e-01,  4.7007e-01, -1.6000e-01, -6.1012e-02,  2.7840e-01,\n",
              "          -4.0791e-03,  2.1196e-01,  1.7836e-02,  2.6773e-01,  4.6690e-01,\n",
              "           1.0962e-01,  2.2605e-01,  2.6528e-01, -3.7340e-02, -2.4740e-01,\n",
              "          -2.8442e-03, -7.0379e-02, -7.9679e-03, -3.8250e-01, -2.3552e-01,\n",
              "          -9.6109e-02, -5.7300e-02, -8.6679e-02,  4.9614e-03, -2.9204e-01,\n",
              "           2.6268e-02, -9.1151e-02, -2.9395e-01, -1.8609e-01,  1.6237e-01,\n",
              "          -1.9009e-01,  4.0621e-02,  1.5914e-01,  4.7550e-02,  3.8241e-01,\n",
              "          -1.0465e-01,  1.7586e-01,  3.5489e-01,  3.1163e-01,  1.2603e-01,\n",
              "           2.0263e-01, -1.2359e-01, -3.2290e-01, -3.6912e-01,  2.5547e-01,\n",
              "           1.5434e-01, -4.7118e-01, -3.1386e-01,  1.7767e-01,  1.7991e-01,\n",
              "          -8.2858e-02,  4.6053e-03, -1.8935e-01, -1.2607e-02, -4.8439e-01,\n",
              "          -2.0914e-01,  2.4593e-01,  2.3148e-03,  7.0095e-02, -2.1298e-02,\n",
              "           7.0454e-01,  1.4294e-03,  9.6280e-02, -4.1974e-01, -1.3933e-01,\n",
              "          -2.2996e-01, -2.0024e-01,  1.1003e-01, -4.6618e-02, -5.6313e-02,\n",
              "          -2.0462e-01, -2.4491e-01, -5.9837e-03,  3.5077e-02,  1.9052e-01,\n",
              "          -4.9906e-01,  4.6397e-01,  3.9201e-01,  7.8808e-02,  8.9844e-02,\n",
              "          -3.1374e-01, -8.5382e-02, -9.4613e-02,  2.8622e-01,  1.3636e-01,\n",
              "          -4.1627e-02,  1.9975e-01, -1.0180e-02,  3.9670e-01,  1.7812e-01,\n",
              "           1.6822e-01,  5.6634e-02,  5.4135e-02,  2.1391e-01, -3.3140e-01,\n",
              "           1.3171e-01,  4.6072e-02, -1.5722e-01,  1.3235e-01, -1.6661e-02,\n",
              "          -2.1548e-01, -2.3497e-01, -1.1517e-01,  2.0131e-01,  2.3072e-01,\n",
              "          -1.6480e-01,  1.3398e-01, -1.6579e-01,  6.3781e-02,  1.1077e-01,\n",
              "          -1.4039e-01,  1.3419e-01,  5.6930e-02, -9.4473e-02,  2.4959e-02,\n",
              "          -2.3136e-01,  1.3663e-01,  2.4035e-01,  3.2284e-01,  8.1617e-02,\n",
              "           6.6470e-02, -3.9875e-01,  2.4612e-01, -2.2828e-01,  3.2165e-01,\n",
              "          -3.7346e-01, -4.1285e-01,  5.3247e-03,  1.3745e-01, -8.8666e-02,\n",
              "          -3.3890e-01,  2.1788e-02,  1.8485e-01, -1.1213e-01,  6.1162e-02,\n",
              "          -4.6214e-02,  2.4517e-01, -3.0776e-02,  1.3928e-01, -2.2696e-02,\n",
              "           3.1692e-01,  2.4527e-01,  5.2547e-02,  1.9976e-01, -1.7084e-01,\n",
              "          -4.8738e-03, -2.2800e-01, -8.7474e-02,  3.2788e-01,  2.3621e-01,\n",
              "          -8.6349e-02,  8.3304e-02,  7.0151e-02,  1.5401e-01, -9.5980e-02,\n",
              "           1.4836e-01,  2.5724e-01,  6.5883e-02,  8.4724e-03,  2.0240e-01,\n",
              "           2.1025e-01, -5.5188e-01, -1.0969e-01,  5.5160e-03,  2.3205e-01,\n",
              "           2.3446e-01, -1.1666e-01,  4.5056e-01,  1.2218e-01,  1.3425e-02,\n",
              "           1.0061e-02,  4.8375e-02, -2.9240e-01,  2.3585e-01, -3.3007e-01,\n",
              "           2.1054e-02,  1.5186e-01, -5.7555e-01, -4.0251e-01, -1.1791e-02,\n",
              "           5.9310e-02, -1.2006e-01, -6.3970e-02, -2.0729e-01,  3.2511e-01,\n",
              "           1.9006e-02, -1.1971e-01, -3.9776e-01, -4.5583e-02, -9.9590e-02,\n",
              "           1.0155e-01,  2.6333e-03, -5.1224e-02,  1.8788e-01,  5.1959e-01,\n",
              "          -2.2349e-01,  3.0741e-01, -4.5067e-01,  3.4338e-02, -1.0348e-01,\n",
              "           2.8375e-02, -2.3717e-01, -2.6033e-02, -1.4750e-01,  2.6983e-02,\n",
              "          -1.5022e-01, -3.1093e-01,  6.1616e-02,  3.4601e-01, -3.3302e-01,\n",
              "           1.6421e-01,  1.4376e-01, -3.6760e-02, -8.9975e-02, -4.6195e-01,\n",
              "          -2.4807e-01,  2.5947e-03,  3.6743e-02, -2.0745e-01,  3.3731e-01,\n",
              "          -1.2387e-01,  3.9053e-01,  2.2129e-03,  7.0039e-02, -6.0833e-02,\n",
              "           1.8077e-01, -7.1968e-02,  4.1472e-01,  2.8672e-01, -1.7228e-01,\n",
              "          -1.7982e-01, -1.1427e-01,  1.0598e-01, -2.5869e-01, -1.2026e-01,\n",
              "           1.4896e-02,  2.2248e-01, -1.9256e-01, -3.3831e-01, -1.3925e-01,\n",
              "          -6.3792e-02, -9.2514e-02, -1.0988e-01,  3.6111e-01,  2.1743e-01,\n",
              "          -3.2634e-01,  4.2840e-01,  4.0583e-02, -5.4703e-01, -2.8655e-01,\n",
              "          -1.6647e-01,  2.2925e-01,  1.7079e-01, -2.1745e-01,  9.9365e-02,\n",
              "          -3.3348e-01,  2.1277e-01, -3.4941e-01, -1.9368e-01, -2.6134e-01,\n",
              "           1.1306e-01,  2.5985e-01,  2.1592e-02,  4.8470e-01, -5.1051e-02,\n",
              "          -2.4463e-01, -1.9552e-01, -1.6897e-01, -1.0364e-01, -2.1135e-01,\n",
              "           8.1913e-02, -9.4593e-02,  1.5276e-01,  3.0924e-01, -3.8189e-01,\n",
              "          -2.9182e-02, -1.5240e-01,  9.2733e-02, -2.1514e-01, -1.0232e-02,\n",
              "           2.0076e-01, -2.8354e-02,  5.3776e-02]]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CLS_vectors_list[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXBO0gqRwGuf",
        "outputId": "b57a21ed-59ed-4231-c23f-a505c6c22918"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((0, 0),\n",
              " 's1: A girl is styling her hair. s2: A girl is brushing her hair.',\n",
              " 2.5,\n",
              " 17,\n",
              " tensor([[ 1.3366e-02,  4.4970e-02, -2.1637e-01, -3.2843e-01,  2.6883e-01,\n",
              "           3.4715e-02, -1.9444e-01, -1.1049e-02, -1.1818e-01, -3.9399e-01,\n",
              "           3.0634e-02, -5.8748e-02,  1.3790e-01, -1.0854e-01, -1.1573e-01,\n",
              "           4.3709e-01,  4.1830e-01,  2.6936e-01, -8.8575e-02, -5.6118e-01,\n",
              "          -5.0836e-01, -3.3846e-01,  2.8790e-02, -1.9942e-01, -1.1913e-01,\n",
              "          -2.5059e-01, -3.8456e-01,  4.5932e-02,  4.7195e-02, -1.2446e-01,\n",
              "          -1.1421e-01, -1.6876e-01,  1.7933e-01,  1.6506e-01, -3.5994e-01,\n",
              "           6.3980e-02, -3.9983e-01,  1.9067e-01, -2.0721e-01,  2.4676e-01,\n",
              "           3.1398e-01, -1.7534e-01, -1.0620e-01,  1.6748e-01,  1.0974e-01,\n",
              "           9.0651e-02, -1.5393e+00, -1.7551e-02,  5.5214e-01, -2.3338e-01,\n",
              "           1.6909e-01,  5.9467e-02, -2.3357e-01,  8.8209e-01,  6.5783e-02,\n",
              "          -1.4159e-01, -2.2780e-01,  1.0475e-01,  2.7281e-01, -2.2613e-01,\n",
              "           1.9078e-02, -1.3809e-02,  2.7687e-01,  3.7127e-02, -2.5137e-01,\n",
              "           4.0342e-01,  1.0888e-01, -2.1168e-01, -2.4087e-02,  4.2044e-02,\n",
              "           7.7703e-03, -1.0821e-03, -3.6651e-01, -4.7638e-01,  2.4341e-01,\n",
              "          -5.7833e-02, -2.6765e-01,  2.3241e-01,  2.5562e-01,  3.3041e-01,\n",
              "          -3.0377e-01, -7.5887e-02,  7.3283e-02,  2.4753e-01,  2.8733e-01,\n",
              "           2.4159e-01,  2.5090e-01,  2.8659e-01, -5.0211e-02,  2.4035e-01,\n",
              "          -3.6193e-01, -4.6894e-02, -2.0913e-01,  2.8753e-02,  7.0249e-02,\n",
              "           1.4872e-01,  5.3545e-01, -3.1319e-01, -1.6712e-01, -2.6523e-01,\n",
              "           2.0126e-02, -1.0949e-01,  1.5555e-01, -7.5298e-02, -4.4586e-01,\n",
              "           3.9126e-01,  2.4918e-02, -1.0390e-01,  8.6138e-02,  1.7019e-01,\n",
              "           2.8112e-01, -1.6113e-01,  2.0060e-02, -1.7760e-01,  9.1851e-02,\n",
              "           4.1034e-01, -3.2049e-01, -2.0413e-01, -5.4218e-02, -5.9541e-02,\n",
              "          -7.9522e-02,  9.2266e-01, -6.3348e-02, -2.3412e-01,  5.0652e-02,\n",
              "           2.2754e-02,  9.2640e-02, -5.9283e-02, -2.8026e-01,  1.5969e-01,\n",
              "           3.7505e-01,  1.4483e-02,  5.2963e-01,  1.5437e-01, -2.4282e-03,\n",
              "           3.5534e-01,  4.5313e-01,  5.6341e-02,  2.8499e-01,  1.9948e+00,\n",
              "          -9.7163e-02,  1.2551e-01, -4.6749e-01,  1.8835e-01, -1.2568e-01,\n",
              "          -3.7155e-01,  9.4080e-02,  5.3741e-02,  1.6287e-02,  2.0011e-01,\n",
              "          -9.3409e-02, -6.4552e-02, -5.9014e-02, -7.7613e-02, -3.7977e-02,\n",
              "           1.5250e-01,  1.5335e-01,  5.3374e-02, -1.4183e-01, -8.5384e-02,\n",
              "           1.3371e-01, -2.6035e-02, -6.1871e-04, -2.7482e-01, -1.4005e-01,\n",
              "           2.2240e-01,  4.8478e-01,  1.6444e-01,  7.8498e-01, -7.4962e-02,\n",
              "          -5.4402e-02,  1.9818e-03,  7.2542e-02, -2.2120e-01, -8.1714e-03,\n",
              "          -3.2649e-02,  1.2988e-01, -2.3693e-01, -1.6599e-01,  1.6207e-01,\n",
              "           1.2483e-01,  7.9260e-02, -3.2821e-01, -6.9188e-03,  1.6208e-01,\n",
              "          -2.1776e-01,  3.1775e-01, -3.9095e-01, -1.8376e-01,  2.1218e-01,\n",
              "           2.0695e-01,  3.5219e-02, -4.3276e-01,  2.9418e-01, -1.0515e-01,\n",
              "          -1.1886e-01,  2.6476e-01,  1.4377e-01, -1.0968e-01, -2.3026e-01,\n",
              "          -3.7732e-01, -1.6594e-01, -8.1956e-02, -1.9302e-01,  1.8249e-01,\n",
              "          -2.0892e-01, -4.1856e-02,  4.1895e-01,  1.6175e-01, -1.2888e-02,\n",
              "           1.0795e-01,  2.3546e-02, -1.7487e-02,  5.0752e-02, -7.6361e-03,\n",
              "          -7.5811e-02, -8.6322e-02,  1.4715e-01,  4.1496e-03, -1.2043e-01,\n",
              "           5.7725e-02, -1.2988e-01, -1.2794e-01,  2.3264e-01,  1.1353e-02,\n",
              "           1.4942e-01,  1.4291e-01,  3.0399e-01, -1.0101e-01, -5.7384e-01,\n",
              "           7.0094e-02, -1.7526e-01,  1.5261e-02,  5.2028e-02, -4.3566e-02,\n",
              "           1.8879e-01,  6.9454e-03, -1.5622e-01, -3.1834e-01, -1.5671e-01,\n",
              "           1.9726e-02, -2.3722e-01,  9.1811e-02, -1.2671e-01, -4.1349e-02,\n",
              "          -5.6327e-01,  1.1370e-01,  1.6299e-01,  3.0379e-01,  3.0600e-01,\n",
              "          -1.5217e-01, -1.5598e-01,  2.2519e-01,  1.3250e-01, -3.7618e-02,\n",
              "           2.2382e-01,  2.6000e-01,  2.8009e-01, -6.2816e-02, -1.6530e-01,\n",
              "          -4.2948e-01,  2.1899e-01,  1.6876e-01, -2.5217e-01, -2.3122e-01,\n",
              "          -4.3579e-01, -2.0297e-01, -1.9977e-01,  1.9908e-01, -1.7648e-01,\n",
              "          -2.4345e-01,  1.8237e-01,  1.5257e-01,  2.0201e-01, -2.7993e-01,\n",
              "          -1.9273e-01,  1.4150e-01,  1.2100e-01, -1.8515e-02,  3.2114e-02,\n",
              "           1.7936e-01, -6.3275e-02,  1.4373e-01, -1.6503e-01,  1.3539e-01,\n",
              "           1.8369e-01,  1.0891e-02, -3.3772e-02,  2.4969e-02, -1.0422e-01,\n",
              "          -1.2204e-01, -1.7160e-01,  2.8673e-02,  6.7599e-02,  1.1149e-01,\n",
              "           9.6529e-02,  3.9039e-01, -1.4949e-01, -2.9466e-01, -1.0825e-01,\n",
              "          -1.4585e-01,  4.4016e-01,  2.3982e-01, -3.0082e-01, -1.0227e+00,\n",
              "          -1.2143e-01, -4.7138e-01,  3.1425e-02, -9.9198e+00, -1.6917e-01,\n",
              "          -4.2679e-01,  2.1791e-01,  3.2133e-01, -1.4489e-02, -1.3293e-01,\n",
              "          -1.5845e-01, -4.4861e-01,  2.5328e-03,  2.5766e-01,  4.9418e-01,\n",
              "          -4.0746e-02,  1.8603e-01,  2.5537e-01, -7.1739e-02, -1.2795e-01,\n",
              "          -3.0123e-01,  1.2319e-02, -2.6447e-01,  2.0923e-01,  1.0613e-01,\n",
              "           3.1948e-01, -2.7839e-01,  1.6128e-01,  1.5274e-02, -3.3914e-01,\n",
              "           7.5671e-02,  9.5483e-02, -3.7359e-01,  5.3302e-02, -1.2824e-01,\n",
              "          -1.4178e-01,  1.3444e-02,  2.7793e-01, -5.1618e-02,  3.1854e-01,\n",
              "           5.2055e-01,  9.5752e-02,  6.5816e-02,  1.3445e-01,  5.7546e-02,\n",
              "          -3.9258e-01,  3.3548e-02,  1.5075e-01, -5.3708e-02, -1.8564e-02,\n",
              "           8.3197e-02, -3.3961e-01,  1.3031e-01,  1.2398e-01,  6.6174e-02,\n",
              "          -8.0499e-02,  2.5352e-01,  8.7653e-02, -1.3290e-01,  1.2581e-01,\n",
              "          -1.5871e-01,  4.8443e-02,  1.3994e-01, -2.9965e-01, -2.4118e-01,\n",
              "           1.1506e-01, -3.2766e-01,  4.2550e-01, -2.6833e-01, -7.4173e-04,\n",
              "          -1.7250e-01, -5.1620e-01, -1.0800e-01, -9.4531e-02, -1.1641e-01,\n",
              "          -3.0526e-02, -7.7764e-01, -2.8800e-02, -1.2682e-01,  2.6371e-01,\n",
              "           3.7315e-02, -1.7796e-01,  2.1037e-01, -3.4599e-02,  1.6556e-01,\n",
              "          -1.6903e-01, -8.9705e-02, -2.8919e-01, -2.9640e-01, -3.3588e-01,\n",
              "          -4.3278e-01, -2.9292e-01, -4.5689e-01,  2.4514e-01, -2.9458e-02,\n",
              "          -1.3141e-01,  1.1420e-01, -2.2643e-01, -2.6110e-02, -2.2702e-01,\n",
              "          -2.5992e-01, -1.6477e-02,  1.7832e-01,  1.3747e-01, -7.3906e-02,\n",
              "          -2.1465e-02, -1.3404e-01, -1.6317e-02, -2.8059e-01,  3.6307e-01,\n",
              "           2.4038e-01, -2.1263e-01, -7.0644e-02, -4.6655e-02,  2.2321e-01,\n",
              "           5.5327e-01,  6.3641e-02,  1.5127e-01,  7.7412e-02, -2.4578e-01,\n",
              "           4.3676e-02,  2.8371e-01, -2.9232e-01, -3.3830e-01, -1.1610e-02,\n",
              "           1.4269e-01, -1.8133e-01, -1.4795e-01, -9.0535e-02, -9.4270e-02,\n",
              "          -6.2744e-02,  3.3707e-03, -1.3148e-01,  3.6776e-01,  1.5839e-01,\n",
              "           7.1392e-02,  1.0878e-01,  4.7547e-04,  8.3035e-01,  1.2055e-01,\n",
              "          -1.6567e-01, -4.7521e-01,  4.7057e-01,  1.8248e-01, -8.7973e-02,\n",
              "           7.9666e-02,  6.6440e-03, -1.5677e-01,  2.4851e-01, -6.4860e-02,\n",
              "           1.0915e-02, -1.4472e-01,  9.6002e-02,  6.9390e-02,  1.6768e-01,\n",
              "          -7.3616e-02,  1.1754e-01, -1.4078e-01, -1.6271e-01, -4.1298e-01,\n",
              "           1.0997e-01,  2.8417e-01, -2.6103e-01,  2.6156e-01,  1.8107e-01,\n",
              "          -5.9557e-01, -1.2684e-01,  2.1451e-01,  2.6874e-02, -1.7074e-01,\n",
              "          -3.9880e-02,  4.1413e-01,  1.1587e-01,  2.2307e-01, -2.4686e-01,\n",
              "           3.6435e-01,  3.2441e-01, -5.7108e-01,  1.3389e-01, -2.5574e-01,\n",
              "           1.9323e-01,  4.7007e-01, -1.6000e-01, -6.1012e-02,  2.7840e-01,\n",
              "          -4.0791e-03,  2.1196e-01,  1.7836e-02,  2.6773e-01,  4.6690e-01,\n",
              "           1.0962e-01,  2.2605e-01,  2.6528e-01, -3.7340e-02, -2.4740e-01,\n",
              "          -2.8442e-03, -7.0379e-02, -7.9679e-03, -3.8250e-01, -2.3552e-01,\n",
              "          -9.6109e-02, -5.7300e-02, -8.6679e-02,  4.9614e-03, -2.9204e-01,\n",
              "           2.6268e-02, -9.1151e-02, -2.9395e-01, -1.8609e-01,  1.6237e-01,\n",
              "          -1.9009e-01,  4.0621e-02,  1.5914e-01,  4.7550e-02,  3.8241e-01,\n",
              "          -1.0465e-01,  1.7586e-01,  3.5489e-01,  3.1163e-01,  1.2603e-01,\n",
              "           2.0263e-01, -1.2359e-01, -3.2290e-01, -3.6912e-01,  2.5547e-01,\n",
              "           1.5434e-01, -4.7118e-01, -3.1386e-01,  1.7767e-01,  1.7991e-01,\n",
              "          -8.2858e-02,  4.6053e-03, -1.8935e-01, -1.2607e-02, -4.8439e-01,\n",
              "          -2.0914e-01,  2.4593e-01,  2.3148e-03,  7.0095e-02, -2.1298e-02,\n",
              "           7.0454e-01,  1.4294e-03,  9.6280e-02, -4.1974e-01, -1.3933e-01,\n",
              "          -2.2996e-01, -2.0024e-01,  1.1003e-01, -4.6618e-02, -5.6313e-02,\n",
              "          -2.0462e-01, -2.4491e-01, -5.9837e-03,  3.5077e-02,  1.9052e-01,\n",
              "          -4.9906e-01,  4.6397e-01,  3.9201e-01,  7.8808e-02,  8.9844e-02,\n",
              "          -3.1374e-01, -8.5382e-02, -9.4613e-02,  2.8622e-01,  1.3636e-01,\n",
              "          -4.1627e-02,  1.9975e-01, -1.0180e-02,  3.9670e-01,  1.7812e-01,\n",
              "           1.6822e-01,  5.6634e-02,  5.4135e-02,  2.1391e-01, -3.3140e-01,\n",
              "           1.3171e-01,  4.6072e-02, -1.5722e-01,  1.3235e-01, -1.6661e-02,\n",
              "          -2.1548e-01, -2.3497e-01, -1.1517e-01,  2.0131e-01,  2.3072e-01,\n",
              "          -1.6480e-01,  1.3398e-01, -1.6579e-01,  6.3781e-02,  1.1077e-01,\n",
              "          -1.4039e-01,  1.3419e-01,  5.6930e-02, -9.4473e-02,  2.4959e-02,\n",
              "          -2.3136e-01,  1.3663e-01,  2.4035e-01,  3.2284e-01,  8.1617e-02,\n",
              "           6.6470e-02, -3.9875e-01,  2.4612e-01, -2.2828e-01,  3.2165e-01,\n",
              "          -3.7346e-01, -4.1285e-01,  5.3247e-03,  1.3745e-01, -8.8666e-02,\n",
              "          -3.3890e-01,  2.1788e-02,  1.8485e-01, -1.1213e-01,  6.1162e-02,\n",
              "          -4.6214e-02,  2.4517e-01, -3.0776e-02,  1.3928e-01, -2.2696e-02,\n",
              "           3.1692e-01,  2.4527e-01,  5.2547e-02,  1.9976e-01, -1.7084e-01,\n",
              "          -4.8738e-03, -2.2800e-01, -8.7474e-02,  3.2788e-01,  2.3621e-01,\n",
              "          -8.6349e-02,  8.3304e-02,  7.0151e-02,  1.5401e-01, -9.5980e-02,\n",
              "           1.4836e-01,  2.5724e-01,  6.5883e-02,  8.4724e-03,  2.0240e-01,\n",
              "           2.1025e-01, -5.5188e-01, -1.0969e-01,  5.5160e-03,  2.3205e-01,\n",
              "           2.3446e-01, -1.1666e-01,  4.5056e-01,  1.2218e-01,  1.3425e-02,\n",
              "           1.0061e-02,  4.8375e-02, -2.9240e-01,  2.3585e-01, -3.3007e-01,\n",
              "           2.1054e-02,  1.5186e-01, -5.7555e-01, -4.0251e-01, -1.1791e-02,\n",
              "           5.9310e-02, -1.2006e-01, -6.3970e-02, -2.0729e-01,  3.2511e-01,\n",
              "           1.9006e-02, -1.1971e-01, -3.9776e-01, -4.5583e-02, -9.9590e-02,\n",
              "           1.0155e-01,  2.6333e-03, -5.1224e-02,  1.8788e-01,  5.1959e-01,\n",
              "          -2.2349e-01,  3.0741e-01, -4.5067e-01,  3.4338e-02, -1.0348e-01,\n",
              "           2.8375e-02, -2.3717e-01, -2.6033e-02, -1.4750e-01,  2.6983e-02,\n",
              "          -1.5022e-01, -3.1093e-01,  6.1616e-02,  3.4601e-01, -3.3302e-01,\n",
              "           1.6421e-01,  1.4376e-01, -3.6760e-02, -8.9975e-02, -4.6195e-01,\n",
              "          -2.4807e-01,  2.5947e-03,  3.6743e-02, -2.0745e-01,  3.3731e-01,\n",
              "          -1.2387e-01,  3.9053e-01,  2.2129e-03,  7.0039e-02, -6.0833e-02,\n",
              "           1.8077e-01, -7.1968e-02,  4.1472e-01,  2.8672e-01, -1.7228e-01,\n",
              "          -1.7982e-01, -1.1427e-01,  1.0598e-01, -2.5869e-01, -1.2026e-01,\n",
              "           1.4896e-02,  2.2248e-01, -1.9256e-01, -3.3831e-01, -1.3925e-01,\n",
              "          -6.3792e-02, -9.2514e-02, -1.0988e-01,  3.6111e-01,  2.1743e-01,\n",
              "          -3.2634e-01,  4.2840e-01,  4.0583e-02, -5.4703e-01, -2.8655e-01,\n",
              "          -1.6647e-01,  2.2925e-01,  1.7079e-01, -2.1745e-01,  9.9365e-02,\n",
              "          -3.3348e-01,  2.1277e-01, -3.4941e-01, -1.9368e-01, -2.6134e-01,\n",
              "           1.1306e-01,  2.5985e-01,  2.1592e-02,  4.8470e-01, -5.1051e-02,\n",
              "          -2.4463e-01, -1.9552e-01, -1.6897e-01, -1.0364e-01, -2.1135e-01,\n",
              "           8.1913e-02, -9.4593e-02,  1.5276e-01,  3.0924e-01, -3.8189e-01,\n",
              "          -2.9182e-02, -1.5240e-01,  9.2733e-02, -2.1514e-01, -1.0232e-02,\n",
              "           2.0076e-01, -2.8354e-02,  5.3776e-02]]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CLS_vectors_list[0][4].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqNERjHcQWkn",
        "outputId": "1ea35490-109c-4bdc-d398-dc9382f3439f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataloader"
      ],
      "metadata": {
        "id": "8-t7cRSS-NRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un sampler secuencial\n",
        "# attentions_list = dataset\n",
        "# SequentialSampler does not perform any shuffling or random selection of items.\n",
        "sampler = SequentialSampler(CLS_vectors_list)\n",
        "\n",
        "# Definir el tamaño del lote\n",
        "batch_size = 12 # always 12, because it is the number of attention layers, 12 layers for the same sentence\n",
        "\n",
        "# Crear el DataLoader sin un BatchSampler\n",
        "dataloader = DataLoader(CLS_vectors_list, batch_size=batch_size, sampler=sampler)"
      ],
      "metadata": {
        "id": "dSzUvRBd7oaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataloader) #1379 OK because there are 1379 sentences, 1 batch = 1 same sentence , 12 elements in the batch because there are 12 layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQmpqNtb9cNp",
        "outputId": "a78e437b-17f4-4ea6-fdd5-36164183ba28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1379"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sr = next(iter(dataloader))\n",
        "sr[0] # ids (num_sent, num_layer)\n",
        "sr[1] # similarity label\n",
        "sr[2].shape\n",
        "sr[3].shape\n",
        "sr[4].shape #[batch_size, len_sentence, input_size] with attentions ([12,289,12])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RUVAl03NZqO",
        "outputId": "a406ae53-5e9b-4a59-adb7-0cb32f366cce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12, 1, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "lh2_LvEAFOuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(model, iterator, optimizer, criterion, device=device, clip = 1.0):\n",
        "    #Training loop\n",
        "    model.train()\n",
        "    loss_sum = 0\n",
        "    seed = 42\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    #torch.cuda.set_device(0)\n",
        "\n",
        "    for i, (_,_,_,_,input) in enumerate(iterator):\n",
        "        optimizer.zero_grad()\n",
        "        output, _ = model(input)\n",
        "        loss = criterion(output, input)\n",
        "        loss.backward()\n",
        "        #prevent gradients from exploding\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        #Update params\n",
        "        optimizer.step()\n",
        "        loss_sum += loss.item()\n",
        "\n",
        "    epoch_train_loss = loss_sum * batch_size / len(iterator)\n",
        "\n",
        "    return epoch_train_loss"
      ],
      "metadata": {
        "id": "cJcjfZz_-uD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraer el vector latente fijo de cada elemento del batch\n",
        "def extract_latent_vectors(model, dataloader, device, model_type='RNN'):\n",
        "    model.eval()\n",
        "    vector_representations = {}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (id,s,label,dim,input) in dataloader:\n",
        "            latent_vectors = []\n",
        "            if model_type == 'RNN':\n",
        "              _, (latent_representation, _) = model.encoder(input)\n",
        "              latent = latent_representation.squeeze(0)\n",
        "            else:\n",
        "              latent_representation = model.encoder(input)\n",
        "              latent = latent_representation.squeeze(0).squeeze(1)\n",
        "            tuples = list(zip(id[0].tolist(), id[1].tolist()))\n",
        "            #latent = latent_representation.squeeze(0)\n",
        "            for i in range(latent.size(0)):\n",
        "              latent_vectors.append(latent[i].numpy())\n",
        "              vector_representations[tuples[i]] = { 'vector' : latent[i].numpy(), 'sequence': s, 'label': label, 'dimension':dim}\n",
        "\n",
        "    return vector_representations"
      ],
      "metadata": {
        "id": "hZ3fWPpSI-pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearAutoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim):\n",
        "        super(LinearAutoencoder, self).__init__()\n",
        "        dims = [768, 512, 256, 128, 32, 8, 2]\n",
        "\n",
        "        layer_dims= [i for i in dims if i > latent_dim ]\n",
        "        layer_dims.append(latent_dim)\n",
        "\n",
        "        encoder_layers = []\n",
        "        decoder_layers = []\n",
        "\n",
        "        for i in range(len(layer_dims) - 1):\n",
        "            encoder_layers.append(nn.Linear(layer_dims[i], layer_dims[i+1]))\n",
        "            encoder_layers.append(nn.GELU())\n",
        "            decoder_layers.insert(0, nn.Linear(layer_dims[i+1], layer_dims[i]))\n",
        "            decoder_layers.insert(0, nn.GELU())\n",
        "\n",
        "        self.encoder = nn.Sequential(*encoder_layers)\n",
        "        self.decoder = nn.Sequential(*decoder_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Codificación\n",
        "        encoded = self.encoder(x)\n",
        "        # Decodificación\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded, encoded\n"
      ],
      "metadata": {
        "id": "CspMdXG6P9dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 500\n",
        "best_valid_loss = float('inf')\n",
        "model_name = 'Autoencoder_Lineal_CLS'\n",
        "train_loss_values = []\n",
        "history = {\"train\": {\"loss\": []}}\n",
        "\n",
        "input_size = 768  #due to 768 dimensión of BERT\n",
        "hidden_size = 2  # size of fixed vector #laten dim\n",
        "learning_rate = 0.00025 #0.00025 #0.0007\n",
        "\n",
        "seed = 42\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "\n",
        "#model = AttentionLinearAutoencoder(input_size, hidden_size)\n",
        "model = LinearAutoencoder(input_size, hidden_size)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    epoch_train_loss = train_loop(model,dataloader,optimizer,criterion,device)\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    train_loss_values.append(epoch_train_loss)\n",
        "\n",
        "    history[\"train\"][\"loss\"].append(epoch_train_loss)\n",
        "\n",
        "    print('-' * 80)\n",
        "    #print(f'Epoch: {epoch+1:03}/{NUM_EPOCHS} | Epoch Time: {epoch_mins}m {epoch_secs}s | Train loss: {epoch_train_loss:.4f} | Train acc: {epoch_train_acc:.4f} | Dev loss: {epoch_dev_loss:.4f} | Dev acc: {epoch_dev_acc:.4f}')\n",
        "    print(f'Epoch: {epoch+1:03}/{NUM_EPOCHS} | Epoch Time: {epoch_mins}m {epoch_secs}s | Train loss: {epoch_train_loss:.4f}')\n"
      ],
      "metadata": {
        "id": "1VTc_w-0EI_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ac1457e-5bf6-4724-f46e-e0d139b03105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Epoch: 001/500 | Epoch Time: 0m 30s | Train loss: 1.2771\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 002/500 | Epoch Time: 0m 25s | Train loss: 0.6560\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 003/500 | Epoch Time: 0m 25s | Train loss: 0.5858\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 004/500 | Epoch Time: 0m 26s | Train loss: 0.5597\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 005/500 | Epoch Time: 0m 25s | Train loss: 0.5477\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 006/500 | Epoch Time: 0m 24s | Train loss: 0.5420\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 007/500 | Epoch Time: 0m 26s | Train loss: 0.5374\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 008/500 | Epoch Time: 0m 32s | Train loss: 0.5322\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 009/500 | Epoch Time: 0m 25s | Train loss: 0.5282\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 010/500 | Epoch Time: 0m 25s | Train loss: 0.5245\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 011/500 | Epoch Time: 0m 25s | Train loss: 0.5187\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 012/500 | Epoch Time: 0m 24s | Train loss: 0.5163\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 013/500 | Epoch Time: 0m 24s | Train loss: 0.5147\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 014/500 | Epoch Time: 0m 25s | Train loss: 0.5115\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 015/500 | Epoch Time: 0m 25s | Train loss: 0.5080\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 016/500 | Epoch Time: 0m 24s | Train loss: 0.5060\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 017/500 | Epoch Time: 0m 25s | Train loss: 0.5035\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 018/500 | Epoch Time: 0m 25s | Train loss: 0.5010\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 019/500 | Epoch Time: 0m 26s | Train loss: 0.4990\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 020/500 | Epoch Time: 0m 24s | Train loss: 0.4985\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 021/500 | Epoch Time: 0m 25s | Train loss: 0.4982\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 022/500 | Epoch Time: 0m 25s | Train loss: 0.4971\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 023/500 | Epoch Time: 0m 25s | Train loss: 0.4940\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 024/500 | Epoch Time: 0m 24s | Train loss: 0.4913\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 025/500 | Epoch Time: 0m 25s | Train loss: 0.4899\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 026/500 | Epoch Time: 0m 25s | Train loss: 0.4886\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 027/500 | Epoch Time: 0m 25s | Train loss: 0.4892\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 028/500 | Epoch Time: 0m 25s | Train loss: 0.4884\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 029/500 | Epoch Time: 0m 24s | Train loss: 0.4870\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 030/500 | Epoch Time: 0m 24s | Train loss: 0.4863\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 031/500 | Epoch Time: 0m 27s | Train loss: 0.4855\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 032/500 | Epoch Time: 0m 23s | Train loss: 0.4856\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 033/500 | Epoch Time: 0m 24s | Train loss: 0.4846\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 034/500 | Epoch Time: 0m 24s | Train loss: 0.4842\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 035/500 | Epoch Time: 0m 24s | Train loss: 0.4846\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 036/500 | Epoch Time: 0m 24s | Train loss: 0.4830\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 037/500 | Epoch Time: 0m 24s | Train loss: 0.4814\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 038/500 | Epoch Time: 0m 24s | Train loss: 0.4808\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 039/500 | Epoch Time: 0m 24s | Train loss: 0.4813\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 040/500 | Epoch Time: 0m 24s | Train loss: 0.4810\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 041/500 | Epoch Time: 0m 24s | Train loss: 0.4812\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 042/500 | Epoch Time: 0m 24s | Train loss: 0.4817\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 043/500 | Epoch Time: 0m 24s | Train loss: 0.4807\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 044/500 | Epoch Time: 0m 24s | Train loss: 0.4795\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 045/500 | Epoch Time: 0m 24s | Train loss: 0.4776\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 046/500 | Epoch Time: 0m 24s | Train loss: 0.4770\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 047/500 | Epoch Time: 0m 24s | Train loss: 0.4765\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 048/500 | Epoch Time: 0m 24s | Train loss: 0.4770\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 049/500 | Epoch Time: 0m 24s | Train loss: 0.4760\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 050/500 | Epoch Time: 0m 24s | Train loss: 0.4760\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 051/500 | Epoch Time: 0m 24s | Train loss: 0.4756\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 052/500 | Epoch Time: 0m 24s | Train loss: 0.4754\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 053/500 | Epoch Time: 0m 24s | Train loss: 0.4742\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 054/500 | Epoch Time: 0m 24s | Train loss: 0.4735\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 055/500 | Epoch Time: 0m 24s | Train loss: 0.4737\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 056/500 | Epoch Time: 0m 24s | Train loss: 0.4741\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 057/500 | Epoch Time: 0m 23s | Train loss: 0.4737\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 058/500 | Epoch Time: 0m 24s | Train loss: 0.4729\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 059/500 | Epoch Time: 0m 24s | Train loss: 0.4736\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 060/500 | Epoch Time: 0m 24s | Train loss: 0.4719\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 061/500 | Epoch Time: 0m 24s | Train loss: 0.4713\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 062/500 | Epoch Time: 0m 24s | Train loss: 0.4712\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 063/500 | Epoch Time: 0m 25s | Train loss: 0.4711\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 064/500 | Epoch Time: 0m 25s | Train loss: 0.4703\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 065/500 | Epoch Time: 0m 25s | Train loss: 0.4696\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 066/500 | Epoch Time: 0m 25s | Train loss: 0.4689\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 067/500 | Epoch Time: 0m 25s | Train loss: 0.4686\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 068/500 | Epoch Time: 0m 25s | Train loss: 0.4694\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 069/500 | Epoch Time: 0m 25s | Train loss: 0.4696\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 070/500 | Epoch Time: 0m 25s | Train loss: 0.4703\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 071/500 | Epoch Time: 0m 25s | Train loss: 0.4704\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 072/500 | Epoch Time: 0m 25s | Train loss: 0.4690\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 073/500 | Epoch Time: 0m 26s | Train loss: 0.4674\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 074/500 | Epoch Time: 0m 25s | Train loss: 0.4670\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 075/500 | Epoch Time: 0m 24s | Train loss: 0.4676\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 076/500 | Epoch Time: 0m 25s | Train loss: 0.4675\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 077/500 | Epoch Time: 0m 25s | Train loss: 0.4666\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 078/500 | Epoch Time: 0m 26s | Train loss: 0.4659\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 079/500 | Epoch Time: 0m 25s | Train loss: 0.4666\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 080/500 | Epoch Time: 0m 25s | Train loss: 0.4688\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 081/500 | Epoch Time: 0m 25s | Train loss: 0.4667\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 082/500 | Epoch Time: 0m 25s | Train loss: 0.4650\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 083/500 | Epoch Time: 0m 26s | Train loss: 0.4647\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 084/500 | Epoch Time: 0m 25s | Train loss: 0.4635\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 085/500 | Epoch Time: 0m 26s | Train loss: 0.4631\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 086/500 | Epoch Time: 0m 26s | Train loss: 0.4648\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 087/500 | Epoch Time: 0m 27s | Train loss: 0.4652\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 088/500 | Epoch Time: 0m 25s | Train loss: 0.4639\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 089/500 | Epoch Time: 0m 25s | Train loss: 0.4629\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 090/500 | Epoch Time: 0m 25s | Train loss: 0.4639\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 091/500 | Epoch Time: 0m 25s | Train loss: 0.4626\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 092/500 | Epoch Time: 0m 26s | Train loss: 0.4630\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 093/500 | Epoch Time: 0m 26s | Train loss: 0.4633\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 094/500 | Epoch Time: 0m 25s | Train loss: 0.4629\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 095/500 | Epoch Time: 0m 26s | Train loss: 0.4626\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 096/500 | Epoch Time: 0m 25s | Train loss: 0.4637\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 097/500 | Epoch Time: 0m 25s | Train loss: 0.4628\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 098/500 | Epoch Time: 0m 25s | Train loss: 0.4622\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 099/500 | Epoch Time: 0m 25s | Train loss: 0.4617\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 100/500 | Epoch Time: 0m 25s | Train loss: 0.4608\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 101/500 | Epoch Time: 0m 25s | Train loss: 0.4605\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 102/500 | Epoch Time: 0m 25s | Train loss: 0.4596\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 103/500 | Epoch Time: 0m 24s | Train loss: 0.4600\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 104/500 | Epoch Time: 0m 25s | Train loss: 0.4606\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 105/500 | Epoch Time: 0m 25s | Train loss: 0.4605\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 106/500 | Epoch Time: 0m 25s | Train loss: 0.4623\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 107/500 | Epoch Time: 0m 25s | Train loss: 0.4605\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 108/500 | Epoch Time: 0m 25s | Train loss: 0.4598\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 109/500 | Epoch Time: 0m 25s | Train loss: 0.4603\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 110/500 | Epoch Time: 0m 25s | Train loss: 0.4594\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 111/500 | Epoch Time: 0m 25s | Train loss: 0.4594\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 112/500 | Epoch Time: 0m 25s | Train loss: 0.4586\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 113/500 | Epoch Time: 0m 25s | Train loss: 0.4584\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 114/500 | Epoch Time: 0m 25s | Train loss: 0.4577\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 115/500 | Epoch Time: 0m 25s | Train loss: 0.4571\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 116/500 | Epoch Time: 0m 25s | Train loss: 0.4567\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 117/500 | Epoch Time: 0m 25s | Train loss: 0.4571\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 118/500 | Epoch Time: 0m 25s | Train loss: 0.4595\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 119/500 | Epoch Time: 0m 25s | Train loss: 0.4580\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 120/500 | Epoch Time: 0m 25s | Train loss: 0.4562\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 121/500 | Epoch Time: 0m 25s | Train loss: 0.4572\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 122/500 | Epoch Time: 0m 25s | Train loss: 0.4571\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 123/500 | Epoch Time: 0m 26s | Train loss: 0.4577\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 124/500 | Epoch Time: 0m 25s | Train loss: 0.4564\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 125/500 | Epoch Time: 0m 25s | Train loss: 0.4555\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 126/500 | Epoch Time: 0m 26s | Train loss: 0.4557\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 127/500 | Epoch Time: 0m 25s | Train loss: 0.4542\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 128/500 | Epoch Time: 0m 26s | Train loss: 0.4534\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 129/500 | Epoch Time: 0m 27s | Train loss: 0.4534\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 130/500 | Epoch Time: 0m 28s | Train loss: 0.4530\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 131/500 | Epoch Time: 0m 27s | Train loss: 0.4546\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 132/500 | Epoch Time: 0m 26s | Train loss: 0.4548\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 133/500 | Epoch Time: 0m 27s | Train loss: 0.4538\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 134/500 | Epoch Time: 0m 26s | Train loss: 0.4530\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 135/500 | Epoch Time: 0m 25s | Train loss: 0.4522\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 136/500 | Epoch Time: 0m 25s | Train loss: 0.4524\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 137/500 | Epoch Time: 0m 25s | Train loss: 0.4528\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 138/500 | Epoch Time: 0m 25s | Train loss: 0.4523\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 139/500 | Epoch Time: 0m 26s | Train loss: 0.4527\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 140/500 | Epoch Time: 0m 26s | Train loss: 0.4531\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 141/500 | Epoch Time: 0m 25s | Train loss: 0.4537\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 142/500 | Epoch Time: 0m 25s | Train loss: 0.4528\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 143/500 | Epoch Time: 0m 25s | Train loss: 0.4527\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 144/500 | Epoch Time: 0m 25s | Train loss: 0.4518\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 145/500 | Epoch Time: 0m 25s | Train loss: 0.4512\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 146/500 | Epoch Time: 0m 24s | Train loss: 0.4520\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 147/500 | Epoch Time: 0m 25s | Train loss: 0.4503\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 148/500 | Epoch Time: 0m 25s | Train loss: 0.4508\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 149/500 | Epoch Time: 0m 25s | Train loss: 0.4524\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 150/500 | Epoch Time: 0m 25s | Train loss: 0.4515\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 151/500 | Epoch Time: 0m 25s | Train loss: 0.4505\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 152/500 | Epoch Time: 0m 25s | Train loss: 0.4498\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 153/500 | Epoch Time: 0m 25s | Train loss: 0.4493\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 154/500 | Epoch Time: 0m 25s | Train loss: 0.4493\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 155/500 | Epoch Time: 0m 25s | Train loss: 0.4489\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 156/500 | Epoch Time: 0m 24s | Train loss: 0.4491\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 157/500 | Epoch Time: 0m 25s | Train loss: 0.4493\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 158/500 | Epoch Time: 0m 25s | Train loss: 0.4492\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 159/500 | Epoch Time: 0m 25s | Train loss: 0.4493\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 160/500 | Epoch Time: 0m 24s | Train loss: 0.4495\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 161/500 | Epoch Time: 0m 25s | Train loss: 0.4486\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 162/500 | Epoch Time: 0m 25s | Train loss: 0.4481\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 163/500 | Epoch Time: 0m 25s | Train loss: 0.4491\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 164/500 | Epoch Time: 0m 25s | Train loss: 0.4471\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 165/500 | Epoch Time: 0m 24s | Train loss: 0.4469\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 166/500 | Epoch Time: 0m 24s | Train loss: 0.4483\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 167/500 | Epoch Time: 0m 25s | Train loss: 0.4478\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 168/500 | Epoch Time: 0m 25s | Train loss: 0.4466\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 169/500 | Epoch Time: 0m 25s | Train loss: 0.4455\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 170/500 | Epoch Time: 0m 25s | Train loss: 0.4449\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 171/500 | Epoch Time: 0m 25s | Train loss: 0.4464\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 172/500 | Epoch Time: 0m 25s | Train loss: 0.4465\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 173/500 | Epoch Time: 0m 25s | Train loss: 0.4459\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 174/500 | Epoch Time: 0m 24s | Train loss: 0.4461\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 175/500 | Epoch Time: 0m 24s | Train loss: 0.4450\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 176/500 | Epoch Time: 0m 24s | Train loss: 0.4446\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 177/500 | Epoch Time: 0m 25s | Train loss: 0.4451\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 178/500 | Epoch Time: 0m 24s | Train loss: 0.4447\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 179/500 | Epoch Time: 0m 24s | Train loss: 0.4461\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 180/500 | Epoch Time: 0m 25s | Train loss: 0.4452\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 181/500 | Epoch Time: 0m 25s | Train loss: 0.4445\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 182/500 | Epoch Time: 0m 25s | Train loss: 0.4441\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 183/500 | Epoch Time: 0m 27s | Train loss: 0.4441\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 184/500 | Epoch Time: 0m 25s | Train loss: 0.4441\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 185/500 | Epoch Time: 0m 25s | Train loss: 0.4431\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 186/500 | Epoch Time: 0m 25s | Train loss: 0.4423\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 187/500 | Epoch Time: 0m 25s | Train loss: 0.4429\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 188/500 | Epoch Time: 0m 25s | Train loss: 0.4434\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 189/500 | Epoch Time: 0m 25s | Train loss: 0.4448\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 190/500 | Epoch Time: 0m 25s | Train loss: 0.4432\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 191/500 | Epoch Time: 0m 25s | Train loss: 0.4427\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 192/500 | Epoch Time: 0m 25s | Train loss: 0.4432\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 193/500 | Epoch Time: 0m 25s | Train loss: 0.4425\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 194/500 | Epoch Time: 0m 25s | Train loss: 0.4425\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 195/500 | Epoch Time: 0m 24s | Train loss: 0.4420\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 196/500 | Epoch Time: 0m 25s | Train loss: 0.4414\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 197/500 | Epoch Time: 0m 25s | Train loss: 0.4410\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 198/500 | Epoch Time: 0m 25s | Train loss: 0.4415\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 199/500 | Epoch Time: 0m 25s | Train loss: 0.4403\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 200/500 | Epoch Time: 0m 25s | Train loss: 0.4406\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 201/500 | Epoch Time: 0m 25s | Train loss: 0.4413\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 202/500 | Epoch Time: 0m 25s | Train loss: 0.4416\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 203/500 | Epoch Time: 0m 24s | Train loss: 0.4413\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 204/500 | Epoch Time: 0m 24s | Train loss: 0.4416\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 205/500 | Epoch Time: 0m 25s | Train loss: 0.4414\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 206/500 | Epoch Time: 0m 24s | Train loss: 0.4399\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 207/500 | Epoch Time: 0m 25s | Train loss: 0.4402\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 208/500 | Epoch Time: 0m 25s | Train loss: 0.4400\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 209/500 | Epoch Time: 0m 25s | Train loss: 0.4403\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 210/500 | Epoch Time: 0m 25s | Train loss: 0.4399\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 211/500 | Epoch Time: 0m 25s | Train loss: 0.4400\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 212/500 | Epoch Time: 0m 25s | Train loss: 0.4393\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 213/500 | Epoch Time: 0m 25s | Train loss: 0.4386\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 214/500 | Epoch Time: 0m 25s | Train loss: 0.4387\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 215/500 | Epoch Time: 0m 25s | Train loss: 0.4389\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 216/500 | Epoch Time: 0m 25s | Train loss: 0.4390\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 217/500 | Epoch Time: 0m 25s | Train loss: 0.4387\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 218/500 | Epoch Time: 0m 25s | Train loss: 0.4390\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 219/500 | Epoch Time: 0m 25s | Train loss: 0.4386\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 220/500 | Epoch Time: 0m 25s | Train loss: 0.4384\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 221/500 | Epoch Time: 0m 25s | Train loss: 0.4376\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 222/500 | Epoch Time: 0m 25s | Train loss: 0.4370\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 223/500 | Epoch Time: 0m 24s | Train loss: 0.4373\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 224/500 | Epoch Time: 0m 26s | Train loss: 0.4375\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 225/500 | Epoch Time: 0m 25s | Train loss: 0.4371\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 226/500 | Epoch Time: 0m 26s | Train loss: 0.4378\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 227/500 | Epoch Time: 0m 26s | Train loss: 0.4365\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 228/500 | Epoch Time: 0m 25s | Train loss: 0.4359\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 229/500 | Epoch Time: 0m 26s | Train loss: 0.4352\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 230/500 | Epoch Time: 0m 26s | Train loss: 0.4349\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 231/500 | Epoch Time: 0m 25s | Train loss: 0.4363\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 232/500 | Epoch Time: 0m 25s | Train loss: 0.4363\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 233/500 | Epoch Time: 0m 26s | Train loss: 0.4361\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 234/500 | Epoch Time: 0m 25s | Train loss: 0.4359\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 235/500 | Epoch Time: 0m 25s | Train loss: 0.4344\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 236/500 | Epoch Time: 0m 25s | Train loss: 0.4340\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 237/500 | Epoch Time: 0m 27s | Train loss: 0.4338\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 238/500 | Epoch Time: 0m 27s | Train loss: 0.4342\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 239/500 | Epoch Time: 0m 25s | Train loss: 0.4340\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 240/500 | Epoch Time: 0m 26s | Train loss: 0.4360\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 241/500 | Epoch Time: 0m 25s | Train loss: 0.4341\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 242/500 | Epoch Time: 0m 26s | Train loss: 0.4331\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 243/500 | Epoch Time: 0m 26s | Train loss: 0.4334\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 244/500 | Epoch Time: 0m 25s | Train loss: 0.4336\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 245/500 | Epoch Time: 0m 26s | Train loss: 0.4352\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 246/500 | Epoch Time: 0m 26s | Train loss: 0.4345\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 247/500 | Epoch Time: 0m 26s | Train loss: 0.4345\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 248/500 | Epoch Time: 0m 26s | Train loss: 0.4357\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 249/500 | Epoch Time: 0m 25s | Train loss: 0.4347\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 250/500 | Epoch Time: 0m 25s | Train loss: 0.4342\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 251/500 | Epoch Time: 0m 25s | Train loss: 0.4332\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 252/500 | Epoch Time: 0m 25s | Train loss: 0.4331\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 253/500 | Epoch Time: 0m 25s | Train loss: 0.4327\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 254/500 | Epoch Time: 0m 25s | Train loss: 0.4334\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 255/500 | Epoch Time: 0m 25s | Train loss: 0.4331\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 256/500 | Epoch Time: 0m 25s | Train loss: 0.4335\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 257/500 | Epoch Time: 0m 25s | Train loss: 0.4341\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 258/500 | Epoch Time: 0m 25s | Train loss: 0.4341\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 259/500 | Epoch Time: 0m 25s | Train loss: 0.4344\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 260/500 | Epoch Time: 0m 26s | Train loss: 0.4345\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 261/500 | Epoch Time: 0m 26s | Train loss: 0.4326\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 262/500 | Epoch Time: 0m 26s | Train loss: 0.4313\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 263/500 | Epoch Time: 0m 26s | Train loss: 0.4314\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 264/500 | Epoch Time: 0m 25s | Train loss: 0.4316\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 265/500 | Epoch Time: 0m 24s | Train loss: 0.4315\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 266/500 | Epoch Time: 0m 25s | Train loss: 0.4305\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 267/500 | Epoch Time: 0m 25s | Train loss: 0.4305\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 268/500 | Epoch Time: 0m 25s | Train loss: 0.4308\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 269/500 | Epoch Time: 0m 25s | Train loss: 0.4302\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 270/500 | Epoch Time: 0m 25s | Train loss: 0.4311\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 271/500 | Epoch Time: 0m 26s | Train loss: 0.4349\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 272/500 | Epoch Time: 0m 26s | Train loss: 0.4318\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 273/500 | Epoch Time: 0m 25s | Train loss: 0.4297\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 274/500 | Epoch Time: 0m 26s | Train loss: 0.4299\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 275/500 | Epoch Time: 0m 26s | Train loss: 0.4295\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 276/500 | Epoch Time: 0m 25s | Train loss: 0.4305\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 277/500 | Epoch Time: 0m 25s | Train loss: 0.4299\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 278/500 | Epoch Time: 0m 25s | Train loss: 0.4290\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 279/500 | Epoch Time: 0m 26s | Train loss: 0.4290\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 280/500 | Epoch Time: 0m 26s | Train loss: 0.4297\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 281/500 | Epoch Time: 0m 26s | Train loss: 0.4304\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 282/500 | Epoch Time: 0m 26s | Train loss: 0.4300\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 283/500 | Epoch Time: 0m 26s | Train loss: 0.4307\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 284/500 | Epoch Time: 0m 26s | Train loss: 0.4301\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 285/500 | Epoch Time: 0m 26s | Train loss: 0.4292\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 286/500 | Epoch Time: 0m 25s | Train loss: 0.4295\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 287/500 | Epoch Time: 0m 26s | Train loss: 0.4287\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 288/500 | Epoch Time: 0m 26s | Train loss: 0.4282\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 289/500 | Epoch Time: 0m 26s | Train loss: 0.4301\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 290/500 | Epoch Time: 0m 26s | Train loss: 0.4316\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 291/500 | Epoch Time: 0m 25s | Train loss: 0.4299\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 292/500 | Epoch Time: 0m 26s | Train loss: 0.4289\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 293/500 | Epoch Time: 0m 26s | Train loss: 0.4284\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 294/500 | Epoch Time: 0m 26s | Train loss: 0.4282\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 295/500 | Epoch Time: 0m 26s | Train loss: 0.4284\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 296/500 | Epoch Time: 0m 25s | Train loss: 0.4277\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 297/500 | Epoch Time: 0m 25s | Train loss: 0.4279\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 298/500 | Epoch Time: 0m 25s | Train loss: 0.4297\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 299/500 | Epoch Time: 0m 25s | Train loss: 0.4285\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 300/500 | Epoch Time: 0m 25s | Train loss: 0.4277\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 301/500 | Epoch Time: 0m 25s | Train loss: 0.4273\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 302/500 | Epoch Time: 0m 25s | Train loss: 0.4280\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 303/500 | Epoch Time: 0m 25s | Train loss: 0.4272\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 304/500 | Epoch Time: 0m 25s | Train loss: 0.4274\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 305/500 | Epoch Time: 0m 25s | Train loss: 0.4267\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 306/500 | Epoch Time: 0m 26s | Train loss: 0.4272\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 307/500 | Epoch Time: 0m 25s | Train loss: 0.4271\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 308/500 | Epoch Time: 0m 25s | Train loss: 0.4274\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 309/500 | Epoch Time: 0m 25s | Train loss: 0.4268\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 310/500 | Epoch Time: 0m 25s | Train loss: 0.4265\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 311/500 | Epoch Time: 0m 25s | Train loss: 0.4267\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 312/500 | Epoch Time: 0m 25s | Train loss: 0.4266\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 313/500 | Epoch Time: 0m 25s | Train loss: 0.4259\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 314/500 | Epoch Time: 0m 25s | Train loss: 0.4253\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 315/500 | Epoch Time: 0m 25s | Train loss: 0.4263\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 316/500 | Epoch Time: 0m 25s | Train loss: 0.4254\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 317/500 | Epoch Time: 0m 25s | Train loss: 0.4255\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 318/500 | Epoch Time: 0m 25s | Train loss: 0.4269\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 319/500 | Epoch Time: 0m 25s | Train loss: 0.4268\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 320/500 | Epoch Time: 0m 24s | Train loss: 0.4261\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 321/500 | Epoch Time: 0m 25s | Train loss: 0.4263\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 322/500 | Epoch Time: 0m 25s | Train loss: 0.4252\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 323/500 | Epoch Time: 0m 25s | Train loss: 0.4271\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 324/500 | Epoch Time: 0m 25s | Train loss: 0.4274\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 325/500 | Epoch Time: 0m 25s | Train loss: 0.4251\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 326/500 | Epoch Time: 0m 25s | Train loss: 0.4244\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 327/500 | Epoch Time: 0m 26s | Train loss: 0.4258\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 328/500 | Epoch Time: 0m 26s | Train loss: 0.4259\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 329/500 | Epoch Time: 0m 25s | Train loss: 0.4240\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 330/500 | Epoch Time: 0m 25s | Train loss: 0.4248\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 331/500 | Epoch Time: 0m 25s | Train loss: 0.4257\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 332/500 | Epoch Time: 0m 25s | Train loss: 0.4243\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 333/500 | Epoch Time: 0m 25s | Train loss: 0.4244\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 334/500 | Epoch Time: 0m 25s | Train loss: 0.4258\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 335/500 | Epoch Time: 0m 25s | Train loss: 0.4250\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 336/500 | Epoch Time: 0m 25s | Train loss: 0.4252\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 337/500 | Epoch Time: 0m 25s | Train loss: 0.4256\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 338/500 | Epoch Time: 0m 25s | Train loss: 0.4244\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 339/500 | Epoch Time: 0m 25s | Train loss: 0.4245\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 340/500 | Epoch Time: 0m 25s | Train loss: 0.4237\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 341/500 | Epoch Time: 0m 25s | Train loss: 0.4242\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 342/500 | Epoch Time: 0m 25s | Train loss: 0.4244\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 343/500 | Epoch Time: 0m 25s | Train loss: 0.4242\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 344/500 | Epoch Time: 0m 25s | Train loss: 0.4244\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 345/500 | Epoch Time: 0m 25s | Train loss: 0.4260\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 346/500 | Epoch Time: 0m 25s | Train loss: 0.4242\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 347/500 | Epoch Time: 0m 26s | Train loss: 0.4236\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 348/500 | Epoch Time: 0m 25s | Train loss: 0.4228\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 349/500 | Epoch Time: 0m 24s | Train loss: 0.4232\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 350/500 | Epoch Time: 0m 24s | Train loss: 0.4227\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 351/500 | Epoch Time: 0m 24s | Train loss: 0.4246\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 352/500 | Epoch Time: 0m 25s | Train loss: 0.4237\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 353/500 | Epoch Time: 0m 24s | Train loss: 0.4233\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 354/500 | Epoch Time: 0m 25s | Train loss: 0.4223\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 355/500 | Epoch Time: 0m 25s | Train loss: 0.4223\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 356/500 | Epoch Time: 0m 25s | Train loss: 0.4224\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 357/500 | Epoch Time: 0m 25s | Train loss: 0.4216\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 358/500 | Epoch Time: 0m 24s | Train loss: 0.4213\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 359/500 | Epoch Time: 0m 25s | Train loss: 0.4231\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 360/500 | Epoch Time: 0m 25s | Train loss: 0.4229\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 361/500 | Epoch Time: 0m 24s | Train loss: 0.4221\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 362/500 | Epoch Time: 0m 24s | Train loss: 0.4213\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 363/500 | Epoch Time: 0m 25s | Train loss: 0.4221\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 364/500 | Epoch Time: 0m 25s | Train loss: 0.4217\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 365/500 | Epoch Time: 0m 25s | Train loss: 0.4210\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 366/500 | Epoch Time: 0m 25s | Train loss: 0.4210\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 367/500 | Epoch Time: 0m 24s | Train loss: 0.4205\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 368/500 | Epoch Time: 0m 24s | Train loss: 0.4205\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 369/500 | Epoch Time: 0m 25s | Train loss: 0.4198\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 370/500 | Epoch Time: 0m 25s | Train loss: 0.4203\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 371/500 | Epoch Time: 0m 25s | Train loss: 0.4199\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 372/500 | Epoch Time: 0m 25s | Train loss: 0.4199\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 373/500 | Epoch Time: 0m 25s | Train loss: 0.4209\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 374/500 | Epoch Time: 0m 25s | Train loss: 0.4221\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 375/500 | Epoch Time: 0m 25s | Train loss: 0.4206\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 376/500 | Epoch Time: 0m 24s | Train loss: 0.4194\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 377/500 | Epoch Time: 0m 24s | Train loss: 0.4186\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 378/500 | Epoch Time: 0m 25s | Train loss: 0.4179\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 379/500 | Epoch Time: 0m 24s | Train loss: 0.4197\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 380/500 | Epoch Time: 0m 25s | Train loss: 0.4200\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 381/500 | Epoch Time: 0m 25s | Train loss: 0.4177\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 382/500 | Epoch Time: 0m 25s | Train loss: 0.4178\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 383/500 | Epoch Time: 0m 25s | Train loss: 0.4185\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 384/500 | Epoch Time: 0m 25s | Train loss: 0.4188\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 385/500 | Epoch Time: 0m 25s | Train loss: 0.4186\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 386/500 | Epoch Time: 0m 25s | Train loss: 0.4186\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 387/500 | Epoch Time: 0m 25s | Train loss: 0.4183\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 388/500 | Epoch Time: 0m 25s | Train loss: 0.4181\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 389/500 | Epoch Time: 0m 25s | Train loss: 0.4180\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 390/500 | Epoch Time: 0m 25s | Train loss: 0.4197\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 391/500 | Epoch Time: 0m 25s | Train loss: 0.4186\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 392/500 | Epoch Time: 0m 25s | Train loss: 0.4183\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 393/500 | Epoch Time: 0m 25s | Train loss: 0.4191\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 394/500 | Epoch Time: 0m 25s | Train loss: 0.4212\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 395/500 | Epoch Time: 0m 26s | Train loss: 0.4222\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 396/500 | Epoch Time: 0m 25s | Train loss: 0.4192\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 397/500 | Epoch Time: 0m 26s | Train loss: 0.4186\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 398/500 | Epoch Time: 0m 25s | Train loss: 0.4189\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 399/500 | Epoch Time: 0m 25s | Train loss: 0.4193\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 400/500 | Epoch Time: 0m 25s | Train loss: 0.4187\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 401/500 | Epoch Time: 0m 25s | Train loss: 0.4177\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 402/500 | Epoch Time: 0m 25s | Train loss: 0.4180\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 403/500 | Epoch Time: 0m 25s | Train loss: 0.4177\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 404/500 | Epoch Time: 0m 25s | Train loss: 0.4193\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 405/500 | Epoch Time: 0m 25s | Train loss: 0.4181\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 406/500 | Epoch Time: 0m 24s | Train loss: 0.4174\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 407/500 | Epoch Time: 0m 25s | Train loss: 0.4188\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 408/500 | Epoch Time: 0m 25s | Train loss: 0.4185\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 409/500 | Epoch Time: 0m 25s | Train loss: 0.4175\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 410/500 | Epoch Time: 0m 25s | Train loss: 0.4183\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 411/500 | Epoch Time: 0m 25s | Train loss: 0.4198\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 412/500 | Epoch Time: 0m 25s | Train loss: 0.4206\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 413/500 | Epoch Time: 0m 25s | Train loss: 0.4207\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 414/500 | Epoch Time: 0m 25s | Train loss: 0.4185\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 415/500 | Epoch Time: 0m 25s | Train loss: 0.4203\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 416/500 | Epoch Time: 0m 25s | Train loss: 0.4209\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 417/500 | Epoch Time: 0m 25s | Train loss: 0.4191\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 418/500 | Epoch Time: 0m 25s | Train loss: 0.4186\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 419/500 | Epoch Time: 0m 25s | Train loss: 0.4181\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 420/500 | Epoch Time: 0m 25s | Train loss: 0.4162\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 421/500 | Epoch Time: 0m 25s | Train loss: 0.4158\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 422/500 | Epoch Time: 0m 25s | Train loss: 0.4179\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 423/500 | Epoch Time: 0m 25s | Train loss: 0.4179\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 424/500 | Epoch Time: 0m 25s | Train loss: 0.4164\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 425/500 | Epoch Time: 0m 26s | Train loss: 0.4169\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 426/500 | Epoch Time: 0m 25s | Train loss: 0.4171\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 427/500 | Epoch Time: 0m 25s | Train loss: 0.4168\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 428/500 | Epoch Time: 0m 25s | Train loss: 0.4168\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 429/500 | Epoch Time: 0m 25s | Train loss: 0.4174\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 430/500 | Epoch Time: 0m 25s | Train loss: 0.4172\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 431/500 | Epoch Time: 0m 25s | Train loss: 0.4179\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 432/500 | Epoch Time: 0m 25s | Train loss: 0.4173\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 433/500 | Epoch Time: 0m 25s | Train loss: 0.4196\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 434/500 | Epoch Time: 0m 25s | Train loss: 0.4186\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 435/500 | Epoch Time: 0m 25s | Train loss: 0.4176\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 436/500 | Epoch Time: 0m 25s | Train loss: 0.4181\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 437/500 | Epoch Time: 0m 25s | Train loss: 0.4189\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 438/500 | Epoch Time: 0m 25s | Train loss: 0.4183\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 439/500 | Epoch Time: 0m 25s | Train loss: 0.4175\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 440/500 | Epoch Time: 0m 26s | Train loss: 0.4190\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 441/500 | Epoch Time: 0m 25s | Train loss: 0.4182\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 442/500 | Epoch Time: 0m 25s | Train loss: 0.4170\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 443/500 | Epoch Time: 0m 25s | Train loss: 0.4174\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 444/500 | Epoch Time: 0m 25s | Train loss: 0.4169\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 445/500 | Epoch Time: 0m 25s | Train loss: 0.4171\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 446/500 | Epoch Time: 0m 25s | Train loss: 0.4163\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 447/500 | Epoch Time: 0m 25s | Train loss: 0.4175\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 448/500 | Epoch Time: 0m 25s | Train loss: 0.4170\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 449/500 | Epoch Time: 0m 26s | Train loss: 0.4153\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 450/500 | Epoch Time: 0m 25s | Train loss: 0.4169\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 451/500 | Epoch Time: 0m 26s | Train loss: 0.4187\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 452/500 | Epoch Time: 0m 25s | Train loss: 0.4181\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 453/500 | Epoch Time: 0m 26s | Train loss: 0.4190\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 454/500 | Epoch Time: 0m 26s | Train loss: 0.4162\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 455/500 | Epoch Time: 0m 25s | Train loss: 0.4165\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 456/500 | Epoch Time: 0m 25s | Train loss: 0.4148\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 457/500 | Epoch Time: 0m 26s | Train loss: 0.4150\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 458/500 | Epoch Time: 0m 25s | Train loss: 0.4151\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 459/500 | Epoch Time: 0m 25s | Train loss: 0.4147\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 460/500 | Epoch Time: 0m 25s | Train loss: 0.4162\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 461/500 | Epoch Time: 0m 25s | Train loss: 0.4173\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 462/500 | Epoch Time: 0m 25s | Train loss: 0.4171\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 463/500 | Epoch Time: 0m 26s | Train loss: 0.4169\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 464/500 | Epoch Time: 0m 25s | Train loss: 0.4161\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 465/500 | Epoch Time: 0m 26s | Train loss: 0.4165\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 466/500 | Epoch Time: 0m 25s | Train loss: 0.4161\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 467/500 | Epoch Time: 0m 25s | Train loss: 0.4160\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 468/500 | Epoch Time: 0m 26s | Train loss: 0.4149\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 469/500 | Epoch Time: 0m 25s | Train loss: 0.4143\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 470/500 | Epoch Time: 0m 25s | Train loss: 0.4140\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 471/500 | Epoch Time: 0m 26s | Train loss: 0.4138\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 472/500 | Epoch Time: 0m 26s | Train loss: 0.4139\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 473/500 | Epoch Time: 0m 25s | Train loss: 0.4136\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 474/500 | Epoch Time: 0m 25s | Train loss: 0.4140\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 475/500 | Epoch Time: 0m 25s | Train loss: 0.4146\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 476/500 | Epoch Time: 0m 25s | Train loss: 0.4144\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 477/500 | Epoch Time: 0m 25s | Train loss: 0.4137\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 478/500 | Epoch Time: 0m 25s | Train loss: 0.4138\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 479/500 | Epoch Time: 0m 25s | Train loss: 0.4126\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 480/500 | Epoch Time: 0m 25s | Train loss: 0.4124\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 481/500 | Epoch Time: 0m 26s | Train loss: 0.4139\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 482/500 | Epoch Time: 0m 26s | Train loss: 0.4129\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 483/500 | Epoch Time: 0m 25s | Train loss: 0.4126\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 484/500 | Epoch Time: 0m 25s | Train loss: 0.4139\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 485/500 | Epoch Time: 0m 25s | Train loss: 0.4133\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 486/500 | Epoch Time: 0m 25s | Train loss: 0.4128\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 487/500 | Epoch Time: 0m 25s | Train loss: 0.4128\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 488/500 | Epoch Time: 0m 25s | Train loss: 0.4137\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 489/500 | Epoch Time: 0m 25s | Train loss: 0.4138\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 490/500 | Epoch Time: 0m 25s | Train loss: 0.4150\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 491/500 | Epoch Time: 0m 26s | Train loss: 0.4143\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 492/500 | Epoch Time: 0m 25s | Train loss: 0.4132\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 493/500 | Epoch Time: 0m 25s | Train loss: 0.4163\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 494/500 | Epoch Time: 0m 25s | Train loss: 0.4138\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 495/500 | Epoch Time: 0m 25s | Train loss: 0.4127\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 496/500 | Epoch Time: 0m 25s | Train loss: 0.4122\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 497/500 | Epoch Time: 0m 26s | Train loss: 0.4126\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 498/500 | Epoch Time: 0m 25s | Train loss: 0.4128\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 499/500 | Epoch Time: 0m 25s | Train loss: 0.4134\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch: 500/500 | Epoch Time: 0m 26s | Train loss: 0.4121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_representations = extract_latent_vectors(model, dataloader, device, model_type='Linear')"
      ],
      "metadata": {
        "id": "rmqDO8T-doKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_representations[(0,0)]['vector']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "387PV-bDzyzd",
        "outputId": "824e71f7-d6a7-4fc0-d755-7717318ebfe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.07872151, -0.1469995 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el diccionario en un archivo\n",
        "torch.save(vector_representations, root_drive + BERT_PATH + str(hidden_size) + '_vector_representations_CLS_Linear2.pth')"
      ],
      "metadata": {
        "id": "hAkzCvQ8p4OQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 2  # size of fixed vector\n",
        "vector_representations = torch.load(root_drive + BERT_PATH + str(hidden_size) + '_vector_representations_CLS_Linear2.pth')"
      ],
      "metadata": {
        "id": "AmOB1Djot8z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vector_representations) #(num_sentence,layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32RlZGvQo8XE",
        "outputId": "03c02986-ce9f-48ae-adbc-61470b388005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16548"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_representations_per_layer(num_sentences, vector_representations, layers = 12):\n",
        "  vectors_per_layer = {}\n",
        "  labels = {}\n",
        "  for l in range(layers):\n",
        "    #vectors_per_layer[l] = np.array([vector_representations[(i,l)]['vector'].detach().numpy() for i in range(num_sentences)])\n",
        "    vectors_per_layer[l] = np.array([vector_representations[(i,l)]['vector'] for i in range(num_sentences)])\n",
        "  labels = { i: vector_representations[(i,0)]['label'][0].item() for i in range(num_sentences)}\n",
        "  return vectors_per_layer, labels"
      ],
      "metadata": {
        "id": "XQ-dXKeYTHok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectors_per_layer, labels = get_representations_per_layer(num_sentences, vector_representations)"
      ],
      "metadata": {
        "id": "mBvM7amZVhFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el diccionario en un archivo\n",
        "torch.save(vectors_per_layer, root_drive + BERT_PATH + str(hidden_size) + '_vectors_per_layer_CLS_LSTM.pth')"
      ],
      "metadata": {
        "id": "iZJHKzT9CB5x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}