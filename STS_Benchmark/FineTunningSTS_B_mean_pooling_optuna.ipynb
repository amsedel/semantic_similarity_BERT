{"cells":[{"cell_type":"code","source":["import locale\n","def getpreferredencoding(do_setlocale = True):\n","    return \"UTF-8\"\n","locale.getpreferredencoding = getpreferredencoding"],"metadata":{"id":"qc0QMDk40uHK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-bc_vxzLzGWU","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b71cd585-b8b6-445c-b1da-2eb742ab2173"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting optuna\n","  Downloading optuna-3.1.1-py3-none-any.whl (365 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.10)\n","Collecting cmaes>=0.9.1\n","  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.22.4)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0)\n","Collecting colorlog\n","  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.65.0)\n","Collecting alembic>=1.5.0\n","  Downloading alembic-1.10.4-py3-none-any.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.9/212.9 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n","Collecting Mako\n","  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n","Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n","Successfully installed Mako-1.2.4 alembic-1.10.4 cmaes-0.9.1 colorlog-6.7.0 optuna-3.1.1\n","Mounted at /content/drive\n"]}],"source":["import pandas as pd\n","import torch\n","import numpy as np\n","import random\n","import re\n","import spacy\n","import shutil\n","import matplotlib.pyplot as plt\n","!pip install transformers\n","!pip install optuna\n","import torch.nn as nn\n","import torch.optim as optim\n","from transformers import AutoTokenizer, BertTokenizer, AutoModel, BertModel\n","from torch.utils.data import Dataset, TensorDataset, DataLoader, random_split, RandomSampler, SequentialSampler\n","import time\n","import optuna\n","from scipy.stats import spearmanr\n","import psycopg2\n","import csv\n","import math\n","import os\n","from sqlalchemy import create_engine\n","from optuna.storages import RDBStorage\n","from google.colab import drive\n","from google.colab import files\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["path_base = '/content/drive/MyDrive/Tesis/STS_Benchmark/transformer_tunned_BERT/uncase_base/study_optuna/'"],"metadata":{"id":"pHJ0GN88YjNV"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dy2Cy1hZz_JJ","outputId":"e2d7eed4-dc00-4aa0-ac67-7e7fee9f581d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["#from google.colab import drive\n","#drive.mount('/content/drive')"]},{"cell_type":"code","source":["!wget -O Stsbenchmark.tar.gz http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz\n","shutil.unpack_archive('./Stsbenchmark.tar.gz', extract_dir='./', format='gztar')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uZ5dtmBFZ5kN","outputId":"25d48c9f-f75f-40c1-ca04-ba66eed4b90e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-05-08 17:39:37--  http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz\n","Resolving ixa2.si.ehu.es (ixa2.si.ehu.es)... 158.227.106.100\n","Connecting to ixa2.si.ehu.es (ixa2.si.ehu.es)|158.227.106.100|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: http://ixa2.si.ehu.eus/stswiki/images/4/48/Stsbenchmark.tar.gz [following]\n","--2023-05-08 17:39:38--  http://ixa2.si.ehu.eus/stswiki/images/4/48/Stsbenchmark.tar.gz\n","Resolving ixa2.si.ehu.eus (ixa2.si.ehu.eus)... 158.227.106.100\n","Connecting to ixa2.si.ehu.eus (ixa2.si.ehu.eus)|158.227.106.100|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 409630 (400K) [application/x-gzip]\n","Saving to: ‘Stsbenchmark.tar.gz’\n","\n","Stsbenchmark.tar.gz 100%[===================>] 400.03K  1.03MB/s    in 0.4s    \n","\n","2023-05-08 17:39:38 (1.03 MB/s) - ‘Stsbenchmark.tar.gz’ saved [409630/409630]\n","\n"]}]},{"cell_type":"code","source":["def getSTSBenchmarkSents(filename='sts-train.csv', root='stsbenchmark/', encoding='utf-8'):\n","  f = open(root+filename, 'r', encoding=encoding)\n","  s1, s2, target = [], [], []\n","  for line in f:\n","    example = re.split(r'\\t+', line)\n","    if len(example) > 7:\n","      example = example[:-2]\n","    s2.append(example[-1])\n","    s1.append(example[-2])\n","    target.append(float(example[-3]))\n","  print(\"{} samples: {}\".format(filename, len(target)))\n","  return s1, s2, target"],"metadata":{"id":"jaSIxSSCw5AY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["s1_train,s2_train,target_train = getSTSBenchmarkSents(filename='sts-train.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F_j7JTGEzZyz","outputId":"c542b330-db5e-43a1-8c9b-c69065f6b957"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sts-train.csv samples: 5749\n"]}]},{"cell_type":"code","source":["s1_test,s2_test,target_test= getSTSBenchmarkSents(filename='sts-test.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u_wBVbk6zwRF","outputId":"dcce37ac-de6e-45f2-8dc4-e9c8c2c46340"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sts-test.csv samples: 1379\n"]}]},{"cell_type":"code","source":["s1_dev,s2_dev,target_dev= getSTSBenchmarkSents(filename='sts-dev.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HCAYUG03z14L","outputId":"f59a34ae-ba35-4c08-b2ec-90d69afbfe12"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sts-dev.csv samples: 1500\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X8TBNqYyCj-u","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0387b540-6e9c-4d64-9edb-54a21ef46fe3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda\n"]}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(f'Device: {device}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HQf5A_IsCu9I"},"outputs":[],"source":["BATCH_SIZE = 32\n","MAX_LEN = 128\n","CORPUS = 'STS-B'\n","BERT_PATH = \"bert-base-uncased\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z600WMjxHnOJ","colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["98a5a82031cf4705b6d322cf505c5437","41819b74e4474f7d91ccab2e2e69f314","5c36bf515962479ba94343efab69de3c","da6b8766860c4691b5c7c2481ce0a96b","7b7d60bd0dbb4e1ebb120d5c2af0fb62","c8c9543dfcde4546a318314b05c5fcbb","5dc24cd0139548409546e9fa86276ee3","2bc5598ad34946f49e453a9ebe5571d5","85529b99b06645f5b535161a866b32c7","43a1dc2a47ae4ab49d1335c768d9a240","c7b0b2c668634cd3bd15e1d37cc2b834","8fb005ce27a945c18b3ba2fee7e5d4f4","406259d592ed44a6bd059efb414ebd18","7954d53bdb964810833a10ed9cb5e5fd","780ab873be8d418fb6313e6db68cf8e7","982e9f5008d247c7a48a2989be45093e","39a8954dfd5b41faab9344050136aeb7","89f177c2f6c044968ef68fc72f1cd121","47bf56159b954ceca9ebeec00c6b81d5","90b27601ccc34feb972fafb2bdf960a6","26972260f1794fc8a4abc8ca117eaa98","64ac94b8b2b342d6ae8bb1d0be96b795","bef607c1b61c46fb888f25be122b54d1","b7416d089d824073b1b0e0767acd2b61","295e44e610d142e892fc78fa863e4313","1870f3b6924b45be85145485cee6344f","9803a589454e46f8a3503a0da500016f","c2e4b26fb1a645f5a92c1e56422f4bca","6534a49a432c40fd9c952ef0a8ebd7d5","1be2b125fb7347d985782bd1a08c04c6","88a7a7592a16428a96741b8296a795e3","cf62ffe976c244e59d8bcbc83dbeda3d","6242496f4126410d89dfacc8ed034d79"]},"outputId":"df317732-59c9-413f-a6fc-08a85f88a205"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98a5a82031cf4705b6d322cf505c5437"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fb005ce27a945c18b3ba2fee7e5d4f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bef607c1b61c46fb888f25be122b54d1"}},"metadata":{}}],"source":["TOKENIZER = BertTokenizer.from_pretrained(BERT_PATH, do_lower_case=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pVdOQNbvVnln"},"outputs":[],"source":["def encode_sents(sents1, sents2):\n","    input_ids_ = []\n","    attention_masks_ = []\n","    type_ids_ = []\n","    for i, sent1 in enumerate(sents1):\n","        encoded_dict = TOKENIZER.encode_plus(\n","                            sent1,                      # Sentence 1 to encode.\n","                            sents2[i],                  # Sentence 2 to encode.\n","                            add_special_tokens = True,  # Add '[CLS]' and '[SEP]'\n","                            truncation = True,\n","                            max_length = MAX_LEN,       # Pad & truncate all sentences.\n","                            pad_to_max_length = True,\n","                            return_attention_mask = True,   # Construct attn. masks.\n","                            return_tensors = 'pt',     # Return pytorch tensors.\n","                      )\n","\n","        # Add the encoded sentence to the list.\n","        input_ids_.append(encoded_dict['input_ids'])\n","\n","        # And its attention mask (simply differentiates padding from non-padding).\n","        attention_masks_.append(encoded_dict['attention_mask'])\n","\n","        type_ids_.append(encoded_dict['token_type_ids'])\n","    return input_ids_, attention_masks_, type_ids_"]},{"cell_type":"code","source":["def getEncodedTensors(s1, s2, labels):\n","    input_ids, attention_masks, type_ids = encode_sents(s1, s2)\n","    input_ids = torch.cat(input_ids, dim=0)\n","    attention_masks = torch.cat(attention_masks, dim=0)\n","    type_ids = torch.cat(type_ids, dim=0)\n","    labels = torch.tensor(labels)\n","    return input_ids, attention_masks, type_ids, labels"],"metadata":{"id":"906LtLLC9Y_Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_ids_train,attention_masks_train,type_ids_train,labels_train = getEncodedTensors(s1_train,s2_train,target_train)"],"metadata":{"id":"t6ru4f5S9-qd","colab":{"base_uri":"https://localhost:8080/"},"outputId":"00427c20-ddec-4ba4-d9c9-f9e70cbb8765"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["input_ids_eval, attention_masks_eval, type_ids_eval, labels_eval = getEncodedTensors(s1_dev, s2_dev, target_dev)"],"metadata":{"id":"-bL1MWnB_-9d"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"adsDoOZNdgVR"},"outputs":[],"source":["# Combine the training inputs into a TensorDataset.\n","train_dataset = TensorDataset(input_ids_train, attention_masks_train, type_ids_train, labels_train)\n","val_dataset = TensorDataset(input_ids_eval, attention_masks_eval, type_ids_eval, labels_eval)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4L0SrB_JlaCY"},"outputs":[],"source":["# Create the DataLoaders for our training and test sets.\n","# We'll take training samples in random order.\n","torch.manual_seed(42)\n","train_loader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = BATCH_SIZE # Trains with this batch size.\n","            #num_workers=2\n","        )\n","torch.manual_seed(42)\n","val_loader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = BATCH_SIZE # Evaluate with this batch size.\n","            #num_workers=2\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nMWrY0KxnEMi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0fbe7188-5c9a-4a2f-ee48-632629698a1b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of train batches: 180\n","Number of evaluation batches: 47\n"]}],"source":["# See first batch\n","#batch = next(iter(train_loader))\n","#print(batch[0]) # 0 -> input_ids , 1 -> attention_masks, 2 -> type_ids, 3 -> targets\n","#print(train_loader.batch_size) #tamaño del batch\n","print('Number of train batches: {}'.format(len(train_loader)))# número de batches\n","print('Number of evaluation batches: {}'.format(len(val_loader)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KkXY8l6PqLwi"},"outputs":[],"source":["class BertBaseUncasedRegressor(nn.Module):\n","  def __init__(self, num_classes = 1, dropout=0.1, attentions=True, n_layers = 0):\n","      super().__init__()\n","      self.bert = BertModel.from_pretrained(BERT_PATH, output_attentions=attentions) #load the model\n","      # Return:\n","      # last_hidden_state.shape -> [batch_size, num_tokens_in_sequence,hidden_size] (bert_base hidden_size = 768)\n","      # pooler_output.shape -> [batch_size, hidden_size] se utiliza una capa de pooling simple que aplica una transformación\n","      # lineal seguida de una función de activación tangente hiperbólica (tanh) a la última representación oculta (last_hidden_state) del token [CLS].\n","      layers = []\n","      for _ in range(n_layers):\n","          layers.append(nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size)) #self.bert.config.hidden_size -> nos da el tamaño oculto\n","          layers.append(nn.Dropout(dropout))\n","      layers.append(nn.Linear(self.bert.config.hidden_size, num_classes)) #self.bert.config.hidden_size -> nos da el tamaño oculto\n","\n","      self.regressor = nn.Sequential(*layers)\n","\n","\n","  def forward(self, input_ids, type_ids, mask):\n","      bert_output =self.bert(input_ids=input_ids, token_type_ids = type_ids, attention_mask= mask)\n","      attention_mask = mask.unsqueeze(-1).expand(bert_output.last_hidden_state.shape).float()\n","      embeddings = bert_output.last_hidden_state * attention_mask\n","      embeddings_sum = torch.sum(embeddings, dim=1)\n","      counts = torch.clamp(attention_mask.sum(1), min=1e-9)\n","      output_mean_pooling = embeddings_sum / counts\n","      #output = bert_output.pooler_output\n","      #output = bert_output.last_hidden_state[:, 0, :]\n","      logits = self.regressor(output_mean_pooling)\n","      #logits = self.regressor(output_drop)\n","      return logits, bert_output"]},{"cell_type":"code","source":["pp = torch.tensor([[[1,2,3],[4,5,6]],[[11,12,13],[14,15,16]]])\n","pp2 = torch.tensor([[[1,1,1],[1,1,0]],[[1,1,1],[1,0,0]]])\n","ma = pp*pp2\n","sum = torch.sum(ma, dim=1)\n","print(ma)\n","print(ma.shape)\n","print(sum)\n","print(sum.shape)\n","counts = torch.clamp(pp2.sum(1), min=1e-9)\n","print(counts)\n","print(sum/counts)"],"metadata":{"id":"RXBGZb2Xc2yc"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gm5OXHZoGZ6V","outputId":"93ed376b-a80b-405b-9afb-23aa0f7dc577"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["\"\"\"model = BertBaseUncasedRegressor().to(device)\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vx7UQjL5GJLu"},"outputs":[],"source":["\"\"\"\n","criterion = nn.MSELoss()\n","LEARNING_RATE = 0.0001\n","optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","\"\"\""]},{"cell_type":"code","source":["def pearson_corr(y_pred, y_true):\n","    all_preds = np.concatenate(y_pred)\n","    all_targets = np.concatenate(y_true)\n","    return np.corrcoef(all_preds, all_targets)[0, 1]"],"metadata":{"id":"n3ur6ZV3_Gb6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def spearman_corr(y_pred, y_true):\n","    all_preds = np.concatenate(y_pred)\n","    all_targets = np.concatenate(y_true)\n","\n","    corr, _ = spearmanr(all_preds, all_targets)\n","    return corr"],"metadata":{"id":"P6-Jax0r_Mhf"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fdInbGmYrUfw"},"outputs":[],"source":["def train_loop(model,loader,optimizer,criterion,device,clip = 1.0):\n","    #Training loop\n","    model.train()\n","    loss_sum = 0\n","    all_preds = []\n","    all_targets = []\n","    seed = 42\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","\n","    for i, batch in enumerate(loader):\n","\n","        b_input_ids = batch[0].to(device)\n","        b_attention_mask = batch[1].to(device)\n","        b_type_ids = batch[2].to(device)\n","        labels = batch[3].to(device)\n","\n","        optimizer.zero_grad()\n","        #Forward\n","        outputs, _ = model(input_ids=b_input_ids, type_ids = b_type_ids, mask = b_attention_mask)\n","        outputs = outputs.squeeze(-1)\n","        #Loss\n","        loss = criterion(outputs.view(-1), labels.float())\n","        #Backprop\n","        loss.backward()\n","        #prevent gradients from exploding\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        #Update params\n","        optimizer.step()\n","\n","        loss_sum += loss.item()\n","\n","        all_preds.append(outputs.detach().cpu().numpy())\n","        all_targets.append(labels.float().detach().cpu().numpy())\n","\n","    epoch_train_loss = loss_sum / len(loader)\n","    epoch_train_pearson = pearson_corr(all_preds, all_targets)\n","    epoch_train_spearman = spearman_corr(all_preds, all_targets)\n","\n","    return epoch_train_loss, epoch_train_pearson, epoch_train_spearman\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CxO7AgRRtnnk"},"outputs":[],"source":["def evaluation_loop(model,loader,criterion,device):\n","    #Evaluation loop\n","    seed = 42\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    model.eval()\n","    with torch.no_grad():\n","        loss_sum = 0\n","        all_preds = []\n","        all_targets = []\n","\n","        for i, batch in enumerate(loader):\n","            b_input_ids = batch[0].to(device)\n","            b_attention_mask = batch[1].to(device)\n","            b_type_ids = batch[2].to(device)\n","            labels = batch[3].to(device)\n","\n","            #Forward\n","            outputs, _ = model(input_ids=b_input_ids, type_ids = b_type_ids, mask = b_attention_mask)\n","            outputs = outputs.squeeze(-1)\n","            #Loss\n","            loss = criterion(outputs.view(-1), labels.float())\n","\n","            loss_sum += loss.item()\n","\n","            all_preds.append(outputs.detach().cpu().numpy())\n","            all_targets.append(labels.float().detach().cpu().numpy())\n","\n","        epoch_dev_loss = loss_sum / len(loader)\n","        epoch_dev_pearson = pearson_corr(all_preds, all_targets)\n","        epoch_dev_spearman = spearman_corr(all_preds, all_targets)\n","\n","    return epoch_dev_loss, epoch_dev_pearson, epoch_dev_spearman"]},{"cell_type":"code","source":["def save_metrics_dataframe(metrics_dict, study_name, path_base):\n","  # Abrir archivo en modo escritura y especificar el separador de campos\n","  path = path_base + 'metrics_' + study_name + \".csv\"\n","  with open(path, \"a+\", newline=\"\") as f:\n","      metrics = [metrics_dict]\n","      # Crear objeto escritor CSV y especificar el separador de campos\n","      metrics_csv = csv.DictWriter(f, fieldnames=['train_loss','valid_loss','spearman_train','spearman_val','pearson_train','pearson_val'],delimiter=\",\")\n","\n","      # Verificar si se ha escrito el encabezado del archivo\n","      if f.tell() == 0:\n","        metrics_csv.writeheader()\n","\n","      # Escribir cada fila de datos\n","      for metric in metrics:\n","          metrics_csv.writerow(metric)"],"metadata":{"id":"dxgbOy7GY0I_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["study_name = 'study-bert-mean-pooling-base'"],"metadata":{"id":"Meh7L_p3ZXm-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def isNan(value):\n","  return 0 if math.isnan(value) else value"],"metadata":{"id":"9dZeuPPWZV-R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def objective(trial):\n","  params = {\n","      \"num_layers\": trial.suggest_int(\"num_layer\", 0, 3),\n","      \"dropout\": trial.suggest_uniform(\"dropout\", 0, 0.7),\n","      \"optimizer\": trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]),\n","      \"learning_rate\": trial.suggest_loguniform(\"learning_rate\",1e-5, 1e-4)\n","  }\n","\n","  model = BertBaseUncasedRegressor(dropout=params[\"dropout\"], n_layers = params[\"num_layers\"]).to(device)\n","  criterion = nn.MSELoss()\n","  optimizer = getattr(optim, params[\"optimizer\"])(model.parameters(), lr=params[\"learning_rate\"])\n","\n","  NUM_EPOCHS = 4\n","  best_valid_loss = float('inf')\n","  MODEL_FILE_NAME = CORPUS+'_'+BERT_PATH+'_'+str(MAX_LEN)+'_tunned_model.pt'\n","  history = {\"train\": {\"loss\": []}, \"test\": {\"loss\": []}}\n","\n","  torch.cuda.empty_cache()\n","  seed = 42\n","  np.random.seed(seed)\n","  random.seed(seed)\n","  torch.manual_seed(seed)\n","  torch.cuda.manual_seed_all(seed)\n","\n","  train_loss_list, val_loss_list, spearman_train, spearman_val, pearson_train, pearson_val = [], [], [], [], [], []\n","\n","  for epoch in range(NUM_EPOCHS):\n","\n","    start_time = time.time()\n","\n","    epoch_train_loss, epoch_train_pearson, epoch_train_spearman = train_loop(model,train_loader,optimizer,criterion,device)\n","    epoch_dev_loss, epoch_dev_pearson, epoch_dev_spearman = evaluation_loop(model,val_loader,criterion,device)\n","\n","    elapsed_time = time.time() - start_time\n","\n","    if trial.should_prune():\n","      raise optuna.exceptions.TrialPruned()\n","\n","    #nos quedamos con el modelo que tiene mejor pérdida de validación\n","    if epoch_dev_loss < best_valid_loss:\n","      best_valid_loss = epoch_dev_loss\n","      torch.save(model.state_dict(), MODEL_FILE_NAME)\n","\n","    train_loss_list.append(isNan(epoch_train_loss))\n","    val_loss_list.append(isNan(epoch_dev_loss))\n","    spearman_train.append(isNan(epoch_train_spearman))\n","    spearman_val.append(isNan(epoch_dev_spearman))\n","    pearson_train.append(isNan(epoch_train_pearson))\n","    pearson_val.append(isNan(epoch_dev_pearson))\n","\n","    history[\"train\"][\"loss\"].append(epoch_train_loss)\n","    history[\"test\"][\"loss\"].append(epoch_dev_loss)\n","\n","    print('-' * 80)\n","    print(f'Epoch: {epoch+1:03}/{NUM_EPOCHS} | Time: {elapsed_time:.4f}s | Train loss: {epoch_train_loss:.4f} | Dev loss: {epoch_dev_loss:.4f}')\n","    print(f'Train Pearson Coef: {epoch_train_pearson:.4f} | Dev Pearson Coef: {epoch_dev_pearson:.4f}')\n","    print(f'Train Spearman Coef: {epoch_train_spearman:.4f} | Dev Spearman Coef: {epoch_dev_spearman:.4f}')\n","\n","  metrics_dict = {\n","      'train_loss' : train_loss_list,\n","      'valid_loss' : val_loss_list,\n","      'spearman_train': spearman_train,\n","      'spearman_val': spearman_val,\n","      'pearson_train': pearson_train,\n","      'pearson_val': pearson_val\n","  }\n","\n","  save_metrics_dataframe(metrics_dict, study_name, path_base)\n","\n","  return best_valid_loss"],"metadata":{"id":"owIEB8g8YyFT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#obtener ip de colab para dar acceso a la DB\n","!curl ipecho.net/plain"],"metadata":{"id":"10Qj8EqSZEiD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ada5aba6-4eb8-49be-8610-8ae7535c8a09"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["34.32.145.133"]}]},{"cell_type":"code","source":["# Define the connection URL.\n","url = \"postgresql://{user}:{password}@{host}:{port}/{database}\"\n","url = url.format(\n","    user='postgres',\n","    password=\"password\",\n","    host='35.184.132.46',\n","    port='5432',\n","    database='stsb-base-mean-pooling',\n",")\n","\n","# Create the engine and the database (if it doesn't exist yet).\n","engine = create_engine(url)\n","\n","\n","# Define the storage.\n","storage = RDBStorage(url)"],"metadata":{"id":"g0axO59jZGj_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define el estudio de Optuna utilizando el storage\n","study = optuna.create_study(study_name=study_name, direction=\"minimize\", storage=storage, load_if_exists=True)"],"metadata":{"id":"kFkzJHFSZRAz","colab":{"base_uri":"https://localhost:8080/"},"outputId":"39783552-fbb9-4dd2-907f-e0baa06d8702"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-05-08 17:40:07,526]\u001b[0m Using an existing study with name 'study-bert-mean-pooling-base' instead of creating a new one.\u001b[0m\n"]}]},{"cell_type":"code","source":["study.optimize(objective, n_trials=10)"],"metadata":{"id":"Cun6M9lVY1WH","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["3e4b8eb1e7734458939404a4032a3e9e","f7c47536a3df419396a9e331c81b03cf","a8d8b250ce794ac787deecdf47329866","d782697103714041a7d0c540917d0844","2b43e1daac0a4a1aa06d7176ff82ff85","178e9f55f17b4eeda2ee2114e846da84","c111bd1ca5d4404bbb820db6522edea5","ec751d6ec20345b2b899bac0aa5df5a8","2f498e047bff49d7b73b9b1f99953dd6","c7ed9ea109064c4784f3bd558d717857","3b8772baae3248f3b1545c204303581e"]},"outputId":"80850055-9849-4199-9da8-1db997f45ba2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-27-53008359ab4f>:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  \"dropout\": trial.suggest_uniform(\"dropout\", 0, 0.7),\n","<ipython-input-27-53008359ab4f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\",1e-5, 1e-4)\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e4b8eb1e7734458939404a4032a3e9e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","Epoch: 001/4 | Time: 116.1788s | Train loss: 0.9328 | Dev loss: 0.4845\n","Train Pearson Coef: 0.7551 | Dev Pearson Coef: 0.8863\n","Train Spearman Coef: 0.7245 | Dev Spearman Coef: 0.8821\n","--------------------------------------------------------------------------------\n","Epoch: 002/4 | Time: 120.6032s | Train loss: 0.3254 | Dev loss: 0.6899\n","Train Pearson Coef: 0.9210 | Dev Pearson Coef: 0.8894\n","Train Spearman Coef: 0.9049 | Dev Spearman Coef: 0.8846\n","--------------------------------------------------------------------------------\n","Epoch: 003/4 | Time: 123.7579s | Train loss: 0.1764 | Dev loss: 0.4725\n","Train Pearson Coef: 0.9581 | Dev Pearson Coef: 0.8961\n","Train Spearman Coef: 0.9509 | Dev Spearman Coef: 0.8912\n","--------------------------------------------------------------------------------\n","Epoch: 004/4 | Time: 125.5288s | Train loss: 0.1193 | Dev loss: 0.4521\n","Train Pearson Coef: 0.9719 | Dev Pearson Coef: 0.8945\n","Train Spearman Coef: 0.9676 | Dev Spearman Coef: 0.8910\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-05-08 17:48:51,986]\u001b[0m Trial 141 finished with value: 0.45209156103590703 and parameters: {'num_layer': 1, 'dropout': 0.0774883090038255, 'optimizer': 'RMSprop', 'learning_rate': 2.870329876059525e-05}. Best is trial 131 with value: 0.4364643043026011.\u001b[0m\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","Epoch: 001/4 | Time: 123.6297s | Train loss: 1.3436 | Dev loss: 0.7334\n","Train Pearson Coef: 0.6223 | Dev Pearson Coef: 0.8531\n","Train Spearman Coef: 0.5922 | Dev Spearman Coef: 0.8529\n","--------------------------------------------------------------------------------\n","Epoch: 002/4 | Time: 125.0165s | Train loss: 0.5752 | Dev loss: 0.7016\n","Train Pearson Coef: 0.8555 | Dev Pearson Coef: 0.8668\n","Train Spearman Coef: 0.8293 | Dev Spearman Coef: 0.8641\n","--------------------------------------------------------------------------------\n","Epoch: 003/4 | Time: 125.8772s | Train loss: 0.3653 | Dev loss: 0.5874\n","Train Pearson Coef: 0.9110 | Dev Pearson Coef: 0.8737\n","Train Spearman Coef: 0.8944 | Dev Spearman Coef: 0.8681\n","--------------------------------------------------------------------------------\n","Epoch: 004/4 | Time: 125.5742s | Train loss: 0.2653 | Dev loss: 0.5753\n","Train Pearson Coef: 0.9361 | Dev Pearson Coef: 0.8751\n","Train Spearman Coef: 0.9240 | Dev Spearman Coef: 0.8714\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-05-08 17:57:30,902]\u001b[0m Trial 142 finished with value: 0.5752580768250405 and parameters: {'num_layer': 1, 'dropout': 0.07987591500454133, 'optimizer': 'RMSprop', 'learning_rate': 2.876286159568434e-05}. Best is trial 131 with value: 0.4364643043026011.\u001b[0m\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","Epoch: 001/4 | Time: 123.5609s | Train loss: 1.4777 | Dev loss: 0.6040\n","Train Pearson Coef: 0.5776 | Dev Pearson Coef: 0.8655\n","Train Spearman Coef: 0.5396 | Dev Spearman Coef: 0.8598\n","--------------------------------------------------------------------------------\n","Epoch: 002/4 | Time: 125.6612s | Train loss: 0.4876 | Dev loss: 0.7344\n","Train Pearson Coef: 0.8793 | Dev Pearson Coef: 0.8745\n","Train Spearman Coef: 0.8535 | Dev Spearman Coef: 0.8693\n","--------------------------------------------------------------------------------\n","Epoch: 003/4 | Time: 125.1737s | Train loss: 0.2563 | Dev loss: 0.6474\n","Train Pearson Coef: 0.9385 | Dev Pearson Coef: 0.8741\n","Train Spearman Coef: 0.9269 | Dev Spearman Coef: 0.8685\n","--------------------------------------------------------------------------------\n","Epoch: 004/4 | Time: 125.3631s | Train loss: 0.1746 | Dev loss: 0.5323\n","Train Pearson Coef: 0.9588 | Dev Pearson Coef: 0.8791\n","Train Spearman Coef: 0.9527 | Dev Spearman Coef: 0.8731\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-05-08 18:06:07,283]\u001b[0m Trial 143 finished with value: 0.5322544010395699 and parameters: {'num_layer': 1, 'dropout': 0.29181264629142595, 'optimizer': 'RMSprop', 'learning_rate': 3.0385193064409116e-05}. Best is trial 131 with value: 0.4364643043026011.\u001b[0m\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","Epoch: 001/4 | Time: 126.2553s | Train loss: 1.1546 | Dev loss: 0.4946\n","Train Pearson Coef: 0.6855 | Dev Pearson Coef: 0.8857\n","Train Spearman Coef: 0.6552 | Dev Spearman Coef: 0.8824\n","--------------------------------------------------------------------------------\n","Epoch: 002/4 | Time: 125.2931s | Train loss: 0.3408 | Dev loss: 0.5146\n","Train Pearson Coef: 0.9172 | Dev Pearson Coef: 0.8896\n","Train Spearman Coef: 0.9007 | Dev Spearman Coef: 0.8850\n","--------------------------------------------------------------------------------\n","Epoch: 003/4 | Time: 125.3353s | Train loss: 0.1866 | Dev loss: 0.5088\n","Train Pearson Coef: 0.9557 | Dev Pearson Coef: 0.8921\n","Train Spearman Coef: 0.9481 | Dev Spearman Coef: 0.8880\n","--------------------------------------------------------------------------------\n","Epoch: 004/4 | Time: 125.6875s | Train loss: 0.1316 | Dev loss: 0.4646\n","Train Pearson Coef: 0.9689 | Dev Pearson Coef: 0.8926\n","Train Spearman Coef: 0.9643 | Dev Spearman Coef: 0.8890\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-05-08 18:14:45,820]\u001b[0m Trial 144 finished with value: 0.4646331566445371 and parameters: {'num_layer': 1, 'dropout': 0.0639856292174052, 'optimizer': 'RMSprop', 'learning_rate': 2.7141584901659573e-05}. Best is trial 131 with value: 0.4364643043026011.\u001b[0m\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","Epoch: 001/4 | Time: 125.6716s | Train loss: 1.4626 | Dev loss: 0.5881\n","Train Pearson Coef: 0.5766 | Dev Pearson Coef: 0.8681\n","Train Spearman Coef: 0.5357 | Dev Spearman Coef: 0.8639\n","--------------------------------------------------------------------------------\n","Epoch: 002/4 | Time: 125.4774s | Train loss: 0.4888 | Dev loss: 0.5256\n","Train Pearson Coef: 0.8787 | Dev Pearson Coef: 0.8759\n","Train Spearman Coef: 0.8553 | Dev Spearman Coef: 0.8729\n","--------------------------------------------------------------------------------\n","Epoch: 003/4 | Time: 125.6047s | Train loss: 0.2533 | Dev loss: 0.6359\n","Train Pearson Coef: 0.9393 | Dev Pearson Coef: 0.8760\n","Train Spearman Coef: 0.9268 | Dev Spearman Coef: 0.8732\n","--------------------------------------------------------------------------------\n","Epoch: 004/4 | Time: 125.4206s | Train loss: 0.1810 | Dev loss: 0.5383\n","Train Pearson Coef: 0.9571 | Dev Pearson Coef: 0.8773\n","Train Spearman Coef: 0.9494 | Dev Spearman Coef: 0.8734\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-05-08 18:23:23,622]\u001b[0m Trial 145 finished with value: 0.5255745769815242 and parameters: {'num_layer': 1, 'dropout': 0.11984379685117892, 'optimizer': 'RMSprop', 'learning_rate': 2.9040247471901766e-05}. Best is trial 131 with value: 0.4364643043026011.\u001b[0m\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","Epoch: 001/4 | Time: 126.1393s | Train loss: 0.8242 | Dev loss: 0.5096\n","Train Pearson Coef: 0.7865 | Dev Pearson Coef: 0.8877\n","Train Spearman Coef: 0.7568 | Dev Spearman Coef: 0.8855\n","--------------------------------------------------------------------------------\n","Epoch: 002/4 | Time: 125.3838s | Train loss: 0.2561 | Dev loss: 0.5198\n","Train Pearson Coef: 0.9385 | Dev Pearson Coef: 0.8968\n","Train Spearman Coef: 0.9255 | Dev Spearman Coef: 0.8931\n","--------------------------------------------------------------------------------\n","Epoch: 003/4 | Time: 125.3588s | Train loss: 0.1326 | Dev loss: 0.4553\n","Train Pearson Coef: 0.9686 | Dev Pearson Coef: 0.8942\n","Train Spearman Coef: 0.9630 | Dev Spearman Coef: 0.8907\n","--------------------------------------------------------------------------------\n","Epoch: 004/4 | Time: 125.4698s | Train loss: 0.1030 | Dev loss: 0.4859\n","Train Pearson Coef: 0.9757 | Dev Pearson Coef: 0.8977\n","Train Spearman Coef: 0.9707 | Dev Spearman Coef: 0.8939\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-05-08 18:32:02,144]\u001b[0m Trial 146 finished with value: 0.45528650632564055 and parameters: {'num_layer': 1, 'dropout': 0.09058375234947526, 'optimizer': 'RMSprop', 'learning_rate': 2.543808336693201e-05}. Best is trial 131 with value: 0.4364643043026011.\u001b[0m\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","Epoch: 001/4 | Time: 126.2258s | Train loss: 0.8278 | Dev loss: 0.5565\n","Train Pearson Coef: 0.7856 | Dev Pearson Coef: 0.8843\n","Train Spearman Coef: 0.7534 | Dev Spearman Coef: 0.8815\n","--------------------------------------------------------------------------------\n","Epoch: 002/4 | Time: 125.6052s | Train loss: 0.2561 | Dev loss: 0.5350\n","Train Pearson Coef: 0.9384 | Dev Pearson Coef: 0.8908\n","Train Spearman Coef: 0.9247 | Dev Spearman Coef: 0.8865\n","--------------------------------------------------------------------------------\n","Epoch: 003/4 | Time: 126.0200s | Train loss: 0.1442 | Dev loss: 0.4774\n","Train Pearson Coef: 0.9659 | Dev Pearson Coef: 0.8896\n","Train Spearman Coef: 0.9596 | Dev Spearman Coef: 0.8885\n","--------------------------------------------------------------------------------\n","Epoch: 004/4 | Time: 126.0482s | Train loss: 0.1020 | Dev loss: 0.4472\n","Train Pearson Coef: 0.9760 | Dev Pearson Coef: 0.8954\n","Train Spearman Coef: 0.9717 | Dev Spearman Coef: 0.8923\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-05-08 18:40:44,602]\u001b[0m Trial 147 finished with value: 0.44723292424323713 and parameters: {'num_layer': 1, 'dropout': 0.14328439549153799, 'optimizer': 'RMSprop', 'learning_rate': 2.5084606604849697e-05}. Best is trial 131 with value: 0.4364643043026011.\u001b[0m\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","Epoch: 001/4 | Time: 125.2088s | Train loss: 0.8829 | Dev loss: 0.5459\n","Train Pearson Coef: 0.7691 | Dev Pearson Coef: 0.8839\n","Train Spearman Coef: 0.7385 | Dev Spearman Coef: 0.8802\n","--------------------------------------------------------------------------------\n","Epoch: 002/4 | Time: 125.9036s | Train loss: 0.2792 | Dev loss: 0.6077\n","Train Pearson Coef: 0.9327 | Dev Pearson Coef: 0.8905\n","Train Spearman Coef: 0.9168 | Dev Spearman Coef: 0.8867\n","--------------------------------------------------------------------------------\n","Epoch: 003/4 | Time: 125.7863s | Train loss: 0.1551 | Dev loss: 0.5298\n","Train Pearson Coef: 0.9632 | Dev Pearson Coef: 0.8869\n","Train Spearman Coef: 0.9556 | Dev Spearman Coef: 0.8829\n","--------------------------------------------------------------------------------\n","Epoch: 004/4 | Time: 125.7080s | Train loss: 0.1068 | Dev loss: 0.4910\n","Train Pearson Coef: 0.9748 | Dev Pearson Coef: 0.8937\n","Train Spearman Coef: 0.9697 | Dev Spearman Coef: 0.8899\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-05-08 18:49:24,385]\u001b[0m Trial 148 finished with value: 0.49102906565716925 and parameters: {'num_layer': 1, 'dropout': 0.1417849176794103, 'optimizer': 'RMSprop', 'learning_rate': 2.274083723156822e-05}. Best is trial 131 with value: 0.4364643043026011.\u001b[0m\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","Epoch: 001/4 | Time: 126.2698s | Train loss: 0.8168 | Dev loss: 0.5414\n","Train Pearson Coef: 0.7881 | Dev Pearson Coef: 0.8854\n","Train Spearman Coef: 0.7570 | Dev Spearman Coef: 0.8822\n","--------------------------------------------------------------------------------\n","Epoch: 002/4 | Time: 125.2183s | Train loss: 0.2604 | Dev loss: 0.5830\n","Train Pearson Coef: 0.9373 | Dev Pearson Coef: 0.8899\n","Train Spearman Coef: 0.9231 | Dev Spearman Coef: 0.8861\n","--------------------------------------------------------------------------------\n","Epoch: 003/4 | Time: 125.4350s | Train loss: 0.1293 | Dev loss: 0.4785\n","Train Pearson Coef: 0.9694 | Dev Pearson Coef: 0.8890\n","Train Spearman Coef: 0.9628 | Dev Spearman Coef: 0.8854\n","--------------------------------------------------------------------------------\n","Epoch: 004/4 | Time: 125.5662s | Train loss: 0.1057 | Dev loss: 0.5214\n","Train Pearson Coef: 0.9752 | Dev Pearson Coef: 0.8936\n","Train Spearman Coef: 0.9698 | Dev Spearman Coef: 0.8900\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-05-08 18:58:02,853]\u001b[0m Trial 149 finished with value: 0.47847019770043964 and parameters: {'num_layer': 1, 'dropout': 0.0998867219505796, 'optimizer': 'RMSprop', 'learning_rate': 2.1268523118731523e-05}. Best is trial 131 with value: 0.4364643043026011.\u001b[0m\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","Epoch: 001/4 | Time: 126.1524s | Train loss: 0.8125 | Dev loss: 0.5826\n","Train Pearson Coef: 0.7899 | Dev Pearson Coef: 0.8889\n","Train Spearman Coef: 0.7589 | Dev Spearman Coef: 0.8865\n","--------------------------------------------------------------------------------\n","Epoch: 002/4 | Time: 125.1313s | Train loss: 0.2526 | Dev loss: 0.4813\n","Train Pearson Coef: 0.9393 | Dev Pearson Coef: 0.8968\n","Train Spearman Coef: 0.9262 | Dev Spearman Coef: 0.8931\n","--------------------------------------------------------------------------------\n","Epoch: 003/4 | Time: 125.4868s | Train loss: 0.1378 | Dev loss: 0.4490\n","Train Pearson Coef: 0.9674 | Dev Pearson Coef: 0.8951\n","Train Spearman Coef: 0.9610 | Dev Spearman Coef: 0.8914\n","--------------------------------------------------------------------------------\n","Epoch: 004/4 | Time: 125.9507s | Train loss: 0.0993 | Dev loss: 0.6022\n","Train Pearson Coef: 0.9766 | Dev Pearson Coef: 0.8944\n","Train Spearman Coef: 0.9720 | Dev Spearman Coef: 0.8895\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-05-08 19:06:42,602]\u001b[0m Trial 150 finished with value: 0.4489823116901073 and parameters: {'num_layer': 1, 'dropout': 0.10825515065611765, 'optimizer': 'RMSprop', 'learning_rate': 2.509632906548691e-05}. Best is trial 131 with value: 0.4364643043026011.\u001b[0m\n"]}]},{"cell_type":"code","source":["df_optuna = study.trials_dataframe(attrs=(\"number\", \"value\", \"params\", \"state\")).dropna(subset=['value']) #eliminar valores NaN\n","# Leer el archivo metrics.CSV y crear un DataFrame\n","path_metrics = path_base + 'metrics_' + study_name + \".csv\"\n","df_metrics = pd.read_csv(path_metrics).dropna(subset=['train_loss'])\n","print(len(df_optuna))\n","print(len(df_metrics ))"],"metadata":{"id":"QgLFZ3WuZnpZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1efe7ec4-bc2d-4eb9-d146-73a2b5e59977"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["150\n","10\n"]}]},{"cell_type":"code","source":["#df_metrics = df_metrics[['train_loss', 'valid_loss', 'pearson_train', 'pearson_val', 'spearman_train', 'spearman_val']]"],"metadata":{"id":"EUzeE8-9R-Jm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#df_metrics = df_metrics.rename(columns={'train_loss': 'train_loss', 'valid_loss': 'val_loss', 'pearson_train': 'Pearson_train','pearson_val': 'Pearson_val', 'spearman_train': 'Spearman_train', 'spearman_val': 'Spearman_val'})"],"metadata":{"id":"4zknzTnaL17p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_metrics"],"metadata":{"id":"beciGKSGSu-U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_old = pd.read_csv(path_base + study_name + \"_COMPLETE_SORT.csv\")\n","print(\"Old trials: \", len(df_old))"],"metadata":{"id":"x9nvclWeZ1gc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b65796ce-cf3b-490e-e342-b37698e2e8fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Old trials:  140\n"]}]},{"cell_type":"code","source":["#df_old = df_old[['number','value','params_dropout','params_learning_rate','params_num_layer','params_optimizer','state','train_loss', 'val_loss', 'Spearman_train','Spearman_val','Pearson_train','Pearson_val']]"],"metadata":{"id":"QaQZ0s9dpxho"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#df_old = df_old.rename(columns={'val_loss': 'valid_loss', 'Spearman_train': 'spearman_train', 'Spearman_val': 'spearman_val', 'Pearson_train':'pearson_train','Pearson_val':'pearson_val'})\n"],"metadata":{"id":"rRON1DZuqejf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Seleccionar los valores de df_optuna que no están ya en df_old\n","if len(df_optuna)-len(df_metrics) == len(df_old):\n","    df_optuna_filter = df_optuna.tail(len(df_metrics)).reset_index(drop=True)\n","else:\n","    # Seleccionar los valores de df_optuna que no están ya en df_old\n","    mask = ~df_optuna['value'].isin(df_old['value'])\n","    df_optuna_filter = df_optuna[mask].reset_index(drop=True)\n","    print(len(df_optuna_filter))"],"metadata":{"id":"d8OF3gFAZ3Nk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def concat(df_optuna_filter, df_metrics, df_old):\n","  # Unir dataframe de metrics con dataframe de optuna de forma horizontal y manejar los valores inexistentes\n","  df_join = pd.concat([df_optuna_filter, df_metrics], axis=1, sort=False)\n","  # Unir dataframe de metrics con dataframe de optuna de forma vertical y manejar los valores inexistentes\n","  df_complete_updated = pd.concat([df_old, df_join], axis=0, sort=False).drop_duplicates()\n","  print(\"All trials: \", len(df_complete_updated))\n","  assert len(df_join) + len(df_old) == len(df_complete_updated)\n","  return df_complete_updated"],"metadata":{"id":"wS3H4F8GZ5iB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if len(df_optuna_filter) == len(df_metrics):\n","  df_complete_updated = concat(df_optuna_filter, df_metrics, df_old).dropna(subset=['train_loss', 'value'])\n","\n","if len(df_optuna_filter) > len(df_metrics):\n","  num_rows_to_add = len(df_optuna_filter) - len(df_metrics)\n","  new_rows = [[np.nan] * len(df_metrics.columns) for i in range(num_rows_to_add)]\n","  new_df = pd.DataFrame(new_rows, columns=df_metrics.columns)\n","  df_metrics = pd.concat([new_df, df_metrics], ignore_index=True)\n","  df_complete_updated = concat(df_optuna_filter, df_metrics, df_old).dropna(subset=['train_loss','value'])"],"metadata":{"id":"7dAZ3rhaZ8O8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"17e4912f-ed16-4987-b555-b02ecf90c170"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["All trials:  150\n"]}]},{"cell_type":"code","source":["df_complete_updated"],"metadata":{"id":"1sOhGFHTLPf2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ordenar el DataFrame unido por valor\n","df = df_complete_updated.sort_values(by='value', ascending=True)\n","# Obtener la prueba con el mejor valor\n","best_trial = df.iloc[0]\n","print(\"Best trial: \")\n","print(best_trial)"],"metadata":{"id":"MxQ5fxnEaAGo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2e71d3fb-3135-4480-94ee-bdf64d660e1c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best trial: \n","number                                                                131\n","value                                                            0.436464\n","params_dropout                                                   0.137565\n","params_learning_rate                                             0.000026\n","params_num_layer                                                        1\n","params_optimizer                                                  RMSprop\n","state                                                            COMPLETE\n","train_loss              [0.8522996495167414, 0.27165179416123364, 0.14...\n","valid_loss              [0.4935647572608704, 0.6157969382215054, 0.485...\n","spearman_train          [0.7493913309890617, 0.9201128253859435, 0.958...\n","spearman_val            [0.8887677638036555, 0.8914520592480365, 0.890...\n","pearson_train           [0.7780476503426055, 0.9345250195924778, 0.965...\n","pearson_val             [0.8917265452021073, 0.8954647163559462, 0.894...\n","Name: 0, dtype: object\n"]}]},{"cell_type":"code","source":["#Guardar CSV completo y ordenado\n","# ruta de acceso a la carpeta de Google Drive montada\n","os.remove(path_base + study_name + \"_COMPLETE_SORT.csv\")\n","path_ = path_base + study_name + \"_COMPLETE_SORT.csv\"\n","# guardar el archivo CSV en Google Drive\n","df.to_csv(path_, index=False)\n","files.download(path_)\n","os.remove(path_metrics)"],"metadata":{"id":"IKMYJGgMaCCY","colab":{"base_uri":"https://localhost:8080/","height":17},"outputId":"858066b0-c36c-4867-ed24-e7296bfd53fc"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_05b66afe-066a-435a-8b2f-f795b6e885b6\", \"study-bert-mean-pooling-base_COMPLETE_SORT.csv\", 81143)"]},"metadata":{}}]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"98a5a82031cf4705b6d322cf505c5437":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_41819b74e4474f7d91ccab2e2e69f314","IPY_MODEL_5c36bf515962479ba94343efab69de3c","IPY_MODEL_da6b8766860c4691b5c7c2481ce0a96b"],"layout":"IPY_MODEL_7b7d60bd0dbb4e1ebb120d5c2af0fb62"}},"41819b74e4474f7d91ccab2e2e69f314":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8c9543dfcde4546a318314b05c5fcbb","placeholder":"​","style":"IPY_MODEL_5dc24cd0139548409546e9fa86276ee3","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"5c36bf515962479ba94343efab69de3c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bc5598ad34946f49e453a9ebe5571d5","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_85529b99b06645f5b535161a866b32c7","value":231508}},"da6b8766860c4691b5c7c2481ce0a96b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43a1dc2a47ae4ab49d1335c768d9a240","placeholder":"​","style":"IPY_MODEL_c7b0b2c668634cd3bd15e1d37cc2b834","value":" 232k/232k [00:00&lt;00:00, 1.27MB/s]"}},"7b7d60bd0dbb4e1ebb120d5c2af0fb62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8c9543dfcde4546a318314b05c5fcbb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5dc24cd0139548409546e9fa86276ee3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2bc5598ad34946f49e453a9ebe5571d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85529b99b06645f5b535161a866b32c7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"43a1dc2a47ae4ab49d1335c768d9a240":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7b0b2c668634cd3bd15e1d37cc2b834":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8fb005ce27a945c18b3ba2fee7e5d4f4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_406259d592ed44a6bd059efb414ebd18","IPY_MODEL_7954d53bdb964810833a10ed9cb5e5fd","IPY_MODEL_780ab873be8d418fb6313e6db68cf8e7"],"layout":"IPY_MODEL_982e9f5008d247c7a48a2989be45093e"}},"406259d592ed44a6bd059efb414ebd18":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39a8954dfd5b41faab9344050136aeb7","placeholder":"​","style":"IPY_MODEL_89f177c2f6c044968ef68fc72f1cd121","value":"Downloading (…)okenizer_config.json: 100%"}},"7954d53bdb964810833a10ed9cb5e5fd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_47bf56159b954ceca9ebeec00c6b81d5","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_90b27601ccc34feb972fafb2bdf960a6","value":28}},"780ab873be8d418fb6313e6db68cf8e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26972260f1794fc8a4abc8ca117eaa98","placeholder":"​","style":"IPY_MODEL_64ac94b8b2b342d6ae8bb1d0be96b795","value":" 28.0/28.0 [00:00&lt;00:00, 1.20kB/s]"}},"982e9f5008d247c7a48a2989be45093e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39a8954dfd5b41faab9344050136aeb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89f177c2f6c044968ef68fc72f1cd121":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"47bf56159b954ceca9ebeec00c6b81d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90b27601ccc34feb972fafb2bdf960a6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"26972260f1794fc8a4abc8ca117eaa98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64ac94b8b2b342d6ae8bb1d0be96b795":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bef607c1b61c46fb888f25be122b54d1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b7416d089d824073b1b0e0767acd2b61","IPY_MODEL_295e44e610d142e892fc78fa863e4313","IPY_MODEL_1870f3b6924b45be85145485cee6344f"],"layout":"IPY_MODEL_9803a589454e46f8a3503a0da500016f"}},"b7416d089d824073b1b0e0767acd2b61":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2e4b26fb1a645f5a92c1e56422f4bca","placeholder":"​","style":"IPY_MODEL_6534a49a432c40fd9c952ef0a8ebd7d5","value":"Downloading (…)lve/main/config.json: 100%"}},"295e44e610d142e892fc78fa863e4313":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1be2b125fb7347d985782bd1a08c04c6","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_88a7a7592a16428a96741b8296a795e3","value":570}},"1870f3b6924b45be85145485cee6344f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf62ffe976c244e59d8bcbc83dbeda3d","placeholder":"​","style":"IPY_MODEL_6242496f4126410d89dfacc8ed034d79","value":" 570/570 [00:00&lt;00:00, 45.4kB/s]"}},"9803a589454e46f8a3503a0da500016f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2e4b26fb1a645f5a92c1e56422f4bca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6534a49a432c40fd9c952ef0a8ebd7d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1be2b125fb7347d985782bd1a08c04c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88a7a7592a16428a96741b8296a795e3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf62ffe976c244e59d8bcbc83dbeda3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6242496f4126410d89dfacc8ed034d79":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e4b8eb1e7734458939404a4032a3e9e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f7c47536a3df419396a9e331c81b03cf","IPY_MODEL_a8d8b250ce794ac787deecdf47329866","IPY_MODEL_d782697103714041a7d0c540917d0844"],"layout":"IPY_MODEL_2b43e1daac0a4a1aa06d7176ff82ff85"}},"f7c47536a3df419396a9e331c81b03cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_178e9f55f17b4eeda2ee2114e846da84","placeholder":"​","style":"IPY_MODEL_c111bd1ca5d4404bbb820db6522edea5","value":"Downloading pytorch_model.bin: 100%"}},"a8d8b250ce794ac787deecdf47329866":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec751d6ec20345b2b899bac0aa5df5a8","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2f498e047bff49d7b73b9b1f99953dd6","value":440473133}},"d782697103714041a7d0c540917d0844":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7ed9ea109064c4784f3bd558d717857","placeholder":"​","style":"IPY_MODEL_3b8772baae3248f3b1545c204303581e","value":" 440M/440M [00:01&lt;00:00, 328MB/s]"}},"2b43e1daac0a4a1aa06d7176ff82ff85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"178e9f55f17b4eeda2ee2114e846da84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c111bd1ca5d4404bbb820db6522edea5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec751d6ec20345b2b899bac0aa5df5a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f498e047bff49d7b73b9b1f99953dd6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c7ed9ea109064c4784f3bd558d717857":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b8772baae3248f3b1545c204303581e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}