{"cells":[{"cell_type":"code","source":["import locale\n","def getpreferredencoding(do_setlocale = True):\n","    return \"UTF-8\"\n","locale.getpreferredencoding = getpreferredencoding"],"metadata":{"id":"qc0QMDk40uHK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-bc_vxzLzGWU","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a9937efc-d2ea-4a04-f7a6-d20104e74d68"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting optuna\n","  Downloading optuna-3.1.1-py3-none-any.whl (365 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.65.0)\n","Collecting colorlog\n","  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.22.4)\n","Collecting alembic>=1.5.0\n","  Downloading alembic-1.10.4-py3-none-any.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.9/212.9 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.10)\n","Collecting cmaes>=0.9.1\n","  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n","Collecting Mako\n","  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n","Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n","Successfully installed Mako-1.2.4 alembic-1.10.4 cmaes-0.9.1 colorlog-6.7.0 optuna-3.1.1\n","Mounted at /content/drive\n"]}],"source":["import pandas as pd\n","import torch\n","import numpy as np\n","import random\n","import re\n","import spacy\n","import shutil\n","import matplotlib.pyplot as plt\n","!pip install transformers\n","!pip install optuna\n","import torch.nn as nn\n","import torch.optim as optim\n","from transformers import AutoTokenizer, BertTokenizer, AutoModel, BertModel\n","from torch.utils.data import Dataset, TensorDataset, DataLoader, random_split, RandomSampler, SequentialSampler\n","import time\n","import optuna\n","from scipy.stats import spearmanr\n","import psycopg2\n","import csv\n","import math\n","import os\n","from sqlalchemy import create_engine\n","from optuna.storages import RDBStorage\n","from google.colab import drive\n","from google.colab import files\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["path_base = '/content/drive/MyDrive/Tesis/STS_Benchmark/transformer_tunned_BERT/uncase_base/study_optuna/'"],"metadata":{"id":"WHNhUg1BsffH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","import optuna\n","\n","def objective(trial):\n","    x = trial.suggest_float('x', -10, 10)\n","    return (x - 2) ** 2\n","\n","study = optuna.create_study()\n","study.optimize(objective, n_trials=100)\n","\n","study.best_params  # E.g. {'x': 2.002108042}\n","\"\"\""],"metadata":{"id":"Gx9ug849hrcw"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dy2Cy1hZz_JJ"},"outputs":[],"source":["#from google.colab import drive\n","#drive.mount('/content/drive')"]},{"cell_type":"code","source":["!wget -O Stsbenchmark.tar.gz http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz\n","shutil.unpack_archive('./Stsbenchmark.tar.gz', extract_dir='./', format='gztar')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uZ5dtmBFZ5kN","outputId":"2d4420f9-e15f-4167-b0a2-0b14c283fa6a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-05-08 21:36:21--  http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz\n","Resolving ixa2.si.ehu.es (ixa2.si.ehu.es)... 158.227.106.100\n","Connecting to ixa2.si.ehu.es (ixa2.si.ehu.es)|158.227.106.100|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: http://ixa2.si.ehu.eus/stswiki/images/4/48/Stsbenchmark.tar.gz [following]\n","--2023-05-08 21:36:21--  http://ixa2.si.ehu.eus/stswiki/images/4/48/Stsbenchmark.tar.gz\n","Resolving ixa2.si.ehu.eus (ixa2.si.ehu.eus)... 158.227.106.100\n","Connecting to ixa2.si.ehu.eus (ixa2.si.ehu.eus)|158.227.106.100|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 409630 (400K) [application/x-gzip]\n","Saving to: ‘Stsbenchmark.tar.gz’\n","\n","Stsbenchmark.tar.gz 100%[===================>] 400.03K   615KB/s    in 0.7s    \n","\n","2023-05-08 21:36:22 (615 KB/s) - ‘Stsbenchmark.tar.gz’ saved [409630/409630]\n","\n"]}]},{"cell_type":"code","source":["def getSTSBenchmarkSents(filename='sts-train.csv', root='stsbenchmark/', encoding='utf-8'):\n","  f = open(root+filename, 'r', encoding=encoding)\n","  s1, s2, target = [], [], []\n","  for line in f:\n","    example = re.split(r'\\t+', line)\n","    if len(example) > 7:\n","      example = example[:-2]\n","    s2.append(example[-1])\n","    s1.append(example[-2])\n","    target.append(float(example[-3]))\n","  print(\"{} samples: {}\".format(filename, len(target)))\n","  return s1, s2, target"],"metadata":{"id":"jaSIxSSCw5AY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["s1_train,s2_train,target_train = getSTSBenchmarkSents(filename='sts-train.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F_j7JTGEzZyz","outputId":"89fe59a3-3819-463b-e28c-6400c32c73d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sts-train.csv samples: 5749\n"]}]},{"cell_type":"code","source":["s1_test,s2_test,target_test= getSTSBenchmarkSents(filename='sts-test.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u_wBVbk6zwRF","outputId":"af362c8d-bbd7-43fe-e606-5c525ddd0a39"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sts-test.csv samples: 1379\n"]}]},{"cell_type":"code","source":["s1_dev,s2_dev,target_dev= getSTSBenchmarkSents(filename='sts-dev.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HCAYUG03z14L","outputId":"9d0d3561-912e-478e-ce7b-c4b72139a2a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sts-dev.csv samples: 1500\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X8TBNqYyCj-u","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2e8c53a4-28d7-45fe-b039-ddd64e03db64"},"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda\n"]}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(f'Device: {device}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HQf5A_IsCu9I"},"outputs":[],"source":["BATCH_SIZE = 32\n","MAX_LEN = 128\n","CORPUS = 'STS-B'\n","BERT_PATH = \"bert-base-uncased\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z600WMjxHnOJ","colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["1cd1f6b7d2e946599fa02a6d6c18cb37","71b41ad0e6884de88a226857bdbb3bd4","bc6b4f38e4d1475b97351ff921fc398f","766ed4a739554e4fba99df812ad95d6c","a524dda22cac45ea86096da5962edb1f","a08d016d54b3483b9f1ab156f23e20f9","9d5ee7a58a9542229d5ada64eae9c988","60c177fa6764453aa4d6ad595d039b66","4310f32e94d54148a92408297fac10ee","3a2b6ddaf9074ffeaa6ce1037b8148a4","c7f3320c11ef4d1fa37da183e638595f","882c5af4f8a3439484a03443260ed220","5060eb16fa9a4798aa738bd4891a8c4f","d04096ed92f94c87beb0eb1c56679d89","99ee20344ddd40f9971b88ec8f42570c","cab1c56a3b8847e68b3c9c4d508969c3","3e32ccde87af4637b37441b92c372c37","a5426a8ef1004dacaad54c2c06ce2734","0981a6dfb726476e8ad292193fd21888","bf5684275efc4477a1842ebe54021e48","5567e222423b4d6c93c6cf31145a7bc1","d4b87505ed904ba9a51c449a79958559","46a38b708a5c4e8fb56673670db77e02","d42a8178f7254a59b49730286ec8822d","cbc715adb0124b98bb0a84d0795d0a69","8482d46c97b14fa799d7a60a2e74c9f3","eba9e07ebe7d4bfd855f7d303a38cdf9","aaf99c89e5e34f23aafa7ac4f5b78226","0c6ccc2437794e57a60b19c001d44218","0f12b8e3f14f4a3fb775e5262de97e69","5f3e4e14be43497b987722f8952137f2","cc0f644d5c1841e7be5fe3cb9433008f","2c5d6c9be8f147a08ca1f6df992d1bce"]},"outputId":"ab097626-f7e1-4e86-f163-7a611a86d9d8"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cd1f6b7d2e946599fa02a6d6c18cb37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"882c5af4f8a3439484a03443260ed220"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46a38b708a5c4e8fb56673670db77e02"}},"metadata":{}}],"source":["TOKENIZER = BertTokenizer.from_pretrained(BERT_PATH, do_lower_case=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pVdOQNbvVnln"},"outputs":[],"source":["def encode_sents(sents1, sents2):\n","    input_ids_ = []\n","    attention_masks_ = []\n","    type_ids_ = []\n","    for i, sent1 in enumerate(sents1):\n","        encoded_dict = TOKENIZER.encode_plus(\n","                            sent1,                      # Sentence 1 to encode.\n","                            sents2[i],                  # Sentence 2 to encode.\n","                            add_special_tokens = True,  # Add '[CLS]' and '[SEP]'\n","                            truncation = True,\n","                            max_length = MAX_LEN,       # Pad & truncate all sentences.\n","                            pad_to_max_length = True,\n","                            return_attention_mask = True,   # Construct attn. masks.\n","                            return_tensors = 'pt',     # Return pytorch tensors.\n","                      )\n","        \n","        # Add the encoded sentence to the list.    \n","        input_ids_.append(encoded_dict['input_ids'])\n","            \n","        # And its attention mask (simply differentiates padding from non-padding).\n","        attention_masks_.append(encoded_dict['attention_mask'])\n","\n","        type_ids_.append(encoded_dict['token_type_ids'])\n","    return input_ids_, attention_masks_, type_ids_"]},{"cell_type":"code","source":["def getEncodedTensors(s1, s2, labels):\n","    input_ids, attention_masks, type_ids = encode_sents(s1, s2)\n","    input_ids = torch.cat(input_ids, dim=0)\n","    attention_masks = torch.cat(attention_masks, dim=0)\n","    type_ids = torch.cat(type_ids, dim=0)\n","    labels = torch.tensor(labels)\n","    return input_ids, attention_masks, type_ids, labels"],"metadata":{"id":"906LtLLC9Y_Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_ids_train,attention_masks_train,type_ids_train,labels_train = getEncodedTensors(s1_train,s2_train,target_train)"],"metadata":{"id":"t6ru4f5S9-qd","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1c5849fb-5eaf-49e8-96fa-649a0fd44a5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["input_ids_eval, attention_masks_eval, type_ids_eval, labels_eval = getEncodedTensors(s1_dev, s2_dev, target_dev)"],"metadata":{"id":"-bL1MWnB_-9d"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"adsDoOZNdgVR"},"outputs":[],"source":["# Combine the training inputs into a TensorDataset.\n","train_dataset = TensorDataset(input_ids_train, attention_masks_train, type_ids_train, labels_train)\n","val_dataset = TensorDataset(input_ids_eval, attention_masks_eval, type_ids_eval, labels_eval)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4L0SrB_JlaCY"},"outputs":[],"source":["# Create the DataLoaders for our training and test sets.\n","# We'll take training samples in random order. \n","torch.manual_seed(42)\n","train_loader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = BATCH_SIZE # Trains with this batch size.\n","            #num_workers=2\n","        )\n","torch.manual_seed(42)\n","val_loader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = BATCH_SIZE # Evaluate with this batch size.\n","            #num_workers=2\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nMWrY0KxnEMi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"29acb235-da23-420b-df3f-b3442814fd36"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of train batches: 180\n","Number of evaluation batches: 47\n"]}],"source":["# See first batch\n","#batch = next(iter(train_loader))\n","#print(batch[0]) # 0 -> input_ids , 1 -> attention_masks, 2 -> type_ids, 3 -> targets\n","#print(train_loader.batch_size) #tamaño del batch\n","print('Number of train batches: {}'.format(len(train_loader)))# número de batches\n","print('Number of evaluation batches: {}'.format(len(val_loader)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KkXY8l6PqLwi"},"outputs":[],"source":["class BertBaseUncasedRegressor(nn.Module):\n","  def __init__(self, num_classes = 1, dropout=0.1, attentions=True, n_layers = 0):\n","      super().__init__()\n","      self.bert = BertModel.from_pretrained(BERT_PATH, output_attentions=attentions) #load the model\n","      # Return: \n","      # last_hidden_state.shape -> [batch_size, num_tokens_in_sequence,hidden_size] (bert_base hidden_size = 768)\n","      # pooler_output.shape -> [batch_size, hidden_size] se utiliza una capa de pooling simple que aplica una transformación \n","      # lineal seguida de una función de activación tangente hiperbólica (tanh) a la última representación oculta (last_hidden_state) del token [CLS].\n","      layers = []\n","      for _ in range(n_layers):\n","          layers.append(nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size)) #self.bert.config.hidden_size -> nos da el tamaño oculto\n","          layers.append(nn.Dropout(dropout))\n","      layers.append(nn.Linear(self.bert.config.hidden_size, num_classes)) #self.bert.config.hidden_size -> nos da el tamaño oculto\n","\n","      self.regressor = nn.Sequential(*layers)\n","\n","\n","  def forward(self, input_ids, type_ids, mask):\n","      bert_output =self.bert(input_ids=input_ids, token_type_ids = type_ids, attention_mask= mask)\n","      #output = bert_output.pooler_output\n","      output = bert_output.last_hidden_state[:, 0, :]\n","      logits = self.regressor(output)\n","      #logits = self.regressor(output_drop)\n","      return logits, bert_output"]},{"cell_type":"code","source":["def pearson_corr(y_pred, y_true):\n","    all_preds = np.concatenate(y_pred)\n","    all_targets = np.concatenate(y_true)\n","    return np.corrcoef(all_preds, all_targets)[0, 1]"],"metadata":{"id":"uofdePYQTC1u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def spearman_corr(y_pred, y_true):\n","    all_preds = np.concatenate(y_pred)\n","    all_targets = np.concatenate(y_true)\n","\n","    corr, _ = spearmanr(all_preds, all_targets)\n","    return corr"],"metadata":{"id":"JKnMRshWTEiT"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fdInbGmYrUfw"},"outputs":[],"source":["def train_loop(model,loader,optimizer,criterion,device,clip = 1.0):\n","    #Training loop\n","    model.train()\n","    loss_sum = 0\n","    all_preds = []\n","    all_targets = []\n","    seed = 42\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","\n","    for i, batch in enumerate(loader):\n","        \n","        b_input_ids = batch[0].to(device)\n","        b_attention_mask = batch[1].to(device)\n","        b_type_ids = batch[2].to(device)\n","        labels = batch[3].to(device)\n","\n","        optimizer.zero_grad()\n","        #Forward \n","        outputs, _ = model(input_ids=b_input_ids, type_ids = b_type_ids, mask = b_attention_mask)\n","        outputs = outputs.squeeze(-1)\n","        #Loss\n","        loss = criterion(outputs.view(-1), labels.float())\n","        #Backprop\n","        loss.backward()\n","        #prevent gradients from exploding\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        #Update params\n","        optimizer.step()\n","\n","        loss_sum += loss.item()\n","\n","        all_preds.append(outputs.detach().cpu().numpy())\n","        all_targets.append(labels.float().detach().cpu().numpy())\n","\n","    epoch_train_loss = loss_sum / len(loader)\n","    epoch_train_pearson = pearson_corr(all_preds, all_targets)\n","    epoch_train_spearman = spearman_corr(all_preds, all_targets)\n","\n","    return epoch_train_loss, epoch_train_pearson, epoch_train_spearman"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CxO7AgRRtnnk"},"outputs":[],"source":["def evaluation_loop(model,loader,criterion,device):\n","    #Evaluation loop\n","    seed = 42\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    model.eval()\n","    with torch.no_grad():\n","        loss_sum = 0\n","        all_preds = []\n","        all_targets = []\n","\n","        for i, batch in enumerate(loader):\n","            b_input_ids = batch[0].to(device)\n","            b_attention_mask = batch[1].to(device)\n","            b_type_ids = batch[2].to(device)\n","            labels = batch[3].to(device)\n","\n","            #Forward\n","            outputs, _ = model(input_ids=b_input_ids, type_ids = b_type_ids, mask = b_attention_mask)\n","            outputs = outputs.squeeze(-1)\n","            #Loss\n","            loss = criterion(outputs.view(-1), labels.float())\n","\n","            loss_sum += loss.item()\n","\n","            all_preds.append(outputs.detach().cpu().numpy())\n","            all_targets.append(labels.float().detach().cpu().numpy())\n","        \n","        epoch_dev_loss = loss_sum / len(loader)\n","        epoch_dev_pearson = pearson_corr(all_preds, all_targets)\n","        epoch_dev_spearman = spearman_corr(all_preds, all_targets)\n","        \n","    return epoch_dev_loss, epoch_dev_pearson, epoch_dev_spearman"]},{"cell_type":"code","source":["def save_metrics_dataframe(metrics_dict, study_name, path_base):\n","  # Abrir archivo en modo escritura y especificar el separador de campos\n","  path = path_base + 'metrics_' + study_name + \".csv\"\n","  with open(path, \"a+\", newline=\"\") as f:\n","      metrics = [metrics_dict]\n","      # Crear objeto escritor CSV y especificar el separador de campos\n","      metrics_csv = csv.DictWriter(f, fieldnames=['train_loss','valid_loss','spearman_train','spearman_val','pearson_train','pearson_val'],delimiter=\",\")\n","      \n","      # Verificar si se ha escrito el encabezado del archivo\n","      if f.tell() == 0:\n","        metrics_csv.writeheader()\n","      \n","      # Escribir cada fila de datos\n","      for metric in metrics:\n","          metrics_csv.writerow(metric)"],"metadata":{"id":"Q2v_3IRZssF6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["study_name = 'study-bert-CLS-base'"],"metadata":{"id":"5pCNcQ9-s0wN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def isNan(value):\n","  return 0 if math.isnan(value) else value"],"metadata":{"id":"FDM0bES_s7Qn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def objective(trial):\n","  params = {\n","      \"num_layers\": trial.suggest_int(\"num_layer\", 0, 3),\n","      \"dropout\": trial.suggest_uniform(\"dropout\", 0, 0.7),\n","      \"optimizer\": trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]),\n","      \"learning_rate\": trial.suggest_loguniform(\"learning_rate\",1e-5, 1e-4)\n","  }\n","\n","  model = BertBaseUncasedRegressor(dropout=params[\"dropout\"], n_layers = params[\"num_layers\"]).to(device)\n","  criterion = nn.MSELoss()\n","  optimizer = getattr(optim, params[\"optimizer\"])(model.parameters(), lr=params[\"learning_rate\"])\n","  \n","  NUM_EPOCHS = 4\n","  best_valid_loss = float('inf')\n","  MODEL_FILE_NAME = CORPUS+'_'+BERT_PATH+'_'+str(MAX_LEN)+'_tunned_model.pt'\n","  history = {\"train\": {\"loss\": []}, \"test\": {\"loss\": []}}\n","\n","  torch.cuda.empty_cache()\n","  seed = 42\n","  np.random.seed(seed)\n","  random.seed(seed)\n","  torch.manual_seed(seed)\n","  torch.cuda.manual_seed_all(seed)\n","\n","  train_loss_list, val_loss_list, spearman_train, spearman_val, pearson_train, pearson_val = [], [], [], [], [], []\n","\n","  for epoch in range(NUM_EPOCHS):\n","    \n","    start_time = time.time()\n","\n","    epoch_train_loss, epoch_train_pearson, epoch_train_spearman = train_loop(model,train_loader,optimizer,criterion,device)\n","    epoch_dev_loss, epoch_dev_pearson, epoch_dev_spearman = evaluation_loop(model,val_loader,criterion,device)\n","\n","    elapsed_time = time.time() - start_time\n","\n","    if trial.should_prune():\n","      raise optuna.exceptions.TrialPruned()\n","\n","    #nos quedamos con el modelo que tiene mejor pérdida de validación\n","    if epoch_dev_loss < best_valid_loss:\n","      best_valid_loss = epoch_dev_loss\n","      torch.save(model.state_dict(), MODEL_FILE_NAME)\n","\n","    train_loss_list.append(isNan(epoch_train_loss))\n","    val_loss_list.append(isNan(epoch_dev_loss))\n","    spearman_train.append(isNan(epoch_train_spearman))\n","    spearman_val.append(isNan(epoch_dev_spearman))\n","    pearson_train.append(isNan(epoch_train_pearson))\n","    pearson_val.append(isNan(epoch_dev_pearson))\n","\n","    history[\"train\"][\"loss\"].append(epoch_train_loss)\n","    history[\"test\"][\"loss\"].append(epoch_dev_loss)\n","\n","    print('-' * 80)\n","    print(f'Epoch: {epoch+1:03}/{NUM_EPOCHS} | Time: {elapsed_time:.4f}s | Train loss: {epoch_train_loss:.4f} | Dev loss: {epoch_dev_loss:.4f}')\n","    print(f'Train Pearson Coef: {epoch_train_pearson:.4f} | Dev Pearson Coef: {epoch_dev_pearson:.4f}')\n","    print(f'Train Spearman Coef: {epoch_train_spearman:.4f} | Dev Spearman Coef: {epoch_dev_spearman:.4f}')\n","\n","  metrics_dict = {\n","      'train_loss' : train_loss_list,\n","      'valid_loss' : val_loss_list,\n","      'spearman_train': spearman_train,\n","      'spearman_val': spearman_val,\n","      'pearson_train': pearson_train,\n","      'pearson_val': pearson_val\n","  }\n","\n","  save_metrics_dataframe(metrics_dict, study_name, path_base)\n","\n","  return best_valid_loss"],"metadata":{"id":"Wymdkdgk0KBG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#obtener ip de colab para dar acceso a la DB\n","!curl ipecho.net/plain"],"metadata":{"id":"0HwFbXIoePJD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"22f52be0-80d5-4e23-8b15-dfd3cb109a86"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["34.86.68.220"]}]},{"cell_type":"code","source":["# Define the connection URL.\n","url = \"postgresql://{user}:{password}@{host}:{port}/{database}\"\n","url = url.format(\n","    user='postgres',\n","    password=\"password\",\n","    host='35.184.132.46',\n","    port='5432',\n","    database='stsb-base-CLS',\n",")\n","\n","# Create the engine and the database (if it doesn't exist yet).\n","engine = create_engine(url)\n","\n","\n","# Define the storage.\n","storage = RDBStorage(url)"],"metadata":{"id":"xEHe5-JEeT61"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define el estudio de Optuna utilizando el storage\n","study = optuna.create_study(study_name=study_name, direction=\"minimize\", storage=storage, load_if_exists=True)"],"metadata":{"id":"57CMvIlqebP6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"44225831-9eb6-4c63-93e8-4c379298f96f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-05-08 21:37:39,553]\u001b[0m Using an existing study with name 'study-bert-CLS-base' instead of creating a new one.\u001b[0m\n"]}]},{"cell_type":"code","source":["study.optimize(objective, n_trials=13)"],"metadata":{"id":"sdmRR266G1so","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["b913aafebd4b4783bf65a81601c9bdc0","e3b0bcf9264f4fabb3ff5a61aa76e8bc","6e9f32d1a42946cba6ab4b97cfb9f6ef","5d530fb5dc5041388c14efd797c68d46","208e0314cdb440548ef63c6c2677b018","9f7650d6e6eb463088ebb8266ab9a854","8bbdb918c1a5457ca2957f77a3732518","7d6a8bc5845a4f71a2eebe6197fb628a","c0fddcaf68514bdeb9c88d63f23fb36e","63c7a1e118b34f659ae8224717eff3bd","41cf2b267b6c4390b77e680285f8c981"]},"outputId":"6c3534f0-9f07-4c50-f829-88ed088689a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-27-53008359ab4f>:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  \"dropout\": trial.suggest_uniform(\"dropout\", 0, 0.7),\n","<ipython-input-27-53008359ab4f>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n","  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\",1e-5, 1e-4)\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b913aafebd4b4783bf65a81601c9bdc0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","Epoch: 001/4 | Time: 118.0217s | Train loss: 0.8338 | Dev loss: 0.6690\n","Train Pearson Coef: 0.7853 | Dev Pearson Coef: 0.8880\n","Train Spearman Coef: 0.7454 | Dev Spearman Coef: 0.8876\n","--------------------------------------------------------------------------------\n","Epoch: 002/4 | Time: 115.5723s | Train loss: 0.2547 | Dev loss: 0.4639\n","Train Pearson Coef: 0.9388 | Dev Pearson Coef: 0.8978\n","Train Spearman Coef: 0.9236 | Dev Spearman Coef: 0.8926\n","--------------------------------------------------------------------------------\n","Epoch: 003/4 | Time: 115.5746s | Train loss: 0.1376 | Dev loss: 0.5114\n","Train Pearson Coef: 0.9675 | Dev Pearson Coef: 0.8982\n","Train Spearman Coef: 0.9595 | Dev Spearman Coef: 0.8929\n","--------------------------------------------------------------------------------\n","Epoch: 004/4 | Time: 115.3275s | Train loss: 0.1025 | Dev loss: 0.4367\n","Train Pearson Coef: 0.9760 | Dev Pearson Coef: 0.8995\n","Train Spearman Coef: 0.9701 | Dev Spearman Coef: 0.8948\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-05-08 21:47:20,225]\u001b[0m Trial 139 finished with value: 0.4367238013668263 and parameters: {'num_layer': 1, 'dropout': 0.07581142097070093, 'optimizer': 'RMSprop', 'learning_rate': 2.443495365545823e-05}. Best is trial 72 with value: 0.4183954437996479.\u001b[0m\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","Epoch: 001/4 | Time: 115.6113s | Train loss: 0.8363 | Dev loss: 0.5350\n","Train Pearson Coef: 0.7845 | Dev Pearson Coef: 0.8884\n","Train Spearman Coef: 0.7433 | Dev Spearman Coef: 0.8861\n","--------------------------------------------------------------------------------\n","Epoch: 002/4 | Time: 115.5445s | Train loss: 0.2642 | Dev loss: 0.4971\n","Train Pearson Coef: 0.9364 | Dev Pearson Coef: 0.8990\n","Train Spearman Coef: 0.9206 | Dev Spearman Coef: 0.8942\n","--------------------------------------------------------------------------------\n","Epoch: 003/4 | Time: 115.4616s | Train loss: 0.1491 | Dev loss: 0.4373\n","Train Pearson Coef: 0.9647 | Dev Pearson Coef: 0.8995\n","Train Spearman Coef: 0.9561 | Dev Spearman Coef: 0.8947\n","--------------------------------------------------------------------------------\n","Epoch: 004/4 | Time: 115.4736s | Train loss: 0.0994 | Dev loss: 0.5014\n","Train Pearson Coef: 0.9766 | Dev Pearson Coef: 0.8998\n","Train Spearman Coef: 0.9708 | Dev Spearman Coef: 0.8953\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-05-08 21:55:11,983]\u001b[0m Trial 140 finished with value: 0.43732666462025743 and parameters: {'num_layer': 1, 'dropout': 0.07692553534245919, 'optimizer': 'RMSprop', 'learning_rate': 2.429185854186108e-05}. Best is trial 72 with value: 0.4183954437996479.\u001b[0m\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","Epoch: 001/4 | Time: 115.6286s | Train loss: 0.8133 | Dev loss: 0.5149\n","Train Pearson Coef: 0.7907 | Dev Pearson Coef: 0.8872\n","Train Spearman Coef: 0.7500 | Dev Spearman Coef: 0.8841\n","--------------------------------------------------------------------------------\n","Epoch: 002/4 | Time: 115.5421s | Train loss: 0.2549 | Dev loss: 0.5335\n","Train Pearson Coef: 0.9387 | Dev Pearson Coef: 0.8972\n","Train Spearman Coef: 0.9240 | Dev Spearman Coef: 0.8929\n","--------------------------------------------------------------------------------\n","Epoch: 003/4 | Time: 115.6338s | Train loss: 0.1387 | Dev loss: 0.4328\n","Train Pearson Coef: 0.9673 | Dev Pearson Coef: 0.8995\n","Train Spearman Coef: 0.9600 | Dev Spearman Coef: 0.8936\n","--------------------------------------------------------------------------------\n","Epoch: 004/4 | Time: 115.6007s | Train loss: 0.1020 | Dev loss: 0.4733\n","Train Pearson Coef: 0.9760 | Dev Pearson Coef: 0.9025\n","Train Spearman Coef: 0.9696 | Dev Spearman Coef: 0.8971\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-05-08 22:03:03,016]\u001b[0m Trial 141 finished with value: 0.43276471882424455 and parameters: {'num_layer': 1, 'dropout': 0.04978938843932513, 'optimizer': 'RMSprop', 'learning_rate': 2.2877932130910024e-05}. Best is trial 72 with value: 0.4183954437996479.\u001b[0m\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","Epoch: 001/4 | Time: 115.5444s | Train loss: 0.8182 | Dev loss: 0.5464\n","Train Pearson Coef: 0.7885 | Dev Pearson Coef: 0.8863\n","Train Spearman Coef: 0.7420 | Dev Spearman Coef: 0.8826\n","--------------------------------------------------------------------------------\n","Epoch: 002/4 | Time: 115.4754s | Train loss: 0.2504 | Dev loss: 0.4779\n","Train Pearson Coef: 0.9398 | Dev Pearson Coef: 0.8928\n","Train Spearman Coef: 0.9237 | Dev Spearman Coef: 0.8897\n","--------------------------------------------------------------------------------\n","Epoch: 003/4 | Time: 115.5256s | Train loss: 0.1436 | Dev loss: 0.4565\n","Train Pearson Coef: 0.9661 | Dev Pearson Coef: 0.8948\n","Train Spearman Coef: 0.9580 | Dev Spearman Coef: 0.8896\n","--------------------------------------------------------------------------------\n","Epoch: 004/4 | Time: 115.4354s | Train loss: 0.1012 | Dev loss: 0.6135\n","Train Pearson Coef: 0.9762 | Dev Pearson Coef: 0.8979\n","Train Spearman Coef: 0.9704 | Dev Spearman Coef: 0.8937\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-05-08 22:10:54,486]\u001b[0m Trial 142 finished with value: 0.45649051095577 and parameters: {'num_layer': 1, 'dropout': 0.09739829385773452, 'optimizer': 'RMSprop', 'learning_rate': 2.173408609318069e-05}. Best is trial 72 with value: 0.4183954437996479.\u001b[0m\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","Epoch: 001/4 | Time: 115.5645s | Train loss: 0.8259 | Dev loss: 0.5102\n","Train Pearson Coef: 0.7870 | Dev Pearson Coef: 0.8902\n","Train Spearman Coef: 0.7462 | Dev Spearman Coef: 0.8858\n","--------------------------------------------------------------------------------\n","Epoch: 002/4 | Time: 115.4293s | Train loss: 0.2610 | Dev loss: 0.5287\n","Train Pearson Coef: 0.9372 | Dev Pearson Coef: 0.8967\n","Train Spearman Coef: 0.9217 | Dev Spearman Coef: 0.8921\n","--------------------------------------------------------------------------------\n","Epoch: 003/4 | Time: 115.5297s | Train loss: 0.1455 | Dev loss: 0.4272\n","Train Pearson Coef: 0.9656 | Dev Pearson Coef: 0.9006\n","Train Spearman Coef: 0.9572 | Dev Spearman Coef: 0.8958\n","--------------------------------------------------------------------------------\n","Epoch: 004/4 | Time: 115.5410s | Train loss: 0.1035 | Dev loss: 0.5028\n","Train Pearson Coef: 0.9756 | Dev Pearson Coef: 0.8993\n","Train Spearman Coef: 0.9699 | Dev Spearman Coef: 0.8943\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-05-08 22:18:45,463]\u001b[0m Trial 143 finished with value: 0.4272005630934492 and parameters: {'num_layer': 1, 'dropout': 0.05047434291264166, 'optimizer': 'RMSprop', 'learning_rate': 2.313132842481812e-05}. Best is trial 72 with value: 0.4183954437996479.\u001b[0m\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","Epoch: 001/4 | Time: 115.5793s | Train loss: 0.8221 | Dev loss: 0.5558\n","Train Pearson Coef: 0.7880 | Dev Pearson Coef: 0.8874\n","Train Spearman Coef: 0.7466 | Dev Spearman Coef: 0.8833\n","--------------------------------------------------------------------------------\n","Epoch: 002/4 | Time: 115.5190s | Train loss: 0.2638 | Dev loss: 0.4913\n","Train Pearson Coef: 0.9365 | Dev Pearson Coef: 0.8966\n","Train Spearman Coef: 0.9201 | Dev Spearman Coef: 0.8919\n","--------------------------------------------------------------------------------\n","Epoch: 003/4 | Time: 115.6316s | Train loss: 0.1478 | Dev loss: 0.4329\n","Train Pearson Coef: 0.9651 | Dev Pearson Coef: 0.8990\n","Train Spearman Coef: 0.9569 | Dev Spearman Coef: 0.8936\n","--------------------------------------------------------------------------------\n","Epoch: 004/4 | Time: 115.5488s | Train loss: 0.1061 | Dev loss: 0.4950\n","Train Pearson Coef: 0.9750 | Dev Pearson Coef: 0.8994\n","Train Spearman Coef: 0.9687 | Dev Spearman Coef: 0.8944\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-05-08 22:26:37,111]\u001b[0m Trial 144 finished with value: 0.43292229162885787 and parameters: {'num_layer': 1, 'dropout': 0.05267025711825092, 'optimizer': 'RMSprop', 'learning_rate': 2.2937585408966356e-05}. Best is trial 72 with value: 0.4183954437996479.\u001b[0m\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","Epoch: 001/4 | Time: 115.5506s | Train loss: 0.8213 | Dev loss: 0.5179\n","Train Pearson Coef: 0.7880 | Dev Pearson Coef: 0.8886\n","Train Spearman Coef: 0.7465 | Dev Spearman Coef: 0.8846\n","--------------------------------------------------------------------------------\n","Epoch: 002/4 | Time: 115.5858s | Train loss: 0.2629 | Dev loss: 0.5400\n","Train Pearson Coef: 0.9367 | Dev Pearson Coef: 0.8987\n","Train Spearman Coef: 0.9214 | Dev Spearman Coef: 0.8943\n","--------------------------------------------------------------------------------\n","Epoch: 003/4 | Time: 115.4127s | Train loss: 0.1470 | Dev loss: 0.4239\n","Train Pearson Coef: 0.9652 | Dev Pearson Coef: 0.9015\n","Train Spearman Coef: 0.9573 | Dev Spearman Coef: 0.8962\n","--------------------------------------------------------------------------------\n","Epoch: 004/4 | Time: 115.5603s | Train loss: 0.1011 | Dev loss: 0.4911\n","Train Pearson Coef: 0.9762 | Dev Pearson Coef: 0.8987\n","Train Spearman Coef: 0.9707 | Dev Spearman Coef: 0.8944\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-05-08 22:34:27,291]\u001b[0m Trial 145 finished with value: 0.4238758382010967 and parameters: {'num_layer': 1, 'dropout': 0.045098687068924635, 'optimizer': 'RMSprop', 'learning_rate': 2.3265931005602508e-05}. Best is trial 72 with value: 0.4183954437996479.\u001b[0m\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","Epoch: 001/4 | Time: 115.5060s | Train loss: 0.8009 | Dev loss: 0.5611\n","Train Pearson Coef: 0.7934 | Dev Pearson Coef: 0.8855\n","Train Spearman Coef: 0.7504 | Dev Spearman Coef: 0.8824\n","--------------------------------------------------------------------------------\n","Epoch: 002/4 | Time: 115.6185s | Train loss: 0.2491 | Dev loss: 0.4780\n","Train Pearson Coef: 0.9401 | Dev Pearson Coef: 0.8915\n","Train Spearman Coef: 0.9242 | Dev Spearman Coef: 0.8876\n","--------------------------------------------------------------------------------\n","Epoch: 003/4 | Time: 115.6416s | Train loss: 0.1446 | Dev loss: 0.4628\n","Train Pearson Coef: 0.9658 | Dev Pearson Coef: 0.8968\n","Train Spearman Coef: 0.9575 | Dev Spearman Coef: 0.8924\n","--------------------------------------------------------------------------------\n","Epoch: 004/4 | Time: 115.5559s | Train loss: 0.0982 | Dev loss: 0.5047\n","Train Pearson Coef: 0.9769 | Dev Pearson Coef: 0.8983\n","Train Spearman Coef: 0.9711 | Dev Spearman Coef: 0.8938\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-05-08 22:42:19,018]\u001b[0m Trial 146 finished with value: 0.46281809660982576 and parameters: {'num_layer': 1, 'dropout': 0.048411617305479104, 'optimizer': 'RMSprop', 'learning_rate': 2.1979979897952332e-05}. Best is trial 72 with value: 0.4183954437996479.\u001b[0m\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","Epoch: 001/4 | Time: 115.5467s | Train loss: 0.8143 | Dev loss: 0.5233\n","Train Pearson Coef: 0.7903 | Dev Pearson Coef: 0.8818\n","Train Spearman Coef: 0.7464 | Dev Spearman Coef: 0.8779\n","--------------------------------------------------------------------------------\n","Epoch: 002/4 | Time: 115.3814s | Train loss: 0.2554 | Dev loss: 0.5456\n","Train Pearson Coef: 0.9386 | Dev Pearson Coef: 0.8938\n","Train Spearman Coef: 0.9219 | Dev Spearman Coef: 0.8893\n","--------------------------------------------------------------------------------\n","Epoch: 003/4 | Time: 115.5028s | Train loss: 0.1473 | Dev loss: 0.4640\n","Train Pearson Coef: 0.9651 | Dev Pearson Coef: 0.8961\n","Train Spearman Coef: 0.9571 | Dev Spearman Coef: 0.8920\n","--------------------------------------------------------------------------------\n","Epoch: 004/4 | Time: 115.5641s | Train loss: 0.1047 | Dev loss: 0.5009\n","Train Pearson Coef: 0.9754 | Dev Pearson Coef: 0.9005\n","Train Spearman Coef: 0.9696 | Dev Spearman Coef: 0.8963\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-05-08 22:50:09,042]\u001b[0m Trial 147 finished with value: 0.46402179053489195 and parameters: {'num_layer': 1, 'dropout': 0.06176133324570718, 'optimizer': 'RMSprop', 'learning_rate': 2.2986080365140517e-05}. Best is trial 72 with value: 0.4183954437996479.\u001b[0m\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","Epoch: 001/4 | Time: 112.2928s | Train loss: 8.3211 | Dev loss: 6.7423\n","Train Pearson Coef: 0.2377 | Dev Pearson Coef: 0.4878\n","Train Spearman Coef: 0.2116 | Dev Spearman Coef: 0.4862\n","--------------------------------------------------------------------------------\n","Epoch: 002/4 | Time: 112.2713s | Train loss: 8.0871 | Dev loss: 6.5318\n","Train Pearson Coef: 0.2524 | Dev Pearson Coef: 0.4970\n","Train Spearman Coef: 0.2233 | Dev Spearman Coef: 0.4981\n","--------------------------------------------------------------------------------\n","Epoch: 003/4 | Time: 112.2277s | Train loss: 7.8572 | Dev loss: 6.3257\n","Train Pearson Coef: 0.2661 | Dev Pearson Coef: 0.5044\n","Train Spearman Coef: 0.2343 | Dev Spearman Coef: 0.5087\n","--------------------------------------------------------------------------------\n","Epoch: 004/4 | Time: 112.2999s | Train loss: 7.6316 | Dev loss: 6.1240\n","Train Pearson Coef: 0.2789 | Dev Pearson Coef: 0.5103\n","Train Spearman Coef: 0.2445 | Dev Spearman Coef: 0.5181\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-05-08 22:57:49,660]\u001b[0m Trial 148 finished with value: 6.1239861681106245 and parameters: {'num_layer': 1, 'dropout': 0.051887783878738915, 'optimizer': 'SGD', 'learning_rate': 2.1368146055438217e-05}. Best is trial 72 with value: 0.4183954437996479.\u001b[0m\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","Epoch: 001/4 | Time: 115.5695s | Train loss: 0.8283 | Dev loss: 0.5320\n","Train Pearson Coef: 0.7862 | Dev Pearson Coef: 0.8904\n","Train Spearman Coef: 0.7433 | Dev Spearman Coef: 0.8876\n","--------------------------------------------------------------------------------\n","Epoch: 002/4 | Time: 115.4860s | Train loss: 0.2719 | Dev loss: 0.4398\n","Train Pearson Coef: 0.9345 | Dev Pearson Coef: 0.8985\n","Train Spearman Coef: 0.9187 | Dev Spearman Coef: 0.8936\n","--------------------------------------------------------------------------------\n","Epoch: 003/4 | Time: 115.4228s | Train loss: 0.1506 | Dev loss: 0.4262\n","Train Pearson Coef: 0.9644 | Dev Pearson Coef: 0.9011\n","Train Spearman Coef: 0.9563 | Dev Spearman Coef: 0.8960\n","--------------------------------------------------------------------------------\n","Epoch: 004/4 | Time: 115.5644s | Train loss: 0.1080 | Dev loss: 0.4870\n","Train Pearson Coef: 0.9746 | Dev Pearson Coef: 0.8996\n","Train Spearman Coef: 0.9684 | Dev Spearman Coef: 0.8950\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-05-08 23:05:41,063]\u001b[0m Trial 149 finished with value: 0.4261533221665849 and parameters: {'num_layer': 1, 'dropout': 0.08944830546623421, 'optimizer': 'RMSprop', 'learning_rate': 2.3650037163313346e-05}. Best is trial 72 with value: 0.4183954437996479.\u001b[0m\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","Epoch: 001/4 | Time: 115.6392s | Train loss: 0.8203 | Dev loss: 0.5468\n","Train Pearson Coef: 0.7881 | Dev Pearson Coef: 0.8854\n","Train Spearman Coef: 0.7455 | Dev Spearman Coef: 0.8815\n","--------------------------------------------------------------------------------\n","Epoch: 002/4 | Time: 115.6110s | Train loss: 0.2601 | Dev loss: 0.4815\n","Train Pearson Coef: 0.9375 | Dev Pearson Coef: 0.8969\n","Train Spearman Coef: 0.9202 | Dev Spearman Coef: 0.8933\n","--------------------------------------------------------------------------------\n","Epoch: 003/4 | Time: 115.4312s | Train loss: 0.1431 | Dev loss: 0.4452\n","Train Pearson Coef: 0.9662 | Dev Pearson Coef: 0.8977\n","Train Spearman Coef: 0.9580 | Dev Spearman Coef: 0.8929\n","--------------------------------------------------------------------------------\n","Epoch: 004/4 | Time: 115.4266s | Train loss: 0.1108 | Dev loss: 0.5744\n","Train Pearson Coef: 0.9739 | Dev Pearson Coef: 0.8994\n","Train Spearman Coef: 0.9674 | Dev Spearman Coef: 0.8945\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-05-08 23:13:32,559]\u001b[0m Trial 150 finished with value: 0.44518983015354646 and parameters: {'num_layer': 1, 'dropout': 0.08239369486424676, 'optimizer': 'RMSprop', 'learning_rate': 2.25150047667274e-05}. Best is trial 72 with value: 0.4183954437996479.\u001b[0m\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","Epoch: 001/4 | Time: 115.7376s | Train loss: 0.7996 | Dev loss: 0.5349\n","Train Pearson Coef: 0.7937 | Dev Pearson Coef: 0.8876\n","Train Spearman Coef: 0.7506 | Dev Spearman Coef: 0.8839\n","--------------------------------------------------------------------------------\n","Epoch: 002/4 | Time: 115.5579s | Train loss: 0.2426 | Dev loss: 0.4575\n","Train Pearson Coef: 0.9418 | Dev Pearson Coef: 0.8951\n","Train Spearman Coef: 0.9259 | Dev Spearman Coef: 0.8902\n","--------------------------------------------------------------------------------\n","Epoch: 003/4 | Time: 115.6485s | Train loss: 0.1350 | Dev loss: 0.5331\n","Train Pearson Coef: 0.9682 | Dev Pearson Coef: 0.8957\n","Train Spearman Coef: 0.9600 | Dev Spearman Coef: 0.8906\n","--------------------------------------------------------------------------------\n","Epoch: 004/4 | Time: 115.3825s | Train loss: 0.0999 | Dev loss: 0.4420\n","Train Pearson Coef: 0.9765 | Dev Pearson Coef: 0.8975\n","Train Spearman Coef: 0.9710 | Dev Spearman Coef: 0.8928\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-05-08 23:21:24,684]\u001b[0m Trial 151 finished with value: 0.4420217922393312 and parameters: {'num_layer': 1, 'dropout': 0.03474538535778546, 'optimizer': 'RMSprop', 'learning_rate': 1.9838023381986938e-05}. Best is trial 72 with value: 0.4183954437996479.\u001b[0m\n"]}]},{"cell_type":"code","source":["df_optuna = study.trials_dataframe(attrs=(\"number\", \"value\", \"params\", \"state\")).dropna(subset=['value']) #eliminar valores NaN\n","# Leer el archivo metrics.CSV y crear un DataFrame\n","path_metrics = path_base + 'metrics_' + study_name + \".csv\"\n","df_metrics = pd.read_csv(path_metrics)\n","print(len(df_optuna))\n","print(len(df_metrics ))"],"metadata":{"id":"uYIuYDOsgPS3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"435d7c25-83a7-4f01-b5dc-76ec1654df50"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["150\n","13\n"]}]},{"cell_type":"code","source":["df_old = pd.read_csv(path_base + study_name + \"_COMPLETE_SORT.csv\")\n","print(\"Old trials: \", len(df_old))"],"metadata":{"id":"edusFk1ngRAg","colab":{"base_uri":"https://localhost:8080/"},"outputId":"81c647c1-ca70-4ed6-e3ee-e6f2b7e7910e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Old trials:  137\n"]}]},{"cell_type":"code","source":["if len(df_optuna)-len(df_metrics) == len(df_old):\n","    df_optuna_filter = df_optuna.tail(len(df_metrics)).reset_index(drop=True)\n","else:\n","    # Seleccionar los valores de df_optuna que no están ya en df_old\n","    mask = ~df_optuna['value'].isin(df_old['value'])\n","    df_optuna_filter = df_optuna[mask].reset_index(drop=True)\n","    print(len(df_optuna_filter))"],"metadata":{"id":"4QSxpnLUgSsF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def concat(df_optuna_filter, df_metrics, df_old):\n","  # Unir dataframe de metrics con dataframe de optuna de forma horizontal y manejar los valores inexistentes\n","  df_join = pd.concat([df_optuna_filter, df_metrics], axis=1, sort=False)\n","  # Unir dataframe de metrics con dataframe de optuna de forma vertical y manejar los valores inexistentes\n","  df_complete_updated = pd.concat([df_old, df_join], axis=0, sort=False).drop_duplicates()\n","  print(\"All trials: \", len(df_complete_updated))\n","  assert len(df_join) + len(df_old) == len(df_complete_updated)\n","  return df_complete_updated"],"metadata":{"id":"o6aTbJK9gUWF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if len(df_optuna_filter) == len(df_metrics):\n","  df_complete_updated = concat(df_optuna_filter, df_metrics, df_old).dropna(subset=['train_loss', 'value'])\n","\n","if len(df_optuna_filter) > len(df_metrics):\n","  num_rows_to_add = len(df_optuna_filter) - len(df_metrics)\n","  new_rows = [[np.nan] * len(df_metrics.columns) for i in range(num_rows_to_add)]\n","  new_df = pd.DataFrame(new_rows, columns=df_metrics.columns)\n","  df_metrics = pd.concat([new_df, df_metrics], ignore_index=True)\n","  df_complete_updated = concat(df_optuna_filter, df_metrics, df_old).dropna(subset=['train_loss','value'])"],"metadata":{"id":"1bG5th1rgWHX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"edcff3ef-71d8-47b2-8a45-bf528a239239"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["All trials:  150\n"]}]},{"cell_type":"code","source":["df_complete_updated"],"metadata":{"id":"j_g0MDM59QhW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ordenar el DataFrame unido por valor\n","df = df_complete_updated.sort_values(by='value', ascending=True)\n","# Obtener la prueba con el mejor valor\n","best_trial = df.iloc[0]\n","print(\"Best trial: \")\n","print(best_trial)"],"metadata":{"id":"J7G_LWiPgYXH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9a4339fe-e740-458d-dc6f-ad8ee5579add"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best trial: \n","number                                                                 72\n","value                                                            0.418395\n","params_dropout                                                   0.068109\n","params_learning_rate                                             0.000025\n","params_num_layer                                                        1\n","params_optimizer                                                  RMSprop\n","state                                                            COMPLETE\n","train_loss              [0.8417161049114333, 0.26998363975435496, 0.14...\n","valid_loss              [0.48342972328054146, 0.47667617937351797, 0.4...\n","spearman_train          [0.7413014664692479, 0.9191786500000931, 0.957...\n","spearman_val            [0.8886493847185074, 0.8953811206748924, 0.897...\n","pearson_train           [0.7824998087382145, 0.9350176153828802, 0.965...\n","pearson_val             [0.8927142673665948, 0.9000055028435762, 0.902...\n","Name: 0, dtype: object\n"]}]},{"cell_type":"code","source":["#Guardar CSV completo y ordenado\n","# ruta de acceso a la carpeta de Google Drive montada\n","os.remove(path_base + study_name + \"_COMPLETE_SORT.csv\")\n","path_ = path_base + study_name + \"_COMPLETE_SORT.csv\"\n","# guardar el archivo CSV en Google Drive\n","df.to_csv(path_, index=False)\n","files.download(path_)\n","os.remove(path_metrics)"],"metadata":{"id":"v2iILEQrgaBW","colab":{"base_uri":"https://localhost:8080/","height":17},"outputId":"7dc0fed4-adf2-4d37-8787-ba1f350b5795"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_60ee49b4-05e3-4047-b0fb-f87da85ce711\", \"study-bert-CLS-base_COMPLETE_SORT.csv\", 86944)"]},"metadata":{}}]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1cd1f6b7d2e946599fa02a6d6c18cb37":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_71b41ad0e6884de88a226857bdbb3bd4","IPY_MODEL_bc6b4f38e4d1475b97351ff921fc398f","IPY_MODEL_766ed4a739554e4fba99df812ad95d6c"],"layout":"IPY_MODEL_a524dda22cac45ea86096da5962edb1f"}},"71b41ad0e6884de88a226857bdbb3bd4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a08d016d54b3483b9f1ab156f23e20f9","placeholder":"​","style":"IPY_MODEL_9d5ee7a58a9542229d5ada64eae9c988","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"bc6b4f38e4d1475b97351ff921fc398f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_60c177fa6764453aa4d6ad595d039b66","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4310f32e94d54148a92408297fac10ee","value":231508}},"766ed4a739554e4fba99df812ad95d6c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a2b6ddaf9074ffeaa6ce1037b8148a4","placeholder":"​","style":"IPY_MODEL_c7f3320c11ef4d1fa37da183e638595f","value":" 232k/232k [00:00&lt;00:00, 3.34MB/s]"}},"a524dda22cac45ea86096da5962edb1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a08d016d54b3483b9f1ab156f23e20f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d5ee7a58a9542229d5ada64eae9c988":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"60c177fa6764453aa4d6ad595d039b66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4310f32e94d54148a92408297fac10ee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3a2b6ddaf9074ffeaa6ce1037b8148a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7f3320c11ef4d1fa37da183e638595f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"882c5af4f8a3439484a03443260ed220":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5060eb16fa9a4798aa738bd4891a8c4f","IPY_MODEL_d04096ed92f94c87beb0eb1c56679d89","IPY_MODEL_99ee20344ddd40f9971b88ec8f42570c"],"layout":"IPY_MODEL_cab1c56a3b8847e68b3c9c4d508969c3"}},"5060eb16fa9a4798aa738bd4891a8c4f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e32ccde87af4637b37441b92c372c37","placeholder":"​","style":"IPY_MODEL_a5426a8ef1004dacaad54c2c06ce2734","value":"Downloading (…)okenizer_config.json: 100%"}},"d04096ed92f94c87beb0eb1c56679d89":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0981a6dfb726476e8ad292193fd21888","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bf5684275efc4477a1842ebe54021e48","value":28}},"99ee20344ddd40f9971b88ec8f42570c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5567e222423b4d6c93c6cf31145a7bc1","placeholder":"​","style":"IPY_MODEL_d4b87505ed904ba9a51c449a79958559","value":" 28.0/28.0 [00:00&lt;00:00, 451B/s]"}},"cab1c56a3b8847e68b3c9c4d508969c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e32ccde87af4637b37441b92c372c37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5426a8ef1004dacaad54c2c06ce2734":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0981a6dfb726476e8ad292193fd21888":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf5684275efc4477a1842ebe54021e48":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5567e222423b4d6c93c6cf31145a7bc1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4b87505ed904ba9a51c449a79958559":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"46a38b708a5c4e8fb56673670db77e02":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d42a8178f7254a59b49730286ec8822d","IPY_MODEL_cbc715adb0124b98bb0a84d0795d0a69","IPY_MODEL_8482d46c97b14fa799d7a60a2e74c9f3"],"layout":"IPY_MODEL_eba9e07ebe7d4bfd855f7d303a38cdf9"}},"d42a8178f7254a59b49730286ec8822d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aaf99c89e5e34f23aafa7ac4f5b78226","placeholder":"​","style":"IPY_MODEL_0c6ccc2437794e57a60b19c001d44218","value":"Downloading (…)lve/main/config.json: 100%"}},"cbc715adb0124b98bb0a84d0795d0a69":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f12b8e3f14f4a3fb775e5262de97e69","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5f3e4e14be43497b987722f8952137f2","value":570}},"8482d46c97b14fa799d7a60a2e74c9f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc0f644d5c1841e7be5fe3cb9433008f","placeholder":"​","style":"IPY_MODEL_2c5d6c9be8f147a08ca1f6df992d1bce","value":" 570/570 [00:00&lt;00:00, 10.2kB/s]"}},"eba9e07ebe7d4bfd855f7d303a38cdf9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aaf99c89e5e34f23aafa7ac4f5b78226":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c6ccc2437794e57a60b19c001d44218":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0f12b8e3f14f4a3fb775e5262de97e69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f3e4e14be43497b987722f8952137f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cc0f644d5c1841e7be5fe3cb9433008f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c5d6c9be8f147a08ca1f6df992d1bce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b913aafebd4b4783bf65a81601c9bdc0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e3b0bcf9264f4fabb3ff5a61aa76e8bc","IPY_MODEL_6e9f32d1a42946cba6ab4b97cfb9f6ef","IPY_MODEL_5d530fb5dc5041388c14efd797c68d46"],"layout":"IPY_MODEL_208e0314cdb440548ef63c6c2677b018"}},"e3b0bcf9264f4fabb3ff5a61aa76e8bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f7650d6e6eb463088ebb8266ab9a854","placeholder":"​","style":"IPY_MODEL_8bbdb918c1a5457ca2957f77a3732518","value":"Downloading pytorch_model.bin: 100%"}},"6e9f32d1a42946cba6ab4b97cfb9f6ef":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d6a8bc5845a4f71a2eebe6197fb628a","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0fddcaf68514bdeb9c88d63f23fb36e","value":440473133}},"5d530fb5dc5041388c14efd797c68d46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_63c7a1e118b34f659ae8224717eff3bd","placeholder":"​","style":"IPY_MODEL_41cf2b267b6c4390b77e680285f8c981","value":" 440M/440M [00:01&lt;00:00, 295MB/s]"}},"208e0314cdb440548ef63c6c2677b018":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f7650d6e6eb463088ebb8266ab9a854":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bbdb918c1a5457ca2957f77a3732518":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d6a8bc5845a4f71a2eebe6197fb628a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0fddcaf68514bdeb9c88d63f23fb36e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"63c7a1e118b34f659ae8224717eff3bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41cf2b267b6c4390b77e680285f8c981":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}